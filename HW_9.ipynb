{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ab9rjmggtbqxhfwq155v",
    "execution_id": "abd29bc9-35b3-4aae-a0cb-a1c7a0826234"
   },
   "source": [
    "# Задание:\n",
    "\n",
    "Разобраться с моделькой генерации текста, собрать самим или взять датасет с вебинара и обучить генератор текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ce7r4mszykv6m6e3cvdg1r",
    "execution_id": "fd65b25d-12c0-4451-ad3d-ed6189c9bebe"
   },
   "source": [
    "## Загрузка библиотек и модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "asw703bsoiwxic8cpdv15",
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "r7x44an7s2vsoget0lxeo",
    "execution_id": "4041f800-d499-4b27-92e7-1a8573efce71"
   },
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "ph5v497b0lat8fgf01ke78",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-y2V7wzbVXe",
    "outputId": "45b55ccd-01e6-4031-ecc9-9d462bea4dba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evgenyi_onegin.txt  рубаи.txt\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "!ls *.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "c06o1md9xiq08ey8avn1cd7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aavnuByVymwK",
    "outputId": "d8342a29-2e54-448e-d278-ccea9f917e74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина Рубаи: 23660 символов\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "text = open('рубаи.txt', 'rb').read().decode(encoding='utf-8')\n",
    "# Длина Евгения Онегина (кол-во символов)\n",
    "print('Длина Рубаи: {} символов'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "2zpmj7zmx1ptafsw7kwzmr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Duhg9NrUymwO",
    "outputId": "bb5f438f-ccc3-43de-dde6-75b9e26e9c5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Омар Хайям. Рубаи\n",
      "Цель вечная движенья миров вселенной - мы.\n",
      "В глазу рассудка ясном зрачок мгновенный - мы.\n",
      "Похож на яркий перстень летящий круг миров.\n",
      "На перстне этом быстром узор нетленный - мы.\n",
      "\n",
      "Из всех ушедших в бесконечный путь\n",
      "Сюда вернулся разве кто-нибудь?\n",
      "Так в этом старом караван-сарае,\n",
      "Смотри, чего-нибудь не позабудь.\n",
      "\n",
      "Для достойного - нету достойных наград,\n",
      "Я живот положить за достойного рад.\n",
      "Хочешь знать, существуют ли адские муки?\n",
      "Жить среди недостойных - вот истинный\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "dapk7lcmg7gaflltlmdqie",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlCgQBRVymwR",
    "outputId": "7b1a4a99-112d-41fe-98d6-38cea3eeeac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 уникальных символов в тексте\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Уникальные символы в тексте\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "print('{} уникальных символов в тексте'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "307mmkdz0g5fshnojrpmng",
    "id": "IalZLbvOzf-F"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Сопоставим уникальные символы текста и индексы\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "# Представим текст в виде последовательности чисел (индексов)\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellId": "a1nzsatsm3pyppcgs2p0j",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-DhY8bbTY3g",
    "outputId": "5bf52a2c-9609-462e-b1bd-821a565ab778"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25 49 37 53  2 31 37 46 68 49  7  2 27 56 38 37 45  1  0 32 42 48 65  2\n",
      " 39 42 60 50 37 68  2 41 39 45 43 42 50 65 68  2 49 45 53 51 39  2 39 54\n",
      " 42 48 42 50 50 51 46  2  6  2 49 64  7  1  0 14  2 40 48 37 44 56  2 53\n",
      " 37 54 54 56 41 47 37  2 68 54 50 51 49  2 44 53 37 60 51 47  2 49 40 50\n",
      " 51 39 42 50 50 64 46  2  6  2 49 64  7  1  0 26 51 58 51 43  2 50 37  2\n",
      " 68 53 47 45 46  2 52 42 53 54 55 42 50 65  2 48 42 55 68 62 45 46  2 47\n",
      " 53 56 40  2 49 45 53 51 39  7  1  0 24 37  2 52 42 53 54 55 50 42  2 66\n",
      " 55 51 49  2 38 64 54 55 53 51 49  2 56 44 51 53  2 50 42 55 48 42 50 50\n",
      " 64 46  2  6  2 49 64  7]\n",
      "Омар Хайям. Рубаи\n",
      "Цель вечная движенья миров вселенной - мы.\n",
      "В глазу рассудка ясном зрачок мгновенный - мы.\n",
      "Похож на яркий перстень летящий круг миров.\n",
      "На перстне этом быстром узор нетленный - мы.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(text_as_int[:200]), print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "lm2b4a92qyooby4d5lyb3i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23660, 23660)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "len(text_as_int), len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xtqnzvspn7lsly62fj12r",
    "execution_id": "606cea81-9cf5-4a9c-b7b3-45b7531f8aef",
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "y2mr5oqbsrgn7zmxtjl84"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Максимальная длина предложения в символах для единичного ввода\n",
    "seq_length = 100\n",
    "# Кол-во примеров в эпоху\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Размер батча\n",
    "BATCH_SIZE = 64\n",
    "# размер буфера для перемешивания данных\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# Размерность эмбеддинга\n",
    "embedding_dim = 256\n",
    "\n",
    "# Число ячеек\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "bm4ta36n83w0ei1bfvso9lu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UHJDA39zf-O",
    "outputId": "3382fac3-c43e-48ac-a206-0e93c46f0e56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23660\n",
      "О\n",
      "tf.Tensor(25, shape=(), dtype=int64)\n",
      "м\n",
      "tf.Tensor(49, shape=(), dtype=int64)\n",
      "а\n",
      "tf.Tensor(37, shape=(), dtype=int64)\n",
      "р\n",
      "tf.Tensor(53, shape=(), dtype=int64)\n",
      " \n",
      "tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: char_dataset\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Создаем датасет\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "print(len(char_dataset))\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "16z7w3fnn7z8n8xlqnh0y9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4hkDU3i7ozi",
    "outputId": "1beb5515-1fce-49ed-f607-efae3bf5a9d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Омар Хайям. Рубаи\\r\\nЦель вечная движенья миров вселенной - мы.\\r\\nВ глазу рассудка ясном зрачок мгновенн'\n",
      "'ый - мы.\\r\\nПохож на яркий перстень летящий круг миров.\\r\\nНа перстне этом быстром узор нетленный - мы.\\r\\n'\n",
      "'\\r\\nИз всех ушедших в бесконечный путь\\r\\nСюда вернулся разве кто-нибудь?\\r\\nТак в этом старом караван-сара'\n",
      "'е,\\r\\nСмотри, чего-нибудь не позабудь.\\r\\n\\r\\nДля достойного - нету достойных наград,\\r\\nЯ живот положить за '\n",
      "'достойного рад.\\r\\nХочешь знать, существуют ли адские муки?\\r\\nЖить среди недостойных - вот истинный ад!\\r'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: char_dataset, sequences\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Разобьём датасет на батчи длиной seq_length+1 символов, последний неполный батч отбрасываем\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellId": "5utbdiv37gu00c8wvymy28bj",
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество батчей в датасете: 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: char_dataset, dataset, sequences\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Разобьём каждый батч на признак и целевую переменную (без первого символа)\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "# из всех батчей создаем датасет из признаков и целевых переменных\n",
    "dataset = sequences.map(split_input_target)\n",
    "print(f'Количество батчей в датасете: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "gyywj9889rccku7jyc0emr",
    "execution_id": "211f3146-94a6-4b37-a85f-0b47d33b4b16",
    "id": "hiCopyGZymwi"
   },
   "source": [
    "Распечатаем первый пример входного текста и целевой переменной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "e1h4ipmlgj76mx8uw5jla7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNbw-iR0ymwj",
    "outputId": "3cd2e248-3e4a-4ef8-8e6c-3cf1c25963a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Омар Хайям. Рубаи\\r\\nЦель вечная движенья миров вселенной - мы.\\r\\nВ глазу рассудка ясном зрачок мгновен'\n",
      "Target data: 'мар Хайям. Рубаи\\r\\nЦель вечная движенья миров вселенной - мы.\\r\\nВ глазу рассудка ясном зрачок мгновенн'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: char_dataset, dataset, sequences\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellId": "gd3s5m1dwjgxhjawoxo23j",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2pGotuNzf-S",
    "outputId": "30091426-c2de-45c9-a0fd-70437379ffeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: char_dataset, dataset, sequences\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Перемешаем разделенные данные\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "enxqexh6u6n0l8i3cwa2jq",
    "execution_id": "d2c398d7-83f5-450d-9afb-0ecd8056f6cf"
   },
   "source": [
    "### Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellId": "dup3gbermza7d0dfj43f4q",
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "                                 \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                             return_sequences=True,\n",
    "                             stateful=True,\n",
    "                             recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                             return_sequences=True,\n",
    "                             stateful=True,\n",
    "                             recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "         tf.keras.layers.LSTM(rnn_units,\n",
    "                              return_sequences=True,\n",
    "                              stateful=True,\n",
    "                              recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                             return_sequences=True,\n",
    "                             stateful=True,\n",
    "                             recurrent_initializer='glorot_uniform'),\n",
    "                                   \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellId": "fchiih9w55dk3mutn8eav",
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model = build_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "87wzvn7ps7b8xw57w0pwp8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPGmAAXmVLGC",
    "outputId": "8a91a444-bc36-4e3b-fd3f-472d89ce5b97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           17664     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (64, None, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (64, None, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (64, None, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 69)            70725     \n",
      "=================================================================\n",
      "Total params: 30,513,477\n",
      "Trainable params: 30,513,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellId": "w6toc3dtbfhaqiatvo5k",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-_70kKAPrPU",
    "outputId": "5c85d4aa-e46a-4cfb-c59d-10901ecc797b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 69) # (batch_size, sequence_length, vocab_size)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: char_dataset, dataset, sequences\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellId": "c8n8mxf0hn9wazw45pk0un",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFkC1pcZjQFq",
    "outputId": "8bae5c53-e42a-4baa-fd0a-51cf81392857"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 69), dtype=float32, numpy=\n",
       "array([[ 3.0124211e-06,  1.3225470e-05,  1.5613827e-05, ...,\n",
       "        -1.1198234e-05, -2.4570701e-05,  8.0973095e-06],\n",
       "       [ 1.8482799e-05,  5.5313812e-05,  3.2395070e-05, ...,\n",
       "        -3.3656062e-05, -4.6851408e-05,  2.2662402e-05],\n",
       "       [ 1.4125150e-05,  1.2846469e-04,  3.1863627e-05, ...,\n",
       "        -6.0498904e-05, -4.5564473e-05,  3.4928624e-05],\n",
       "       ...,\n",
       "       [ 9.1013365e-04,  9.1484550e-04, -3.3225801e-03, ...,\n",
       "         2.9508276e-03, -1.3989927e-03, -1.1057666e-03],\n",
       "       [ 8.2392036e-04,  9.4673363e-04, -3.2138578e-03, ...,\n",
       "         3.1240166e-03, -1.4995181e-03, -1.3588653e-03],\n",
       "       [ 7.1854866e-04,  9.9469337e-04, -3.0948119e-03, ...,\n",
       "         3.2871505e-03, -1.5599538e-03, -1.5439064e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "example_batch_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellId": "5rh1l94loz6n28f29iupg",
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellId": "0uu0s48vhj3lkvaf337tl8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWcFwPwLSo05",
    "outputId": "5f6eee22-47aa-4963-bb69-d0cc355a3043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'ед придут.\\r\\n\\r\\nДай вина! Здесь не место пустым словесам.\\r\\nПоцелуи любимой - мой хлеб и бальзам.\\r\\nГубы'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'ЛбщЛЧкаГ\\rллнК\"ЛСоКНВЗнаМОПжяшЯнжиптШс\";ОЦ:хд?НЗГыыАшхепфБэч:Зр;бйЧ!Еаду!ВОгуЧЗфзХРПчРис?ШМЕбкъБАьлНБ'\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "1cp764kreebr0mnikbueup",
    "execution_id": "37ab4902-0c77-494c-8046-9032f163a4d5",
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellId": "u56za7k7yjbbrhp0rg74t",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HrXTACTdzY-",
    "outputId": "18508a4e-0e38-4b26-a638-70e91fcc469a"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# т.к. задача многоклассовой классификации, то функция потерь - обычная кросс-энтропия\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellId": "e5bp7yppefsfryksa23wve"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 69)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.234407\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cellId": "xxcidds363pi57kfw8qi3e",
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# компиляция модели\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "09z89kve4qdqs8kft6cyes",
    "execution_id": "f28320d1-a414-494c-ab7e-4339ea619c0b",
    "id": "W6fWTriUZP-n"
   },
   "source": [
    "#!g1.1\n",
    "# Папка для сохранения чекпоинтов\n",
    "checkpoint_dir = '/home/jupyter/work/resources/9_Языковое_моделирование/training_checkpoints'\n",
    "\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_freq=88*5,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellId": "xesrd7400toerk0c8je97n"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta = 0.000001,\n",
    "    patience = 10,\n",
    "    verbose = 1,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellId": "9rmdejaub4lnbz36eht75q",
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "EPOCHS = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellId": "33enu8gmbk1pcz24j4c8ti",
    "id": "UK-hmKjYVoll"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "3/3 [==============================] - 5s 143ms/step - loss: 4.3264\n",
      "Epoch 2/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 3.9630\n",
      "Epoch 3/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 3.6634\n",
      "Epoch 4/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 3.4485\n",
      "Epoch 5/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.4045\n",
      "Epoch 6/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 3.4031\n",
      "Epoch 7/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.3903\n",
      "Epoch 8/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.3808\n",
      "Epoch 9/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 3.3857\n",
      "Epoch 10/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.3801\n",
      "Epoch 11/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 3.3783\n",
      "Epoch 12/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 3.3752\n",
      "Epoch 13/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.3747\n",
      "Epoch 14/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.3687\n",
      "Epoch 15/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 3.3674\n",
      "Epoch 16/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 3.3642\n",
      "Epoch 17/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.3535\n",
      "Epoch 18/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.3430\n",
      "Epoch 19/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.3418\n",
      "Epoch 20/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.3208\n",
      "Epoch 21/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.2993\n",
      "Epoch 22/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.2757\n",
      "Epoch 23/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 3.2580\n",
      "Epoch 24/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 3.2407\n",
      "Epoch 25/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 3.1987\n",
      "Epoch 26/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 3.1661\n",
      "Epoch 27/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 3.1747\n",
      "Epoch 28/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 3.0825\n",
      "Epoch 29/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 3.0044\n",
      "Epoch 30/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.9379\n",
      "Epoch 31/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.9036\n",
      "Epoch 32/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.8622\n",
      "Epoch 33/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.8204\n",
      "Epoch 34/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.8110\n",
      "Epoch 35/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.7801\n",
      "Epoch 36/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.7587\n",
      "Epoch 37/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.7291\n",
      "Epoch 38/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.6973\n",
      "Epoch 39/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.6525\n",
      "Epoch 40/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.5918\n",
      "Epoch 41/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.5728\n",
      "Epoch 42/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.5609\n",
      "Epoch 43/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.5291\n",
      "Epoch 44/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 2.5094\n",
      "Epoch 45/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.4929\n",
      "Epoch 46/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.4779\n",
      "Epoch 47/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.4708\n",
      "Epoch 48/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.4563\n",
      "Epoch 49/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.4530\n",
      "Epoch 50/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.4320\n",
      "Epoch 51/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.4128\n",
      "Epoch 52/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.4138\n",
      "Epoch 53/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.4010\n",
      "Epoch 54/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.3858\n",
      "Epoch 55/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.3778\n",
      "Epoch 56/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.3662\n",
      "Epoch 57/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.3490\n",
      "Epoch 58/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.3381\n",
      "Epoch 59/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.3302\n",
      "Epoch 60/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.3158\n",
      "Epoch 61/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.3076\n",
      "Epoch 62/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.3035\n",
      "Epoch 63/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.2894\n",
      "Epoch 64/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 2.2778\n",
      "Epoch 65/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.2556\n",
      "Epoch 66/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.2418\n",
      "Epoch 67/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.2252\n",
      "Epoch 68/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.1991\n",
      "Epoch 69/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.1801\n",
      "Epoch 70/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.1605\n",
      "Epoch 71/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 2.1366\n",
      "Epoch 72/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 2.1134\n",
      "Epoch 73/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.1006\n",
      "Epoch 74/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 2.0874\n",
      "Epoch 75/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.0780\n",
      "Epoch 76/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.0493\n",
      "Epoch 77/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 2.0305\n",
      "Epoch 78/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 2.0062\n",
      "Epoch 79/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.9680\n",
      "Epoch 80/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 1.9352\n",
      "Epoch 81/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.9131\n",
      "Epoch 82/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 1.9008\n",
      "Epoch 83/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 1.8519\n",
      "Epoch 84/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 1.8413\n",
      "Epoch 85/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.7981\n",
      "Epoch 86/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 1.7501\n",
      "Epoch 87/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.7029\n",
      "Epoch 88/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 1.6861\n",
      "Epoch 89/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.6412\n",
      "Epoch 90/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.6180\n",
      "Epoch 91/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 1.5543\n",
      "Epoch 92/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 1.4795\n",
      "Epoch 93/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 1.4600\n",
      "Epoch 94/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 1.3849\n",
      "Epoch 95/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.3690\n",
      "Epoch 96/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.3155\n",
      "Epoch 97/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 1.2779\n",
      "Epoch 98/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 1.2296\n",
      "Epoch 99/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.1724\n",
      "Epoch 100/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 1.1185\n",
      "Epoch 101/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 1.0606\n",
      "Epoch 102/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.9989\n",
      "Epoch 103/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.9463\n",
      "Epoch 104/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.9098\n",
      "Epoch 105/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.8587\n",
      "Epoch 106/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.8215\n",
      "Epoch 107/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.7876\n",
      "Epoch 108/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.7358\n",
      "Epoch 109/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.7099\n",
      "Epoch 110/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.6645\n",
      "Epoch 111/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.6362\n",
      "Epoch 112/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.5993\n",
      "Epoch 113/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.5751\n",
      "Epoch 114/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.5559\n",
      "Epoch 115/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.5300\n",
      "Epoch 116/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.5197\n",
      "Epoch 117/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.4914\n",
      "Epoch 118/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.4803\n",
      "Epoch 119/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.4825\n",
      "Epoch 120/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.4501\n",
      "Epoch 121/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.4482\n",
      "Epoch 122/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.4222\n",
      "Epoch 123/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.4143\n",
      "Epoch 124/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.4008\n",
      "Epoch 125/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.4000\n",
      "Epoch 126/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3861\n",
      "Epoch 127/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3784\n",
      "Epoch 128/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3699\n",
      "Epoch 129/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3636\n",
      "Epoch 130/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3452\n",
      "Epoch 131/600\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.3343\n",
      "Epoch 132/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3442\n",
      "Epoch 133/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3252\n",
      "Epoch 134/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3243\n",
      "Epoch 135/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3270\n",
      "Epoch 136/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3164\n",
      "Epoch 137/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3170\n",
      "Epoch 138/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3115\n",
      "Epoch 139/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3538\n",
      "Epoch 140/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3791\n",
      "Epoch 141/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3680\n",
      "Epoch 142/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3358\n",
      "Epoch 143/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3304\n",
      "Epoch 144/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3169\n",
      "Epoch 145/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3016\n",
      "Epoch 146/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2894\n",
      "Epoch 147/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2824\n",
      "Epoch 148/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.2773\n",
      "Epoch 149/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.2737\n",
      "Epoch 150/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2677\n",
      "Epoch 151/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2586\n",
      "Epoch 152/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2548\n",
      "Epoch 153/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2521\n",
      "Epoch 154/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2476\n",
      "Epoch 155/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2421\n",
      "Epoch 156/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2386\n",
      "Epoch 157/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2353\n",
      "Epoch 158/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2374\n",
      "Epoch 159/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2307\n",
      "Epoch 160/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2363\n",
      "Epoch 161/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2242\n",
      "Epoch 162/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2232\n",
      "Epoch 163/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2151\n",
      "Epoch 164/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2258\n",
      "Epoch 165/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2105\n",
      "Epoch 166/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2106\n",
      "Epoch 167/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2189\n",
      "Epoch 168/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2059\n",
      "Epoch 169/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2048\n",
      "Epoch 170/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2028\n",
      "Epoch 171/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2097\n",
      "Epoch 172/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2095\n",
      "Epoch 173/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2031\n",
      "Epoch 174/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2096\n",
      "Epoch 175/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2014\n",
      "Epoch 176/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1991\n",
      "Epoch 177/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1923\n",
      "Epoch 178/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1980\n",
      "Epoch 179/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1867\n",
      "Epoch 180/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1841\n",
      "Epoch 181/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1831\n",
      "Epoch 182/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1888\n",
      "Epoch 183/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1869\n",
      "Epoch 184/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1896\n",
      "Epoch 185/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1805\n",
      "Epoch 186/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1856\n",
      "Epoch 187/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1826\n",
      "Epoch 188/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1781\n",
      "Epoch 189/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1783\n",
      "Epoch 190/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1805\n",
      "Epoch 191/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1825\n",
      "Epoch 192/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1718\n",
      "Epoch 193/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1711\n",
      "Epoch 194/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1725\n",
      "Epoch 195/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1740\n",
      "Epoch 196/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1706\n",
      "Epoch 197/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1710\n",
      "Epoch 198/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1647\n",
      "Epoch 199/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1648\n",
      "Epoch 200/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1652\n",
      "Epoch 201/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1742\n",
      "Epoch 202/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1681\n",
      "Epoch 203/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1672\n",
      "Epoch 204/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1648\n",
      "Epoch 205/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1629\n",
      "Epoch 206/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1693\n",
      "Epoch 207/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1647\n",
      "Epoch 208/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1578\n",
      "Epoch 209/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1607\n",
      "Epoch 210/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1601\n",
      "Epoch 211/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1566\n",
      "Epoch 212/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1511\n",
      "Epoch 213/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1539\n",
      "Epoch 214/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1559\n",
      "Epoch 215/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1528\n",
      "Epoch 216/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1456\n",
      "Epoch 217/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1553\n",
      "Epoch 218/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1492\n",
      "Epoch 219/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1570\n",
      "Epoch 220/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1433\n",
      "Epoch 221/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1481\n",
      "Epoch 222/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1399\n",
      "Epoch 223/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1466\n",
      "Epoch 224/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1379\n",
      "Epoch 225/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1458\n",
      "Epoch 226/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1384\n",
      "Epoch 227/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1384\n",
      "Epoch 228/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1373\n",
      "Epoch 229/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1385\n",
      "Epoch 230/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1443\n",
      "Epoch 231/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1390\n",
      "Epoch 232/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1378\n",
      "Epoch 233/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1420\n",
      "Epoch 234/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1397\n",
      "Epoch 235/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1423\n",
      "Epoch 236/600\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.1364\n",
      "Epoch 237/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1367\n",
      "Epoch 238/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1281\n",
      "Epoch 239/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1277\n",
      "Epoch 240/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1331\n",
      "Epoch 241/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1325\n",
      "Epoch 242/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1297\n",
      "Epoch 243/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1300\n",
      "Epoch 244/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1266\n",
      "Epoch 245/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1273\n",
      "Epoch 246/600\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1255\n",
      "Epoch 247/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1270\n",
      "Epoch 248/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1245\n",
      "Epoch 249/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1240\n",
      "Epoch 250/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1236\n",
      "Epoch 251/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1272\n",
      "Epoch 252/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1224\n",
      "Epoch 253/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1214\n",
      "Epoch 254/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1211\n",
      "Epoch 255/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1232\n",
      "Epoch 256/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1236\n",
      "Epoch 257/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1177\n",
      "Epoch 258/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1203\n",
      "Epoch 259/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1212\n",
      "Epoch 260/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1181\n",
      "Epoch 261/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1193\n",
      "Epoch 262/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1219\n",
      "Epoch 263/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1147\n",
      "Epoch 264/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1155\n",
      "Epoch 265/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1172\n",
      "Epoch 266/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1192\n",
      "Epoch 267/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1159\n",
      "Epoch 268/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1136\n",
      "Epoch 269/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1204\n",
      "Epoch 270/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1182\n",
      "Epoch 271/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1151\n",
      "Epoch 272/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1197\n",
      "Epoch 273/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1162\n",
      "Epoch 274/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1155\n",
      "Epoch 275/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1141\n",
      "Epoch 276/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1088\n",
      "Epoch 277/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1140\n",
      "Epoch 278/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1109\n",
      "Epoch 279/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1135\n",
      "Epoch 280/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1077\n",
      "Epoch 281/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1124\n",
      "Epoch 282/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1088\n",
      "Epoch 283/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1112\n",
      "Epoch 284/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1037\n",
      "Epoch 285/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1061\n",
      "Epoch 286/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1115\n",
      "Epoch 287/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1068\n",
      "Epoch 288/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1034\n",
      "Epoch 289/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1073\n",
      "Epoch 290/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1057\n",
      "Epoch 291/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1026\n",
      "Epoch 292/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1044\n",
      "Epoch 293/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1063\n",
      "Epoch 294/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1003\n",
      "Epoch 295/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1029\n",
      "Epoch 296/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1045\n",
      "Epoch 297/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1002\n",
      "Epoch 298/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1005\n",
      "Epoch 299/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1005\n",
      "Epoch 300/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1014\n",
      "Epoch 301/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1016\n",
      "Epoch 302/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0996\n",
      "Epoch 303/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1015\n",
      "Epoch 304/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1024\n",
      "Epoch 305/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0969\n",
      "Epoch 306/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0982\n",
      "Epoch 307/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0990\n",
      "Epoch 308/600\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0943\n",
      "Epoch 309/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1010\n",
      "Epoch 310/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.1039\n",
      "Epoch 311/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0985\n",
      "Epoch 312/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0967\n",
      "Epoch 313/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0949\n",
      "Epoch 314/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0961\n",
      "Epoch 315/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0992\n",
      "Epoch 316/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0965\n",
      "Epoch 317/600\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0976\n",
      "Epoch 318/600\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0952\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00318: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: char_dataset, dataset, sequences\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Обучение модели\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "hx1213lorcpfp2k3xbpc7f",
    "execution_id": "5a7d613c-d20f-42a3-8284-b3af3de18103",
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "### Генерация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cellId": "x7omg0tfvyse9cmom2g38"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "start_string=u\"Цель вечная движенья миров вселенной - мы.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "vc446eqomxmecnga123hq",
    "execution_id": "d813e1aa-84df-4dd3-ab60-e0cafecb884f",
    "id": "LycQ-ot_jjyu"
   },
   "source": [
    "#!g1.1\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cellId": "o47ycgylonk2wk8ff2l8xe",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71xa6jnYVrAN",
    "outputId": "43620da7-7bd5-491a-992a-d1f094cc7362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           17664     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (64, None, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (64, None, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (64, None, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 69)            70725     \n",
      "=================================================================\n",
      "Total params: 30,513,477\n",
      "Trainable params: 30,513,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellId": "zc50e6y041kla3zlfsodb",
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# на вход процедуры поступает префикс start_string\n",
    "\n",
    "def generate_text(model, start_string):\n",
    "    num_generate = 500\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "    temperature = 0.5\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cellId": "y9cqjwtgttn6pmo76gnr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktovv0RFhrkn",
    "outputId": "a38f3ab1-c7a9-49ba-ae80-dd4d50c50604"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm: expected shape=(64, None, 256), found shape=(1, 42, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f7a7881ccb11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-50967db395ee>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, start_string)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    367\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    415\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         training=training_mode):\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             raise ValueError('Input ' + str(input_index) +\n\u001b[0m\u001b[1;32m    267\u001b[0m                              \u001b[0;34m' is incompatible with layer '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                              \u001b[0;34m': expected shape='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm: expected shape=(64, None, 256), found shape=(1, 42, 256)"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "text = generate_text(model, start_string=start_string)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "nwsturwxshl0eidl0rk9g",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wqVniuFpofL",
    "outputId": "7fd5d01c-e99a-4464-facf-2900a0437618"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "len(text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "1e20e514-64ff-40de-aed6-a24ae01621f9",
  "notebookPath": "9_Языковое_моделирование/HW_9.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

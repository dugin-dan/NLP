{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73da10ce",
   "metadata": {
    "cellId": "wa3ndx8g2mlzrtjvagxj",
    "execution_id": "da2b2ff6-da9d-4c92-a753-c0a78d8b33a7"
   },
   "source": [
    "# Домашнее задание №5.\n",
    "# Part-of-Speech разметка, NER, извлечение отношений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bd2ba7",
   "metadata": {
    "cellId": "xxyxk2t0do8jx39xgna2",
    "execution_id": "5fce563e-4318-4b9c-9700-8cf69e3e64c5"
   },
   "source": [
    "## <a id='Оглавление_5'>Оглавление</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e2bd0",
   "metadata": {
    "cellId": "8vt2el6yxr0y9rygokzckg",
    "execution_id": "1be14730-658c-4643-915e-f05cefadcb9a"
   },
   "source": [
    "## [Подготовка ](#Подготовка_5)\n",
    "\n",
    "## [Задание 1](#Задание_1)\n",
    "* [1.1 Теггеры UnigramTagger, BigramTagger, TrigramTagger](#Теггеры)\n",
    "* [1.2 Самописный теггер](#Самописный_теггер)\n",
    "* [1.3 Выводы](#Выводы_5.1)\n",
    "\n",
    "## [Задание 2](#Задание_2)\n",
    "* [2.1 NER из NLTK](#NER_NLTK)\n",
    "* [2.2 NER из Spacy](#NER_Spacy)\n",
    "* [2.3 NER из slovnet](#NER_slovnet)\n",
    "* [2.4 NER из deeppavlov](#NER_deeppavlov)\n",
    "* [2.5 Самописный NER](#NER_свой)\n",
    "* [2.6 Выводы](#Выводы_5.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c69697",
   "metadata": {
    "cellId": "c2513klc5uasn5dpov2dga",
    "execution_id": "fd76fa98-4840-4143-83fa-1fda4db8b1fd"
   },
   "source": [
    "## <a id='Подготовка_5'>Подготовка</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf94c87d",
   "metadata": {
    "cellId": "0b0ezez6ga0tclrxy67bqp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyconll in /home/jupyter/.local/lib/python3.8/site-packages (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: corus in /home/jupyter/.local/lib/python3.8/site-packages (0.9.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /home/jupyter/.local/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/jupyter/.local/lib/python3.8/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: jinja2 in /kernel/lib/python3.8/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/jupyter/.local/lib/python3.8/site-packages (from spacy) (8.1.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.50.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/jupyter/.local/lib/python3.8/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.19.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /kernel/lib/python3.8/site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /kernel/lib/python3.8/site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/jupyter/.local/lib/python3.8/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/jupyter/.local/lib/python3.8/site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: setuptools in /kernel/lib/python3.8/site-packages (from spacy) (51.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /kernel/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /kernel/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /kernel/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/jupyter/.local/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/jupyter/.local/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /kernel/lib/python3.8/site-packages (from jinja2->spacy) (2.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: slovnet in /home/jupyter/.local/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: navec in /home/jupyter/.local/lib/python3.8/site-packages (from slovnet) (0.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from slovnet) (1.19.2)\n",
      "Requirement already satisfied: razdel in /home/jupyter/.local/lib/python3.8/site-packages (from slovnet) (0.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting deeppavlov\n",
      "  Downloading deeppavlov-1.0.2-py3-none-any.whl (441 kB)\n",
      "     |████████████████████████████████| 441 kB 1.7 MB/s            \n",
      "\u001b[?25hCollecting overrides==4.1.2\n",
      "  Downloading overrides-4.1.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from deeppavlov) (1.8.2)\n",
      "Requirement already satisfied: scipy<1.9.0 in /usr/local/lib/python3.8/dist-packages (from deeppavlov) (1.4.1)\n",
      "Requirement already satisfied: tqdm<4.65.0,>=4.42.0 in /usr/local/lib/python3.8/dist-packages (from deeppavlov) (4.50.0)\n",
      "Collecting fastapi<0.78.0,>=0.47.0\n",
      "  Downloading fastapi-0.77.1-py3-none-any.whl (54 kB)\n",
      "     |████████████████████████████████| 54 kB 3.9 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: nltk<3.8.0,>=3.2.5 in /usr/local/lib/python3.8/dist-packages (from deeppavlov) (3.4.5)\n",
      "Collecting aio-pika<6.9.0,>=3.2.2\n",
      "  Downloading aio_pika-6.8.2-py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 995 kB/s             \n",
      "\u001b[?25hCollecting prometheus-client<0.15.0,>=0.13.0\n",
      "  Downloading prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
      "     |████████████████████████████████| 59 kB 2.5 MB/s             \n",
      "\u001b[?25hCollecting pybind11==2.2.4\n",
      "  Downloading pybind11-2.2.4-py2.py3-none-any.whl (145 kB)\n",
      "     |████████████████████████████████| 145 kB 31.6 MB/s            \n",
      "\u001b[?25hCollecting pandas<1.5.0,>=1.0.0\n",
      "  Downloading pandas-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "     |████████████████████████████████| 11.7 MB 28.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pymorphy2==0.9.1 in /usr/local/lib/python3.8/dist-packages (from deeppavlov) (0.9.1)\n",
      "Collecting scikit-learn<1.1.0,>=0.24\n",
      "  Downloading scikit_learn-1.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "     |████████████████████████████████| 26.7 MB 92.2 MB/s            \n",
      "\u001b[?25hCollecting uvicorn<0.19.0,>=0.13.0\n",
      "  Downloading uvicorn-0.18.3-py3-none-any.whl (57 kB)\n",
      "     |████████████████████████████████| 57 kB 8.0 MB/s              \n",
      "\u001b[?25hRequirement already satisfied: numpy<1.24 in /usr/local/lib/python3.8/dist-packages (from deeppavlov) (1.19.2)\n",
      "Requirement already satisfied: filelock<3.8.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from deeppavlov) (3.4.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.19.0 in /kernel/lib/python3.8/site-packages (from deeppavlov) (2.28.2)\n",
      "Collecting typing-utils>=0.0.3\n",
      "  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from pymorphy2==0.9.1->deeppavlov) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.8/dist-packages (from pymorphy2==0.9.1->deeppavlov) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.8/dist-packages (from pymorphy2==0.9.1->deeppavlov) (2.4.417127.4579844)\n",
      "Requirement already satisfied: yarl in /usr/local/lib/python3.8/dist-packages (from aio-pika<6.9.0,>=3.2.2->deeppavlov) (1.7.2)\n",
      "Collecting aiormq<4,>=3.2.3\n",
      "  Downloading aiormq-3.3.1-py3-none-any.whl (28 kB)\n",
      "Collecting starlette==0.19.1\n",
      "  Downloading starlette-0.19.1-py3-none-any.whl (63 kB)\n",
      "     |████████████████████████████████| 63 kB 1.5 MB/s             \n",
      "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
      "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "     |████████████████████████████████| 80 kB 881 kB/s             \n",
      "\u001b[?25hCollecting typing-extensions>=3.10.0\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six in /kernel/lib/python3.8/site-packages (from nltk<3.8.0,>=3.2.5->deeppavlov) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas<1.5.0,>=1.0.0->deeppavlov) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /kernel/lib/python3.8/site-packages (from pandas<1.5.0,>=1.0.0->deeppavlov) (2.8.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /kernel/lib/python3.8/site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /kernel/lib/python3.8/site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.8/site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.8/site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (2022.12.7)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.1.0,>=0.24->deeppavlov) (1.1.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     |████████████████████████████████| 58 kB 9.7 MB/s              \n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn<0.19.0,>=0.13.0->deeppavlov) (8.0.3)\n",
      "Collecting pamqp==2.3.0\n",
      "  Downloading pamqp-2.3.0-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.8/dist-packages (from yarl->aio-pika<6.9.0,>=3.2.2->deeppavlov) (5.2.0)\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sniffio, typing-extensions, pamqp, anyio, typing-utils, threadpoolctl, starlette, h11, aiormq, uvicorn, scikit-learn, pybind11, prometheus-client, pandas, overrides, fastapi, aio-pika, deeppavlov\n",
      "\u001b[33m  WARNING: The script uvicorn is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
      "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.4.0 which is incompatible.\n",
      "tensorflow 2.6.0 requires wrapt~=1.12.1, but you have wrapt 1.14.1 which is incompatible.\u001b[0m\n",
      "Successfully installed aio-pika-6.8.2 aiormq-3.3.1 anyio-3.6.2 deeppavlov-1.0.2 fastapi-0.77.1 h11-0.14.0 overrides-4.1.2 pamqp-2.3.0 pandas-1.4.4 prometheus-client-0.14.1 pybind11-2.2.4 scikit-learn-1.0.2 sniffio-1.3.0 starlette-0.19.1 threadpoolctl-3.1.0 typing-extensions-4.4.0 typing-utils-0.1.0 uvicorn-0.18.3\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipymarkup in /home/jupyter/.local/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: intervaltree>=3 in /home/jupyter/.local/lib/python3.8/site-packages (from ipymarkup) (3.1.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /home/jupyter/.local/lib/python3.8/site-packages (from intervaltree>=3->ipymarkup) (2.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn_crfsuite in /home/jupyter/.local/lib/python3.8/site-packages (0.3.6)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
      "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.8/dist-packages (from sklearn_crfsuite) (4.50.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /home/jupyter/.local/lib/python3.8/site-packages (from sklearn_crfsuite) (0.9.8)\n",
      "Requirement already satisfied: six in /kernel/lib/python3.8/site-packages (from sklearn_crfsuite) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install pyconll\n",
    "%pip install corus\n",
    "%pip install -U spacy\n",
    "%pip install slovnet\n",
    "%pip install deeppavlov\n",
    "%pip install ipymarkup\n",
    "%pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44864809",
   "metadata": {
    "cellId": "0cvgthg65alwz3h2gh1cwi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ru-core-news-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.5.0/ru_core_news_sm-3.5.0-py3-none-any.whl (15.3 MB)\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in /home/jupyter/.local/lib/python3.8/site-packages (from ru-core-news-sm==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: pymorphy3>=1.0.0 in /home/jupyter/.local/lib/python3.8/site-packages (from ru-core-news-sm==3.5.0) (1.2.0)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.5.0) (0.7.2)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in /home/jupyter/.local/lib/python3.8/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.5.0) (2.4.417150.4580142)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.8/dist-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.5.0) (0.6.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.0.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/jupyter/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/jupyter/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.4.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (4.50.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in /kernel/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/jupyter/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/jupyter/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /kernel/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/jupyter/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /kernel/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (51.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.19.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /kernel/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /kernel/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jupyter/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /kernel/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /kernel/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/jupyter/.local/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/jupyter/.local/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /kernel/lib/python3.8/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 20:14:09.411512: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2023-01-29 20:14:09.411543: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-29 20:14:09.411561: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (s-410d2fa1-7f99-4bf1-85f8-a124ef9b415e): /proc/driver/nvidia/version does not exist\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#!:python3\n",
    "%%python3 -m spacy download ru_core_news_sm\n",
    "%%python3 -m deeppavlov install squad_bert\n",
    "%%python3 -m deeppavlov install ner_ontonotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d74446b",
   "metadata": {
    "cellId": "ajqymqxwt3uihgi565luy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pyconll\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import corus\n",
    "import deeppavlov\n",
    "from deeppavlov import configs, build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f1bb88",
   "metadata": {
    "cellId": "v7zwlwo7xrlqop9t2l2psd"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import ru_core_news_sm\n",
    "import pandas as pd\n",
    "from navec import Navec\n",
    "from slovnet import NER\n",
    "from ipymarkup import show_span_ascii_markup as show_markup\n",
    "from razdel import tokenize\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eab1f4",
   "metadata": {
    "cellId": "all6v9hv2lkjxfon9fj3ur",
    "execution_id": "6a98573b-e62e-47cf-9bd0-7bc4444f8115"
   },
   "source": [
    "## <a id='Задание_1'>Задание 1. Написать теггер на данных с русским языком</a>\n",
    "\n",
    "1. проверить UnigramTagger, BigramTagger, TrigramTagger и их комбмнации;\n",
    "2. написать свой теггер как на занятии (попробовать разные векторайзеры, добавить знание не только букв, но и слов);\n",
    "3. сравнить все реализованные методы сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f9ee38",
   "metadata": {
    "cellId": "4zxu798y3okcv7ti1804f"
   },
   "outputs": [],
   "source": [
    "# Загружаем данные\n",
    "full_train = pyconll.load_from_file('ru_syntagrus-ud-train-a.conllu')\n",
    "full_test = pyconll.load_from_file('ru_syntagrus-ud-dev.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c4fc373",
   "metadata": {
    "cellId": "zipw9bimhtky1nkr1x65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анкета NOUN\n",
      ". PUNCT\n",
      "\n",
      "Начальник NOUN\n",
      "областного ADJ\n",
      "управления NOUN\n",
      "связи NOUN\n",
      "Семен PROPN\n",
      "Еремеевич PROPN\n",
      "был AUX\n",
      "человек NOUN\n",
      "простой ADJ\n",
      ", PUNCT\n",
      "приходил VERB\n",
      "на ADP\n",
      "работу NOUN\n",
      "всегда ADV\n",
      "вовремя ADV\n",
      ", PUNCT\n",
      "здоровался VERB\n",
      "с ADP\n",
      "секретаршей NOUN\n",
      "за ADP\n",
      "руку NOUN\n",
      "и CCONJ\n",
      "иногда ADV\n",
      "даже PART\n",
      "писал VERB\n",
      "в ADP\n",
      "стенгазету NOUN\n",
      "заметки NOUN\n",
      "под ADP\n",
      "псевдонимом NOUN\n",
      "\" PUNCT\n",
      "Муха NOUN\n",
      "\" PUNCT\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Просматриваем 2 предложения тренировочных данных:\n",
    "# В каждом из них для каждого токена выводим form (словоформа для чтения) и upos (часть речи)\n",
    "for sent in full_train[:2]:\n",
    "    for token in sent:\n",
    "        print(token.form, token.upos)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070ea25b",
   "metadata": {
    "cellId": "svfnq22iseyizg2j58zlb"
   },
   "outputs": [],
   "source": [
    "# Собираем данные\n",
    "fdata_train = []\n",
    "for sent in full_train[:]:\n",
    "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_sent_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_sent_test.append([token.form for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "257fa5b2",
   "metadata": {
    "cellId": "p7mc6vu2tmer2xl3vgeum"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наибольшая длина предложения 194\n",
      "Наибольшая длина токена 31\n"
     ]
    }
   ],
   "source": [
    "# Определяем наибольшую длину предложения и токена\n",
    "MAX_SENT_LEN = max(len(sent) for sent in full_train)\n",
    "MAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\n",
    "print('Наибольшая длина предложения', MAX_SENT_LEN)\n",
    "print('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da9c8b88",
   "metadata": {
    "cellId": "o747y8gu3gbh2wk5v5x0nl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24516, 8906, 8906)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdata_train), len(fdata_test), len(fdata_sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d12de9e",
   "metadata": {
    "cellId": "qogpt8dmteq5comx4rhk2k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Анкета', 'NOUN'), ('.', 'PUNCT')],\n",
       " [('Начальник', 'NOUN'),\n",
       "  ('областного', 'ADJ'),\n",
       "  ('управления', 'NOUN'),\n",
       "  ('связи', 'NOUN'),\n",
       "  ('Семен', 'PROPN'),\n",
       "  ('Еремеевич', 'PROPN'),\n",
       "  ('был', 'AUX'),\n",
       "  ('человек', 'NOUN'),\n",
       "  ('простой', 'ADJ'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('приходил', 'VERB'),\n",
       "  ('на', 'ADP'),\n",
       "  ('работу', 'NOUN'),\n",
       "  ('всегда', 'ADV'),\n",
       "  ('вовремя', 'ADV'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('здоровался', 'VERB'),\n",
       "  ('с', 'ADP'),\n",
       "  ('секретаршей', 'NOUN'),\n",
       "  ('за', 'ADP'),\n",
       "  ('руку', 'NOUN'),\n",
       "  ('и', 'CCONJ'),\n",
       "  ('иногда', 'ADV'),\n",
       "  ('даже', 'PART'),\n",
       "  ('писал', 'VERB'),\n",
       "  ('в', 'ADP'),\n",
       "  ('стенгазету', 'NOUN'),\n",
       "  ('заметки', 'NOUN'),\n",
       "  ('под', 'ADP'),\n",
       "  ('псевдонимом', 'NOUN'),\n",
       "  ('\"', 'PUNCT'),\n",
       "  ('Муха', 'NOUN'),\n",
       "  ('\"', 'PUNCT'),\n",
       "  ('.', 'PUNCT')],\n",
       " [('В', 'ADP'),\n",
       "  ('приемной', 'NOUN'),\n",
       "  ('его', 'PRON'),\n",
       "  ('с', 'ADP'),\n",
       "  ('утра', 'NOUN'),\n",
       "  ('ожидали', 'VERB'),\n",
       "  ('посетители', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('-', 'PUNCT'),\n",
       "  ('кое-кто', 'PRON'),\n",
       "  ('с', 'ADP'),\n",
       "  ('важными', 'ADJ'),\n",
       "  ('делами', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('а', 'CCONJ'),\n",
       "  ('кое-кто', 'PRON'),\n",
       "  ('и', 'PART'),\n",
       "  ('с', 'ADP'),\n",
       "  ('такими', 'DET'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('которые', 'PRON'),\n",
       "  ('легко', 'ADV'),\n",
       "  ('можно', 'ADV'),\n",
       "  ('было', 'AUX'),\n",
       "  ('решить', 'VERB'),\n",
       "  ('в', 'ADP'),\n",
       "  ('нижестоящих', 'ADJ'),\n",
       "  ('инстанциях', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('не', 'PART'),\n",
       "  ('затрудняя', 'VERB'),\n",
       "  ('Семена', 'PROPN'),\n",
       "  ('Еремеевича', 'PROPN'),\n",
       "  ('.', 'PUNCT')],\n",
       " [('Однако', 'ADV'),\n",
       "  ('стиль', 'NOUN'),\n",
       "  ('работы', 'NOUN'),\n",
       "  ('Семена', 'PROPN'),\n",
       "  ('Еремеевича', 'PROPN'),\n",
       "  ('заключался', 'VERB'),\n",
       "  ('в', 'ADP'),\n",
       "  ('том', 'PRON'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('чтобы', 'SCONJ'),\n",
       "  ('принимать', 'VERB'),\n",
       "  ('всех', 'DET'),\n",
       "  ('желающих', 'VERB'),\n",
       "  ('и', 'CCONJ'),\n",
       "  ('лично', 'ADV'),\n",
       "  ('вникать', 'VERB'),\n",
       "  ('в', 'ADP'),\n",
       "  ('дело', 'NOUN'),\n",
       "  ('.', 'PUNCT')],\n",
       " [('Приемная', 'NOUN'),\n",
       "  ('была', 'AUX'),\n",
       "  ('обставлена', 'VERB'),\n",
       "  ('просто', 'ADV'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('но', 'CCONJ'),\n",
       "  ('по-деловому', 'ADV'),\n",
       "  ('.', 'PUNCT')]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Просматриваем тренировочные данные (токен, тег)\n",
    "fdata_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb6f33",
   "metadata": {
    "cellId": "leoj8gbqxhafli02i1mh4",
    "execution_id": "4f81388c-4176-49ff-841b-99046ac4273d"
   },
   "source": [
    "### <a id='Теггеры'>1.1 Теггеры UnigramTagger, BigramTagger, TrigramTagger и их комбмнации</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5645fb",
   "metadata": {
    "cellId": "kwug0sg58gmh3djycyxuf",
    "execution_id": "f84e597e-1b88-4d4e-83ed-3c829747ee1c"
   },
   "source": [
    "**UnigramTagger** ( UnigramTagger учитывает условную частоту тегов и предсказывает наиболее частый тег для каждого токена, не ориентируется на соседние слова)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c7a6a2e",
   "metadata": {
    "cellId": "cauwvh7rtxbkz4x2t84uzk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.823732013802982"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unigram_tagger = UnigramTagger(fdata_train)\n",
    "accuracy_U = unigram_tagger.evaluate(fdata_test)\n",
    "display(accuracy_U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b389269",
   "metadata": {
    "cellId": "k6jwjyt49irvm7gzw86jxr",
    "execution_id": "cacb9cbc-8181-4a83-b0c8-827e2c4953da"
   },
   "source": [
    "**BigramTagger** (BigramTagger учитывает тэги двух слов: текущее и предыдущее слово)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb6a48ac",
   "metadata": {
    "cellId": "16eammnpk6ohgv5uzsu5j"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6093886320724006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bigram_tagger = BigramTagger(fdata_train)\n",
    "accuracy_B = bigram_tagger.evaluate(fdata_test)\n",
    "display(accuracy_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912a623",
   "metadata": {
    "cellId": "tv5m3pjn3ujukeckmx0d3e",
    "execution_id": "c45850c2-0d14-44eb-acd1-ef94903aeb8b"
   },
   "source": [
    "**TrigramTagger** (TrigramTagger учитывает тэги трёх слов: текущее и 2 предыдущих слова)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4ad9d63",
   "metadata": {
    "cellId": "deyybhik719kn6z9nril"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1778631421316492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trigram_tagger = TrigramTagger(fdata_train)\n",
    "accuracy_T = trigram_tagger.evaluate(fdata_test)\n",
    "display(accuracy_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec1f160",
   "metadata": {
    "cellId": "3zcilou0evosw0204y8ko",
    "execution_id": "6e41582d-2389-4f1c-9e5f-b477884c68e7"
   },
   "source": [
    "**Комбинация теггеров**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aaa7a8a",
   "metadata": {
    "cellId": "xf10hswsmad99yz54dl8s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8275343446838986, 0.8273650628296113, 0.1750309264926102, 0.827905462595221]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_1 = [UnigramTagger, BigramTagger]\n",
    "\n",
    "list_2 = [UnigramTagger, TrigramTagger]\n",
    "\n",
    "list_3 = [BigramTagger, TrigramTagger]\n",
    "\n",
    "list_4 = [UnigramTagger, BigramTagger, TrigramTagger]\n",
    "\n",
    "accuracy_N = []\n",
    "\n",
    "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
    "    for cls in tagger_classes:\n",
    "        backoff = cls(train_sents, backoff=backoff)\n",
    "    return backoff\n",
    "\n",
    "for list_N in [list_1, list_2, list_3, list_4]:\n",
    "    backoff = DefaultTagger('NN') \n",
    "    tag = backoff_tagger(fdata_train,  \n",
    "                         list_N,  \n",
    "                         backoff = backoff) \n",
    "\n",
    "    accuracy_N.append(tag.evaluate(fdata_test))\n",
    "\n",
    "accuracy_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6ed7390",
   "metadata": {
    "cellId": "icjlkng46rk5c80ut5f1y7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tagger</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UnigramTagger+BigramTagger+TrigramTagger</td>\n",
       "      <td>0.827905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unigram + Bigram</td>\n",
       "      <td>0.827534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnigramTagger + TrigramTagger</td>\n",
       "      <td>0.827365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unigram</td>\n",
       "      <td>0.823732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bigram</td>\n",
       "      <td>0.609389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trigram</td>\n",
       "      <td>0.177863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BigramTagger + TrigramTagger</td>\n",
       "      <td>0.175031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Tagger  Accuracy\n",
       "6  UnigramTagger+BigramTagger+TrigramTagger  0.827905\n",
       "3                          Unigram + Bigram  0.827534\n",
       "4             UnigramTagger + TrigramTagger  0.827365\n",
       "0                                   Unigram  0.823732\n",
       "1                                    Bigram  0.609389\n",
       "2                                   Trigram  0.177863\n",
       "5              BigramTagger + TrigramTagger  0.175031"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Tagger': ['Unigram', 'Bigram', 'Trigram', 'Unigram + Bigram', 'UnigramTagger + TrigramTagger', 'BigramTagger + TrigramTagger', 'UnigramTagger+BigramTagger+TrigramTagger'], 'Accuracy' : [accuracy_U, accuracy_B, accuracy_T] + accuracy_N})\n",
    "result.sort_values('Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d10f1ea",
   "metadata": {
    "cellId": "n4w0x677tfko3g7wag2q8",
    "execution_id": "e8fe3a54-4bac-4517-9d82-f6eec1cc34d8"
   },
   "source": [
    "**Вывод:** лучшие показатели метрики у комбинации теггеров UnigramTagger + BigramTagger + TrigramTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f382b5",
   "metadata": {
    "cellId": "mltokje3uf0d8d2w6w7ci4",
    "execution_id": "b188bf9a-accc-49b8-8a2b-187876c17d06"
   },
   "source": [
    "### <a id='Самописный_теггер'>1.2 Самописный теггер с различными векторайзерами</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45f76fde",
   "metadata": {
    "cellId": "6ilvx0n7gfefiu3ltggnvf"
   },
   "outputs": [],
   "source": [
    "# Собираем токены и лэйблы в списки\n",
    "train_tok = [] # Список токенов\n",
    "train_label = [] # Список теггов\n",
    "for sent in fdata_train[:]:\n",
    "    for tok in sent:\n",
    "        train_tok.append(tok[0])\n",
    "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
    "        \n",
    "test_tok = []\n",
    "test_label = []\n",
    "for sent in fdata_test[:]:\n",
    "    for tok in sent:\n",
    "        test_tok.append(tok[0])\n",
    "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "876bccfb",
   "metadata": {
    "cellId": "03uiu8yo0vr1q54401q6fq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN',\n",
       "       'NO_TAG', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM',\n",
       "       'VERB', 'X'], dtype='<U6')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Кодируем целевые метки значениями от 0 до (кол-во классов - 1)\n",
    "le = LabelEncoder()\n",
    "train_enc_labels = le.fit_transform(train_label)\n",
    "test_enc_labels = le.transform(test_label)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8bb7fa3",
   "metadata": {
    "cellId": "sgg0r5cvlkqobd77dlwa3k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.92      0.91      0.92     11247\n",
      "         ADP       0.98      1.00      0.99     10255\n",
      "         ADV       0.92      0.90      0.91      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.98      0.93      4276\n",
      "         DET       0.88      0.75      0.81      2978\n",
      "        INTJ       0.33      0.36      0.35        11\n",
      "        NOUN       0.92      0.95      0.94     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.86      0.90      0.88      1436\n",
      "        PART       0.95      0.78      0.86      3762\n",
      "        PRON       0.83      0.89      0.86      5346\n",
      "       PROPN       0.79      0.59      0.67      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.91      0.86      2176\n",
      "         SYM       1.00      0.68      0.81        53\n",
      "        VERB       0.94      0.94      0.94     12617\n",
      "           X       0.47      0.16      0.24       105\n",
      "\n",
      "    accuracy                           0.93    115000\n",
      "   macro avg       0.85      0.82      0.82    115000\n",
      "weighted avg       0.93      0.93      0.93    115000\n",
      "\n",
      "TfidfVectorizer(analyzer='char', ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.90      0.91      0.91     11247\n",
      "         ADP       0.99      0.99      0.99     10255\n",
      "         ADV       0.92      0.87      0.89      5986\n",
      "         AUX       0.81      0.97      0.89      1058\n",
      "       CCONJ       0.88      0.98      0.93      4276\n",
      "         DET       0.80      0.83      0.82      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.90      0.96      0.93     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.85      0.90      0.87      1436\n",
      "        PART       0.95      0.79      0.86      3762\n",
      "        PRON       0.87      0.84      0.86      5346\n",
      "       PROPN       0.80      0.52      0.63      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.91      0.86      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.93      0.93      0.93     12617\n",
      "           X       0.45      0.09      0.14       105\n",
      "\n",
      "    accuracy                           0.92    115000\n",
      "   macro avg       0.83      0.78      0.79    115000\n",
      "weighted avg       0.92      0.92      0.92    115000\n",
      "\n",
      "HashingVectorizer(analyzer='char', n_features=1000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.84      0.84      0.84     11247\n",
      "         ADP       0.97      0.98      0.98     10255\n",
      "         ADV       0.83      0.79      0.81      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.80      0.80      0.80      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.84      0.90      0.87     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.81      0.82      0.82      1436\n",
      "        PART       0.92      0.78      0.84      3762\n",
      "        PRON       0.84      0.86      0.85      5346\n",
      "       PROPN       0.72      0.45      0.55      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.90      0.85      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.88      0.84      0.86     12617\n",
      "           X       0.31      0.05      0.08       105\n",
      "\n",
      "    accuracy                           0.89    115000\n",
      "   macro avg       0.79      0.75      0.76    115000\n",
      "weighted avg       0.88      0.89      0.88    115000\n",
      "\n",
      "CountVectorizer(ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.95      0.44      0.60     11247\n",
      "         ADP       0.99      0.48      0.65     10255\n",
      "         ADV       0.96      0.78      0.86      5986\n",
      "         AUX       0.83      0.88      0.85      1058\n",
      "       CCONJ       0.90      0.20      0.33      4276\n",
      "         DET       0.79      0.76      0.77      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.98      0.73      0.84     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.89      0.54      0.67      1436\n",
      "        PART       0.96      0.75      0.84      3762\n",
      "        PRON       0.84      0.79      0.81      5346\n",
      "       PROPN       0.95      0.15      0.26      4315\n",
      "       PUNCT       0.39      1.00      0.56     21941\n",
      "       SCONJ       0.78      0.84      0.81      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.97      0.46      0.62     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.66    115000\n",
      "   macro avg       0.68      0.49      0.53    115000\n",
      "weighted avg       0.84      0.66      0.67    115000\n",
      "\n",
      "TfidfVectorizer(ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.95      0.44      0.60     11247\n",
      "         ADP       0.99      0.48      0.65     10255\n",
      "         ADV       0.96      0.79      0.86      5986\n",
      "         AUX       0.83      0.88      0.85      1058\n",
      "       CCONJ       0.89      0.20      0.33      4276\n",
      "         DET       0.86      0.69      0.76      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.98      0.68      0.80     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.90      0.52      0.66      1436\n",
      "        PART       0.97      0.75      0.84      3762\n",
      "        PRON       0.81      0.85      0.83      5346\n",
      "       PROPN       0.94      0.15      0.26      4315\n",
      "       PUNCT       0.38      1.00      0.55     21941\n",
      "       SCONJ       0.79      0.85      0.82      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.97      0.46      0.62     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.65    115000\n",
      "   macro avg       0.68      0.48      0.52    115000\n",
      "weighted avg       0.84      0.65      0.66    115000\n",
      "\n",
      "HashingVectorizer(n_features=1000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.43      0.21      0.28     11247\n",
      "         ADP       0.83      0.47      0.60     10255\n",
      "         ADV       0.59      0.63      0.61      5986\n",
      "         AUX       0.70      0.94      0.80      1058\n",
      "       CCONJ       0.84      0.18      0.30      4276\n",
      "         DET       0.49      0.55      0.52      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.25      0.53      0.34     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.41      0.43      0.42      1436\n",
      "        PART       0.86      0.76      0.81      3762\n",
      "        PRON       0.64      0.76      0.70      5346\n",
      "       PROPN       0.32      0.08      0.13      4315\n",
      "       PUNCT       0.00      0.00      0.00     21941\n",
      "       SCONJ       0.67      0.95      0.78      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.45      0.25      0.32     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.37    115000\n",
      "   macro avg       0.42      0.38      0.37    115000\n",
      "weighted avg       0.39      0.37      0.35    115000\n",
      "\n",
      "HashingVectorizer(analyzer='char', n_features=2000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.87      0.87      0.87     11247\n",
      "         ADP       0.98      0.99      0.98     10255\n",
      "         ADV       0.87      0.82      0.84      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.84      0.75      0.80      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.86      0.93      0.89     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.83      0.84      0.83      1436\n",
      "        PART       0.94      0.78      0.85      3762\n",
      "        PRON       0.83      0.89      0.85      5346\n",
      "       PROPN       0.74      0.41      0.53      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.90      0.85      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.89      0.88      0.89     12617\n",
      "           X       0.38      0.06      0.10       105\n",
      "\n",
      "    accuracy                           0.90    115000\n",
      "   macro avg       0.81      0.76      0.77    115000\n",
      "weighted avg       0.90      0.90      0.90    115000\n",
      "\n",
      "HashingVectorizer(analyzer='char', n_features=3000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.87      0.88      0.87     11247\n",
      "         ADP       0.98      0.99      0.98     10255\n",
      "         ADV       0.88      0.83      0.85      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.98      0.93      4276\n",
      "         DET       0.95      0.67      0.79      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.87      0.93      0.90     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.83      0.83      0.83      1436\n",
      "        PART       0.95      0.77      0.85      3762\n",
      "        PRON       0.79      0.93      0.86      5346\n",
      "       PROPN       0.78      0.39      0.52      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.90      0.85      2176\n",
      "         SYM       1.00      0.79      0.88        53\n",
      "        VERB       0.87      0.90      0.89     12617\n",
      "           X       0.28      0.10      0.15       105\n",
      "\n",
      "    accuracy                           0.90    115000\n",
      "   macro avg       0.81      0.77      0.78    115000\n",
      "weighted avg       0.90      0.90      0.90    115000\n",
      "\n",
      "HashingVectorizer(analyzer='char', n_features=5000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.88      0.88     11247\n",
      "         ADP       0.98      0.99      0.98     10255\n",
      "         ADV       0.90      0.83      0.86      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.83      0.78      0.81      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.87      0.94      0.90     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.84      0.87      0.85      1436\n",
      "        PART       0.94      0.78      0.85      3762\n",
      "        PRON       0.83      0.86      0.85      5346\n",
      "       PROPN       0.76      0.41      0.54      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.90      0.85      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.89      0.90      0.89     12617\n",
      "           X       0.50      0.05      0.09       105\n",
      "\n",
      "    accuracy                           0.91    115000\n",
      "   macro avg       0.82      0.77      0.77    115000\n",
      "weighted avg       0.90      0.91      0.90    115000\n",
      "\n",
      "HashingVectorizer(analyzer='char', n_features=10000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.88      0.88     11247\n",
      "         ADP       0.98      0.99      0.98     10255\n",
      "         ADV       0.90      0.84      0.87      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.83      0.78      0.81      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.88      0.94      0.91     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.84      0.88      0.86      1436\n",
      "        PART       0.94      0.79      0.85      3762\n",
      "        PRON       0.82      0.87      0.85      5346\n",
      "       PROPN       0.78      0.42      0.54      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.82      0.86      0.84      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.90      0.90      0.90     12617\n",
      "           X       0.71      0.05      0.09       105\n",
      "\n",
      "    accuracy                           0.91    115000\n",
      "   macro avg       0.83      0.77      0.78    115000\n",
      "weighted avg       0.91      0.91      0.90    115000\n",
      "\n",
      "HashingVectorizer(n_features=2000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.50      0.26      0.34     11247\n",
      "         ADP       0.90      0.48      0.62     10255\n",
      "         ADV       0.68      0.69      0.68      5986\n",
      "         AUX       0.75      0.94      0.84      1058\n",
      "       CCONJ       0.89      0.18      0.31      4276\n",
      "         DET       0.67      0.53      0.59      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.61      0.58      0.59     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.53      0.47      0.50      1436\n",
      "        PART       0.91      0.76      0.83      3762\n",
      "        PRON       0.69      0.85      0.76      5346\n",
      "       PROPN       0.39      0.10      0.15      4315\n",
      "       PUNCT       0.48      1.00      0.65     21941\n",
      "       SCONJ       0.76      0.90      0.82      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.55      0.31      0.39     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.58    115000\n",
      "   macro avg       0.52      0.45      0.45    115000\n",
      "weighted avg       0.62      0.58      0.56    115000\n",
      "\n",
      "HashingVectorizer(n_features=3000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.55      0.30      0.39     11247\n",
      "         ADP       0.92      0.48      0.63     10255\n",
      "         ADV       0.77      0.71      0.74      5986\n",
      "         AUX       0.77      0.94      0.85      1058\n",
      "       CCONJ       0.93      0.18      0.30      4276\n",
      "         DET       0.71      0.57      0.63      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.65      0.60      0.62     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.61      0.49      0.54      1436\n",
      "        PART       0.90      0.78      0.84      3762\n",
      "        PRON       0.74      0.83      0.79      5346\n",
      "       PROPN       0.44      0.12      0.18      4315\n",
      "       PUNCT       0.47      1.00      0.64     21941\n",
      "       SCONJ       0.73      0.95      0.83      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.60      0.33      0.43     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.60    115000\n",
      "   macro avg       0.54      0.46      0.47    115000\n",
      "weighted avg       0.65      0.60      0.58    115000\n",
      "\n",
      "HashingVectorizer(n_features=5000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.63      0.33      0.44     11247\n",
      "         ADP       0.91      0.48      0.63     10255\n",
      "         ADV       0.82      0.72      0.77      5986\n",
      "         AUX       0.79      0.95      0.86      1058\n",
      "       CCONJ       0.92      0.19      0.31      4276\n",
      "         DET       0.69      0.70      0.70      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.70      0.62      0.65     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.66      0.48      0.55      1436\n",
      "        PART       0.91      0.76      0.83      3762\n",
      "        PRON       0.79      0.79      0.79      5346\n",
      "       PROPN       0.54      0.13      0.21      4315\n",
      "       PUNCT       0.45      1.00      0.62     21941\n",
      "       SCONJ       0.76      0.88      0.82      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.67      0.36      0.47     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.61    115000\n",
      "   macro avg       0.57      0.47      0.48    115000\n",
      "weighted avg       0.68      0.61      0.59    115000\n",
      "\n",
      "HashingVectorizer(n_features=10000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.72      0.37      0.49     11247\n",
      "         ADP       0.96      0.48      0.64     10255\n",
      "         ADV       0.88      0.75      0.81      5986\n",
      "         AUX       0.81      0.88      0.84      1058\n",
      "       CCONJ       0.88      0.20      0.33      4276\n",
      "         DET       0.72      0.75      0.74      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.77      0.64      0.70     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.74      0.58      0.65      1436\n",
      "        PART       0.96      0.75      0.84      3762\n",
      "        PRON       0.83      0.78      0.81      5346\n",
      "       PROPN       0.67      0.15      0.24      4315\n",
      "       PUNCT       0.42      1.00      0.60     21941\n",
      "       SCONJ       0.78      0.88      0.83      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.75      0.41      0.53     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.63    115000\n",
      "   macro avg       0.60      0.48      0.50    115000\n",
      "weighted avg       0.72      0.63      0.62    115000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Строим модели логистической регрессии с различными векторайзерами\n",
    "# P.S. тестовые данные срезаны до 115000 штук из-за битых файлов\n",
    "\n",
    "vectorizers = [CountVectorizer(ngram_range=(1, 3), analyzer='char'), \n",
    "               TfidfVectorizer(ngram_range=(1, 3), analyzer='char'), \n",
    "               HashingVectorizer(ngram_range=(1, 3), analyzer='char', n_features=1000)] \n",
    "vectorizers_word = [CountVectorizer(ngram_range=(1, 3), analyzer='word'), \n",
    "               TfidfVectorizer(ngram_range=(1, 3), analyzer='word'), \n",
    "               HashingVectorizer(ngram_range=(1, 3), analyzer='word', n_features=1000)] \n",
    "n_features = [2000, 3000, 5000, 10000]\n",
    "vectorizers_hash = [HashingVectorizer(ngram_range=(1, 3), analyzer='char', n_features=feat) for feat in n_features]\n",
    "vectorizers_hash_word = [HashingVectorizer(ngram_range=(1, 3), analyzer='word', n_features=feat) for feat in n_features]\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for vectorizer in vectorizers + vectorizers_word + vectorizers_hash + vectorizers_hash_word:\n",
    "    X_train = vectorizer.fit_transform(train_tok)\n",
    "    X_test = vectorizer.transform(test_tok[:115000])\n",
    "    \n",
    "    lr = LogisticRegression(random_state=0, max_iter=100)\n",
    "    lr.fit(X_train, train_enc_labels)\n",
    "    pred = lr.predict(X_test)\n",
    "    f1 = f1_score(test_enc_labels[:115000], pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    acc = accuracy_score(test_enc_labels[:115000], pred)\n",
    "    accuracy_scores.append(acc)\n",
    "    \n",
    "    print(vectorizer)\n",
    "    print(classification_report(test_enc_labels[:115000], pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a08fcb01",
   "metadata": {
    "cellId": "i6iaszvctaehiivb1chohl"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.927826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.921185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.903654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.901222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.897174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.895273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.882215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>0.672425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>0.662678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HashingVectorizer(n_features=10000, ngram_rang...</td>\n",
       "      <td>0.620668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HashingVectorizer(n_features=5000, ngram_range...</td>\n",
       "      <td>0.594498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HashingVectorizer(n_features=3000, ngram_range...</td>\n",
       "      <td>0.577113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HashingVectorizer(n_features=2000, ngram_range...</td>\n",
       "      <td>0.555762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HashingVectorizer(n_features=1000, ngram_range...</td>\n",
       "      <td>0.345039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Vectorizer  f1_score\n",
       "0   CountVectorizer(analyzer='char', ngram_range=(...  0.927826\n",
       "1   TfidfVectorizer(analyzer='char', ngram_range=(...  0.921185\n",
       "9   HashingVectorizer(analyzer='char', n_features=...  0.903654\n",
       "8   HashingVectorizer(analyzer='char', n_features=...  0.901222\n",
       "7   HashingVectorizer(analyzer='char', n_features=...  0.897174\n",
       "6   HashingVectorizer(analyzer='char', n_features=...  0.895273\n",
       "2   HashingVectorizer(analyzer='char', n_features=...  0.882215\n",
       "3                 CountVectorizer(ngram_range=(1, 3))  0.672425\n",
       "4                 TfidfVectorizer(ngram_range=(1, 3))  0.662678\n",
       "13  HashingVectorizer(n_features=10000, ngram_rang...  0.620668\n",
       "12  HashingVectorizer(n_features=5000, ngram_range...  0.594498\n",
       "11  HashingVectorizer(n_features=3000, ngram_range...  0.577113\n",
       "10  HashingVectorizer(n_features=2000, ngram_range...  0.555762\n",
       "5   HashingVectorizer(n_features=1000, ngram_range...  0.345039"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_model = pd.DataFrame({'Vectorizer': vectorizers + vectorizers_word + vectorizers_hash + vectorizers_hash_word,\n",
    "                            'f1_score': f1_scores})\n",
    "result_model.sort_values('f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b780f1d7",
   "metadata": {
    "cellId": "r3zu97scrosk241qqrxxpq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.929504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.923609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.907417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.901417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.898939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.885157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>0.664722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>0.652991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HashingVectorizer(n_features=10000, ngram_rang...</td>\n",
       "      <td>0.630270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HashingVectorizer(n_features=5000, ngram_range...</td>\n",
       "      <td>0.612443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HashingVectorizer(n_features=3000, ngram_range...</td>\n",
       "      <td>0.601191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HashingVectorizer(n_features=2000, ngram_range...</td>\n",
       "      <td>0.584009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HashingVectorizer(n_features=1000, ngram_range...</td>\n",
       "      <td>0.365243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Vectorizer  Accuracy\n",
       "0   CountVectorizer(analyzer='char', ngram_range=(...  0.929504\n",
       "1   TfidfVectorizer(analyzer='char', ngram_range=(...  0.923609\n",
       "9   HashingVectorizer(analyzer='char', n_features=...  0.907417\n",
       "8   HashingVectorizer(analyzer='char', n_features=...  0.905000\n",
       "7   HashingVectorizer(analyzer='char', n_features=...  0.901417\n",
       "6   HashingVectorizer(analyzer='char', n_features=...  0.898939\n",
       "2   HashingVectorizer(analyzer='char', n_features=...  0.885157\n",
       "3                 CountVectorizer(ngram_range=(1, 3))  0.664722\n",
       "4                 TfidfVectorizer(ngram_range=(1, 3))  0.652991\n",
       "13  HashingVectorizer(n_features=10000, ngram_rang...  0.630270\n",
       "12  HashingVectorizer(n_features=5000, ngram_range...  0.612443\n",
       "11  HashingVectorizer(n_features=3000, ngram_range...  0.601191\n",
       "10  HashingVectorizer(n_features=2000, ngram_range...  0.584009\n",
       "5   HashingVectorizer(n_features=1000, ngram_range...  0.365243"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_model_acc = pd.DataFrame({'Vectorizer': vectorizers + vectorizers_word + vectorizers_hash + vectorizers_hash_word,\n",
    "                            'Accuracy': accuracy_scores})\n",
    "result_model_acc.sort_values('Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2732a3",
   "metadata": {
    "cellId": "9cvczhkrmee05t4ur6ulywc",
    "execution_id": "d6e60de2-0d48-4fb6-a720-404587a6cfc0"
   },
   "source": [
    "**Вывод:** лучшие показатели метрик f1 и accuracy у CountVectorizer(analyzer='char', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12c850e",
   "metadata": {
    "cellId": "w9lvertqra71zgp1k8ps7h",
    "execution_id": "b8d117d7-76d9-4185-b110-f2d7efa5e631"
   },
   "source": [
    "### <a id='Выводы_5.1'>1.3 Выводы</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7f9ca05",
   "metadata": {
    "cellId": "byetmvvx3pm2pmfax5so1j"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tagger</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UnigramTagger+BigramTagger+TrigramTagger</td>\n",
       "      <td>0.827905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Tagger  Accuracy\n",
       "6  UnigramTagger+BigramTagger+TrigramTagger  0.827905"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values('Accuracy', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86902030",
   "metadata": {
    "cellId": "dy41tje722po25cj1z07n"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.927826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Vectorizer  f1_score\n",
       "0  CountVectorizer(analyzer='char', ngram_range=(...  0.927826"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_model.sort_values('f1_score', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ee60429",
   "metadata": {
    "cellId": "3t1e3phc3ny3ewyp1y5y2z"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.929504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Vectorizer  Accuracy\n",
       "0  CountVectorizer(analyzer='char', ngram_range=(...  0.929504"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_model_acc.sort_values('Accuracy', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc36dfb3",
   "metadata": {
    "cellId": "976ggtp8kku8yjck04sdn",
    "execution_id": "80afb5c0-6cac-40b8-a3f0-375016474423"
   },
   "source": [
    "***Вывод: лучший метод pos tagging (по результатам подсчета метрик) - самописный теггер с CountVectorizer(analyzer='char', ngram_range=(1, 3))***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b415f",
   "metadata": {
    "cellId": "6mqrqgldf8v1tynk3lostm",
    "execution_id": "d6db5963-723c-464b-8906-80dbdfdde9a5"
   },
   "source": [
    "## <a id='Задание_2'>Задание 2. Проверить насколько хорошо работает NER</a>\n",
    "\n",
    "Данные брать из http://www.labinform.ru/pub/named_entities/\n",
    "\n",
    "1. проверить NER из nltk/spacy/deeppavlov.\n",
    "2. написать свой NER, попробовать разные подходы:\n",
    "  * передаём в сетку токен и его соседей\n",
    "  * передаём в сетку только токен\n",
    "  * свой вариант\n",
    "3. сравнить реализованные подходы на качество (вывести precision/recall/f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478fcf61",
   "metadata": {
    "cellId": "prndp2tcb8eyu6qdszejs",
    "execution_id": "ed1bf7fa-9a4b-4a8a-b15e-86af971cf6ff"
   },
   "source": [
    "Датасет содержит 1000 файлов txt и 1000 файлов ann, в которых размечены 3 сущности:\n",
    "\n",
    "- имена людей (PER),\n",
    "- имена организаций (ORG),\n",
    "- географические названия (LOC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fc3f66",
   "metadata": {
    "cellId": "r427yakgg3cibdgqvfk5mh",
    "execution_id": "1eb3d54b-0c6c-4d23-b04b-5ad6ec0b5b4f"
   },
   "source": [
    "Файлы 595.txt и 595.ann битые, в следcтвие чего были удалены из рассмотрения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e123252",
   "metadata": {
    "cellId": "v4bw3rynjeazswj4n5sat",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['03_12_12a.ann', '003.txt', '03_12_12c.ann', '03_12_12d.txt', '03_12_12c.txt', '03_12_12h.ann', '03_12_12h.txt', '004.ann', '03_12_12g.txt', '03_12_12b.ann', '03_12_12a.txt', '03_12_12g.ann', '003.ann', '03_12_12d.ann', '03_12_12b.txt', '004.txt', '04_03_13a_sorokin.ann', '04_02_13a_abdulatipov.ann', '04_12_12f.txt', '04_02_13a_abdulatipov.txt', '04_12_12f.ann', '04_12_12g.txt', '04_12_12h_corr.ann', '04_12_12b.txt', '04_12_12b.ann', '04_12_12d.ann', '006.txt', '007.ann', '04_12_12g.ann', '005.txt', '009.txt', '04_12_12h_corr.txt', '005.ann', '008.txt', '006.ann', '09_01_13.ann', '008.ann', '007.txt', '009.ann', '09_01_13a.txt', '09_01_13.txt', '09_01_13a.ann', '04_03_13a_sorokin.txt', '09_01_13c.txt', '09_01_13e.ann', '09_01_13c.ann', '09_01_13e.txt', '09_01_13d.txt', '09_01_13h.txt', '010.ann', '09_01_13i.ann', '09_01_13d.ann', '09_01_13h.ann', '010.txt', '09_01_13i.txt', '11_01_13b.txt', '10_01_13a.ann', '11_01_13e.txt', '10_01_13i.ann', '10_01_13d.ann', '04_12_12d.txt', '11_01_13e.ann', '10_01_13d.txt', '011.ann', '10_01_13i.txt', '013.txt', '10_01_13a.txt', '11_01_13b.ann', '014.ann', '14_01_13i.ann', '014.txt', '14_01_13c.ann', '011.txt', '14_01_13g.txt', '012.txt', '15_01_13a.ann', '15_01_13a.txt', '14_01_13c.txt', '14_01_13g.ann', '013.ann', '015 (!).txt', '15_01_13e.ann', '012.ann', '14_01_13i.txt', '016.ann', '018.ann', '019.ann', '15_01_13b.txt', '017.ann', '15_01_13e.txt', '017.txt', '15_01_13b.ann', '19_11_12d.ann', '016.txt', '15_01_13f.txt', '15_01_13f.ann', '019.txt', '018.txt', '19_11_12d.txt', '015 (!).ann', '020.txt', '19_11_12h.txt', '19_11_12h.ann', '20_11_12a.ann', '020.ann', '20_11_12a.txt', '20_11_12d.txt', '20_11_12b.ann', '20_11_12b.txt', '20_11_12d.ann', '20_11_12c.ann', '20_11_12c.txt', '20_11_12i.ann', '20_11_12i.txt', '021.ann', '021.txt', '21_11_12c.ann', '21_11_12c.txt', '21_11_12h.ann', '21_11_12h.txt', '21_11_12i.ann', '21_11_12i.txt', '21_11_12j.ann', '022.ann', '21_11_12j.txt', '022.txt', '22_11_12a.ann', '22_11_12a.txt', '22_11_12c.ann', '22_11_12c.txt', '22_11_12d.txt', '22_11_12d.ann', '22_11_12g.ann', '22_11_12g.txt', '22_11_12h.txt', '22_11_12h.ann', '22_11_12i.ann', '22_11_12j.ann', '22_11_12i.txt', '22_11_12j.txt', '023.ann', '023.txt', '23_11_12a.ann', '23_11_12a.txt', '23_11_12b.ann', '23_11_12b.txt', '23_11_12c.ann', '23_11_12c.txt', '23_11_12d.ann', '23_11_12d.txt', '23_11_12e.ann', '23_11_12e.txt', '23_11_12f.ann', '23_11_12f.txt', '025.ann', '25_12_12a.ann', '25_12_12a.txt', '25_12_12c.ann', '25_12_12c.txt', '25_12_12d.ann', '25_12_12d.txt', '25_12_12e.txt', '25_12_12e.ann', '026.ann', '026.txt', '26_11_12b.ann', '26_11_12b.txt', '26_11_12c.ann', '26_11_12c.txt', '26_11_12e.ann', '26_11_12e.txt', '26_11_12f.ann', '26_11_12f.txt', '027.ann', '027.txt', '27_11_12a.ann', '27_11_12a.txt', '27_11_12c.ann', '27_11_12c.txt', '27_11_12d.ann', '27_11_12d.txt', '27_11_12e.ann', '27_11_12j.txt', '27_11_12e.txt', '028.txt', '028.ann', '27_11_12j.ann', '025.txt', '28_11_12a.ann', '28_11_12a.txt', '28_11_12f.ann', '28_11_12f.txt', '28_11_12g.ann', '28_11_12g.txt', '28_11_12h.ann', '28_11_12h.txt', '28_11_12i.ann', '28_11_12i.txt', '28_11_12j.ann', '28_11_12j.txt', '029.ann', '029.txt', '29_11_12a.ann', '29_11_12a.txt', '29_11_12b.ann', '29_11_12b.txt', '030.txt', '030.ann', '30_11_12h.ann', '30_11_12b.ann', '30_11_12b.txt', '30_11_12h.txt', '30_11_12i.txt', '30_11_12i.ann', '031.txt', '031.ann', '032.ann', '032.txt', '033.ann', '033.txt', '034.ann', '034.txt', '035.ann', '036.txt', '035.txt', '037.ann', '036.ann', '037.txt', '038.ann', '039.ann', '039.txt', '038.txt', '040.ann', '041.txt', '041.ann', '042.ann', '040.txt', '043.ann', '043.txt', '044.ann', '044.txt', '045.txt', '042.txt', '046.ann', '045.ann', '046.txt', '047.ann', '047.txt', '048.txt', '048.ann', '049.txt', '050.ann', '050.txt', '051.ann', '051.txt', '052.ann', '052.txt', '053.txt', '053.ann', '054.ann', '054.txt', '055.ann', '055.txt', '056.ann', '056.txt', '057.ann', '057.txt', '058.ann', '058.txt', '059.ann', '059.txt', '060.ann', '061.ann', '060.txt', '061.txt', '062.ann', '062.txt', '049.ann', '063.ann', '063.txt', '064.ann', '064.txt', '065.ann', '065.txt', '066.ann', '066.txt', '067.ann', '067.txt', '068.ann', '068.txt', '069.ann', '069.txt', '070.ann', '070.txt', '071.txt', '071.ann', '072.txt', '072.ann', '073.ann', '073.txt', '074.ann', '074.txt', '075.ann', '075.txt', '076.ann', '076.txt', '077.ann', '077.txt', '078.ann', '078.txt', '079.ann', '079.txt', '080.ann', '080.txt', '081.ann', '081.txt', '082.ann', '082.txt', '083.ann', '083.txt', '084.ann', '084.txt', '085.ann', '085.txt', '086.ann', '086.txt', '087.ann', '088.ann', '087.txt', '088.txt', '089.ann', '089.txt', '090.ann', '090.txt', '091.ann', '092.ann', '091.txt', '092.txt', '093.ann', '093.txt', '094.txt', '094.ann', '095.ann', '095.txt', '096.ann', '096.txt', '097.ann', '097.txt', '098.ann', '098.txt', '099.ann', '099.txt', '100.ann', '100.txt', '101.ann', '101.txt', '102.ann', '102.txt', '103.ann', '103.txt', '104.ann', '104.txt', '105.ann', '105.txt', '106.ann', '106.txt', '107.ann', '107.txt', '108.ann', '108.txt', '109.ann', '109.txt', '110.ann', '110.txt', '111.ann', '111.txt', '112.ann', '112.txt', '113.ann', '113.txt', '114.ann', '114.txt', '115.ann', '115.txt', '116.ann', '116.txt', '117.ann', '118.ann', '117.txt', '118.txt', '119.ann', '120.ann', '120.txt', '119.txt', '121.ann', '121.txt', '122.txt', '122.ann', '123.ann', '123.txt', '124.ann', '125.ann', '124.txt', '126.ann', '126.txt', '125.txt', '127.txt', '127.ann', '128.txt', '129.ann', '130.ann', '129.txt', '130.txt', '131.ann', '131.txt', '132.ann', '134.txt', '133.ann', '133.txt', '132.txt', '134.ann', '135.ann', '135.txt', '136.ann', '137.txt', '136.txt', '137.ann', '138.txt', '139.ann', '138.ann', '128.ann', '139.txt', '140.txt', '140.ann', '141.ann', '141.txt', '142.ann', '143.ann', '142.txt', '144.ann', '143.txt', '145.txt', '145.ann', '144.txt', '146.ann', '146.txt', '147.ann', '148.ann', '147.txt', '149.ann', '148.txt', '150.ann', '149.txt', '150.txt', '151.ann', '151.txt', '152.ann', '152.txt', '153.txt', '153.ann', '154.ann', '155.ann', '154.txt', '155.txt', '156.ann', '156.txt', '157.ann', '157.txt', '158.ann', '158.txt', '159.ann', '159.txt', '160.ann', '160.txt', '161.ann', '161.txt', '162.ann', '162.txt', '163.ann', '163.txt', '164.ann', '164.txt', '165.ann', '165.txt', '166.ann', '166.txt', '167.ann', '167.txt', '168.ann', '168.txt', '169.ann', '169.txt', '170.txt', '171.txt', '171.ann', '172.txt', '170.ann', '173.ann', '172.ann', '173.txt', '174.ann', '175.ann', '174.txt', '176.txt', '176.ann', '175.txt', '177.txt', '177.ann', '178.ann', '178.txt', '179.ann', '179.txt', '180.ann', '181.txt', '180.txt', '181.ann', '182.ann', '183.ann', '182.txt', '183.txt', '184.ann', '184.txt', '186.txt', '185.ann', '186.ann', '185.txt', '187.ann', '187.txt', '188.ann', '188.txt', '189.ann', '189.txt', '190.txt', '190.ann', '191.ann', '191.txt', '192.ann', '192.txt', '193.ann', '193.txt', '194.ann', '194.txt', '195.ann', '195.txt', '196.ann', '196.txt', '197.ann', '197.txt', '198.ann', '198.txt', '199.ann', '199.txt', '200.ann', '200.txt', '201.ann', '201.txt', '202.ann', '202.txt', '203.ann', '203.txt', '204.ann', '204.txt', '205.ann', '205.txt', '206.ann', '206.txt', '207.ann', '207.txt', '208.ann', '208.txt', '209.ann', '209.txt', '210.ann', '210.txt', '211.ann', '211.txt', '212.txt', '212.ann', '213.ann', '213.txt', '214.ann', '214.txt', '215.ann', '216.txt', '215.txt', '216.ann', '217.ann', '217.txt', '219.ann', '218.ann', '218.txt', '219.txt', '220.ann', '220.txt', '221.ann', '221.txt', '222.ann', '222.txt', '223.ann', '223.txt', '224.ann', '224.txt', '225.ann', '225.txt', '226.ann', '226.txt', '227.ann', '227.txt', '228.ann', '228.txt', '229.ann', '229.txt', '230.ann', '230.txt', '231.ann', '231.txt', '232.ann', '232.txt', '233.ann', '233.txt', '234.ann', '234.txt', '235.ann', '235.txt', '236.ann', '236.txt', '237.ann', '237.txt', '238.ann', '238.txt', '239.ann', '239.txt', '240.txt', '241.ann', '240.ann', '241.txt', '242.txt', '243.txt', '243.ann', '244.ann', '244.txt', '245.ann', '245.txt', '246.ann', '246.txt', '247.ann', '247.txt', '248.ann', '248.txt', '249.ann', '249.txt', '250.ann', '250.txt', '251.ann', '251.txt', '252.ann', '252.txt', '253.ann', '253.txt', '254.ann', '254.txt', '255.ann', '255.txt', '242.ann', '256.txt', '257.txt', '257.ann', '256.ann', '258.ann', '258.txt', '259.ann', '259.txt', '261.ann', '260.ann', '261.txt', '260.txt', '262.ann', '262.txt', '263.ann', '263.txt', '264.ann', '264.txt', '265.ann', '266.ann', '265.txt', '266.txt', '267.ann', '267.txt', '268.txt', '268.ann', '269.ann', '269.txt', '270.ann', '270.txt', '271.ann', '271.txt', '272.ann', '272.txt', '273.ann', '273.txt', '274.ann', '274.txt', '275.ann', '275.txt', '276.ann', '276.txt', '277.ann', '277.txt', '278.ann', '278.txt', '279.txt', '280.ann', '280.txt', '281.ann', '281.txt', '282.txt', '282.ann', '283.ann', '283.txt', '284.ann', '284.txt', '285.ann', '285.txt', '286.ann', '286.txt', '287.ann', '287.txt', '288.ann', '289.ann', '289.txt', '288.txt', '290.ann', '290.txt', '291.ann', '291.txt', '292.ann', '293.ann', '293.txt', '279.ann', '294.ann', '294.txt', '295.ann', '295.txt', '296.ann', '296.txt', '297.ann', '297.txt', '298.ann', '298.txt', '299.ann', '299.txt', '300.ann', '300.txt', '301.ann', '301.txt', '302.ann', '303.ann', '302.txt', '304.ann', '303.txt', '304.txt', '305.ann', '305.txt', '306.ann', '306.txt', '307.ann', '307.txt', '308.ann', '292.txt', '308.txt', '309.ann', '309.txt', '310.ann', '310.txt', '311.ann', '311.txt', '312.ann', '313.ann', '312.txt', '313.txt', '314.ann', '314.txt', '315.ann', '315.txt', '316.ann', '316.txt', '317.ann', '317.txt', '318.ann', '318.txt', '319.ann', '319.txt', '320.ann', '320.txt', '321.ann', '321.txt', '322.ann', '323.ann', '323.txt', '322.txt', '324.txt', '324.ann', '325.txt', '325.ann', '326.txt', '326.ann', '327.ann', '327.txt', '328.ann', '329.txt', '330.ann', '328.txt', '331.ann', '329.ann', '330.txt', '331.txt', '332.ann', '332.txt', '333.ann', '333.txt', '334.ann', '334.txt', '335.ann', '335.txt', '336.ann', '336.txt', '337.ann', '337.txt', '338.ann', '338.txt', '339.ann', '339.txt', '340.ann', '340.txt', '341.ann', '341.txt', '342.ann', '342.txt', '343.ann', '343.txt', '344.ann', '344.txt', '345.ann', '345.txt', '346.txt', '346.ann', '347.ann', '347.txt', '348.ann', '348.txt', '349.ann', '349.txt', '350.ann', '350.txt', '351.ann', '351.txt', '352.ann', '352.txt', '353.ann', '353.txt', '354.txt', '354.ann', '355.ann', '355.txt', '356.ann', '356.txt', '357.ann', '357.txt', '358.ann', '358.txt', '359.ann', '360.ann', '359.txt', '360.txt', '361.ann', '361.txt', '362.ann', '363.ann', '362.txt', '363.txt', '364.ann', '364.txt', '365.ann', '365.txt', '366.ann', '366.txt', '367.ann', '367.txt', '368.ann', '368.txt', '369.ann', '369.txt', '370.ann', '370.txt', '371.ann', '371.txt', '372.ann', '372.txt', '373.ann', '373.txt', '374.ann', '374.txt', '375.txt', '375.ann', '376.ann', '376.txt', '377.ann', '377.txt', '378.txt', '379.ann', '378.ann', '380.ann', '381.ann', '381.txt', '379.txt', '383.ann', '380.txt', '382.ann', '383.txt', '384.ann', '384.txt', '385.ann', '385.txt', '386.ann', '386.txt', '387.ann', '387.txt', '388.ann', '388.txt', '389.ann', '389.txt', '390.ann', '390.txt', '391.ann', '392.ann', '391.txt', '393.ann', '392.txt', '393.txt', '394.ann', '394.txt', '395.ann', '395.txt', '396.ann', '396.txt', '397.ann', '397.txt', '382.txt', '398.ann', '398.txt', '399.ann', '400.ann', '400.txt', '401.ann', '402.txt', '403.ann', '402.ann', '403.txt', '404.ann', '404.txt', '405.ann', '405.txt', '406.ann', '406.txt', '407.ann', '407.txt', '408.ann', '408.txt', '409.ann', '409.txt', '410.ann', '410.txt', '411.txt', '411.ann', '412.ann', '412.txt', '413.txt', '413.ann', '414.ann', '414.txt', '399.txt', '415.ann', '416.ann', '415.txt', '416.txt', '417.ann', '417.txt', '401.txt', '418.ann', '419.ann', '418.txt', '420.ann', '419.txt', '420.txt', '421.ann', '421.txt', '422.txt', '422.ann', '423.ann', '424.txt', '423.txt', '424.ann', '425.ann', '425.txt', '426.txt', '427.ann', '427.txt', '428.ann', '428.txt', '429.ann', '429.txt', '430.ann', '430.txt', '431.ann', '431.txt', '432.ann', '432.txt', '433.ann', '433.txt', '434.ann', '434.txt', '435.ann', '436.ann', '436.txt', '435.txt', '437.ann', '437.txt', '438.ann', '438.txt', '439.ann', '426.ann', '439.txt', '440.ann', '441.ann', '440.txt', '441.txt', '442.ann', '442.txt', '443.txt', '444.txt', '445.ann', '443.ann', '445.txt', '446.ann', '444.ann', '446.txt', '447.ann', '447.txt', '448.txt', '449.txt', '448.ann', '449.ann', '450.ann', '451.ann', '450.txt', '451.txt', '452.ann', '453.txt', '452.txt', '454.txt', '453.ann', '454.ann', '455.txt', '455.ann', '457.txt', '457.ann', '458.ann', '459.ann', '458.txt', '459.txt', '460.ann', '460.txt', '461.txt', '461.ann', '462.ann', '463.ann', '462.txt', '463.txt', '464.ann', '465.txt', '464.txt', '465.ann', '466.ann', '467.ann', '467.txt', '468.ann', '466.txt', '469.txt', '468.txt', '470.ann', '469.ann', '471.txt', '472.txt', '470.txt', '473.txt', '472.ann', '474.ann', '471.ann', '475.ann', '473.ann', '476.ann', '474.txt', '475.txt', '476.txt', '477.txt', '477.ann', '478.ann', '479.ann', '478.txt', '480.txt', '479.txt', '481.txt', '480.ann', '482.txt', '483.txt', '482.ann', '481.ann', '483.ann', '484.ann', '485.ann', '484.txt', '485.txt', '486.ann', '487.txt', '487.ann', '488.ann', '488.txt', '486.txt', '489.txt', '489.ann', '490.ann', '492.ann', '490.txt', '491.ann', '492.txt', '493.txt', '493.ann', '494.txt', '491.txt', '495.txt', '494.ann', '496.txt', '495.ann', '497.txt', '498.txt', '499.txt', '498.ann', '496.ann', '500.ann', '499.ann', '500.txt', '497.ann', '501.txt', '501.ann', '502.txt', '502.ann', '503.txt', '504.txt', '504.ann', '503.ann', '505.txt', '505.ann', '506.ann', '506.txt', '507.ann', '507.txt', '508.ann', '508.txt', '509.ann', '509.txt', '510.ann', '510.txt', '511.ann', '511.txt', '512.ann', '513.ann', '512.txt', '513.txt', '514.txt', '514.ann', '515.txt', '515.ann', '517.ann', '516.ann', '516.txt', '517.txt', '518.ann', '519.ann', '518.txt', '519.txt', '520.ann', '520.txt', '521.ann', '521.txt', '522.ann', '522.txt', '523.txt', '523.ann', '524.ann', '524.txt', '525.ann', '525.txt', '526.txt', '526.ann', '527.ann', '527.txt', '528.ann', '529.ann', '528.txt', '529.txt', '530.ann', '531.ann', '531.txt', '532.ann', '530.txt', '532.txt', '533 (!).ann', '533 (!).txt', '534.ann', '535.ann', '534.txt', '535.txt', '536.ann', '536.txt', '537.ann', '537.txt', '538.ann', '538.txt', '539.ann', '539.txt', '540.ann', '540.txt', '541.ann', '541.txt', '542.ann', '542.txt', '543.ann', '543.txt', '544.ann', '545.ann', '545.txt', '546.ann', '546.txt', '547.ann', '548.txt', '547.txt', '548.ann', '549.ann', '549.txt', '550.ann', '550.txt', '552.ann', '551.ann', '552.txt', '551.txt', '553.ann', '553.txt', '554.ann', '554.txt', '555 (!).ann', '555 (!).txt', '556.ann', '556.txt', '557.ann', '557.txt', '558.ann', '544.txt', '558.txt', '559.txt', '559.ann', '560.ann', '560.txt', '561.ann', '561.txt', '562.ann', '562.txt', '563.ann', '564.ann', '563.txt', '564.txt', '565.ann', '565.txt', '567.txt', '567.ann', '568.ann', '568.txt', '569.ann', '569.txt', '570.ann', '570.txt', '571.txt', '571.ann', '572.ann', '574.ann', '572.txt', '575.ann', '574.txt', '576.ann', '576.txt', '575.txt', '577.txt', '577.ann', '578.txt', '579.ann', '578.ann', '581.ann', '579.txt', '582.ann', '581.txt', '582.txt', '583.ann', '583.txt', '584 (!).ann', '584 (!).txt', '585.ann', '585.txt', '586.ann', '586.txt', '587.ann', '587.txt', '588.ann', '588.txt', '589.ann', '589.txt', '590.ann', '590.txt', '591.ann', '592.ann', '592.txt', '593.ann', '593.txt', '594.ann', '594.txt', '596.ann', '596.txt', '597.ann', '598 (!).ann', '598 (!).txt', '597.txt', '599.ann', '599.txt', '600.ann', '600.txt', '601.ann', '601.txt', '602.ann', '602.txt', '610.ann', '610.txt', '611.ann', '612.ann', '612.txt', '613.txt', '611.txt', '614.ann', '614.txt', '591.txt', '615.ann', '615.txt', '616.ann', '616.txt', '617.ann', '617.txt', '618.ann', '618.txt', '619.ann', '619.txt', '620.txt', '621.ann', '621.txt', '622.ann', '623.ann', '622.txt', '623.txt', '624.ann', '624.txt', '625.ann', '625.txt', '626.ann', '626.txt', '613.ann', '627.ann', '627.txt', '1150.ann', '620.ann', '1007.txt', '1042.ann', '1199.txt', '2002.txt', 'chaves.txt', 'last_03.ann', 'last_04.txt', 'last_43.ann']\n"
     ]
    }
   ],
   "source": [
    "# Просматриваем содержание коллекции\n",
    "print(os.listdir(\"collection3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aa5b099",
   "metadata": {
    "cellId": "ada8bcufjvjjo8ki02vmdb",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['003.txt', '03_12_12d.txt', '03_12_12c.txt', '03_12_12h.txt', '03_12_12g.txt', '03_12_12a.txt', '03_12_12b.txt', '004.txt', '04_12_12f.txt', '04_02_13a_abdulatipov.txt', '04_12_12g.txt', '04_12_12b.txt', '006.txt', '005.txt', '009.txt', '04_12_12h_corr.txt', '008.txt', '007.txt', '09_01_13a.txt', '09_01_13.txt', '04_03_13a_sorokin.txt', '09_01_13c.txt', '09_01_13e.txt', '09_01_13d.txt', '09_01_13h.txt', '010.txt', '09_01_13i.txt', '11_01_13b.txt', '11_01_13e.txt', '04_12_12d.txt', '10_01_13d.txt', '10_01_13i.txt', '013.txt', '10_01_13a.txt', '014.txt', '011.txt', '14_01_13g.txt', '012.txt', '15_01_13a.txt', '14_01_13c.txt', '015 (!).txt', '14_01_13i.txt', '15_01_13b.txt', '15_01_13e.txt', '017.txt', '016.txt', '15_01_13f.txt', '019.txt', '018.txt', '19_11_12d.txt', '020.txt', '19_11_12h.txt', '20_11_12a.txt', '20_11_12d.txt', '20_11_12b.txt', '20_11_12c.txt', '20_11_12i.txt', '021.txt', '21_11_12c.txt', '21_11_12h.txt', '21_11_12i.txt', '21_11_12j.txt', '022.txt', '22_11_12a.txt', '22_11_12c.txt', '22_11_12d.txt', '22_11_12g.txt', '22_11_12h.txt', '22_11_12i.txt', '22_11_12j.txt', '023.txt', '23_11_12a.txt', '23_11_12b.txt', '23_11_12c.txt', '23_11_12d.txt', '23_11_12e.txt', '23_11_12f.txt', '25_12_12a.txt', '25_12_12c.txt', '25_12_12d.txt', '25_12_12e.txt', '026.txt', '26_11_12b.txt', '26_11_12c.txt', '26_11_12e.txt', '26_11_12f.txt', '027.txt', '27_11_12a.txt', '27_11_12c.txt', '27_11_12d.txt', '27_11_12j.txt', '27_11_12e.txt', '028.txt', '025.txt', '28_11_12a.txt', '28_11_12f.txt', '28_11_12g.txt', '28_11_12h.txt', '28_11_12i.txt', '28_11_12j.txt', '029.txt', '29_11_12a.txt', '29_11_12b.txt', '030.txt', '30_11_12b.txt', '30_11_12h.txt', '30_11_12i.txt', '031.txt', '032.txt', '033.txt', '034.txt', '036.txt', '035.txt', '037.txt', '039.txt', '038.txt', '041.txt', '040.txt', '043.txt', '044.txt', '045.txt', '042.txt', '046.txt', '047.txt', '048.txt', '049.txt', '050.txt', '051.txt', '052.txt', '053.txt', '054.txt', '055.txt', '056.txt', '057.txt', '058.txt', '059.txt', '060.txt', '061.txt', '062.txt', '063.txt', '064.txt', '065.txt', '066.txt', '067.txt', '068.txt', '069.txt', '070.txt', '071.txt', '072.txt', '073.txt', '074.txt', '075.txt', '076.txt', '077.txt', '078.txt', '079.txt', '080.txt', '081.txt', '082.txt', '083.txt', '084.txt', '085.txt', '086.txt', '087.txt', '088.txt', '089.txt', '090.txt', '091.txt', '092.txt', '093.txt', '094.txt', '095.txt', '096.txt', '097.txt', '098.txt', '099.txt', '100.txt', '101.txt', '102.txt', '103.txt', '104.txt', '105.txt', '106.txt', '107.txt', '108.txt', '109.txt', '110.txt', '111.txt', '112.txt', '113.txt', '114.txt', '115.txt', '116.txt', '117.txt', '118.txt', '120.txt', '119.txt', '121.txt', '122.txt', '123.txt', '124.txt', '126.txt', '125.txt', '127.txt', '128.txt', '129.txt', '130.txt', '131.txt', '134.txt', '133.txt', '132.txt', '135.txt', '137.txt', '136.txt', '138.txt', '139.txt', '140.txt', '141.txt', '142.txt', '143.txt', '145.txt', '144.txt', '146.txt', '147.txt', '148.txt', '149.txt', '150.txt', '151.txt', '152.txt', '153.txt', '154.txt', '155.txt', '156.txt', '157.txt', '158.txt', '159.txt', '160.txt', '161.txt', '162.txt', '163.txt', '164.txt', '165.txt', '166.txt', '167.txt', '168.txt', '169.txt', '170.txt', '171.txt', '172.txt', '173.txt', '174.txt', '176.txt', '175.txt', '177.txt', '178.txt', '179.txt', '181.txt', '180.txt', '182.txt', '183.txt', '184.txt', '186.txt', '185.txt', '187.txt', '188.txt', '189.txt', '190.txt', '191.txt', '192.txt', '193.txt', '194.txt', '195.txt', '196.txt', '197.txt', '198.txt', '199.txt', '200.txt', '201.txt', '202.txt', '203.txt', '204.txt', '205.txt', '206.txt', '207.txt', '208.txt', '209.txt', '210.txt', '211.txt', '212.txt', '213.txt', '214.txt', '216.txt', '215.txt', '217.txt', '218.txt', '219.txt', '220.txt', '221.txt', '222.txt', '223.txt', '224.txt', '225.txt', '226.txt', '227.txt', '228.txt', '229.txt', '230.txt', '231.txt', '232.txt', '233.txt', '234.txt', '235.txt', '236.txt', '237.txt', '238.txt', '239.txt', '240.txt', '241.txt', '242.txt', '243.txt', '244.txt', '245.txt', '246.txt', '247.txt', '248.txt', '249.txt', '250.txt', '251.txt', '252.txt', '253.txt', '254.txt', '255.txt', '256.txt', '257.txt', '258.txt', '259.txt', '261.txt', '260.txt', '262.txt', '263.txt', '264.txt', '265.txt', '266.txt', '267.txt', '268.txt', '269.txt', '270.txt', '271.txt', '272.txt', '273.txt', '274.txt', '275.txt', '276.txt', '277.txt', '278.txt', '279.txt', '280.txt', '281.txt', '282.txt', '283.txt', '284.txt', '285.txt', '286.txt', '287.txt', '289.txt', '288.txt', '290.txt', '291.txt', '293.txt', '294.txt', '295.txt', '296.txt', '297.txt', '298.txt', '299.txt', '300.txt', '301.txt', '302.txt', '303.txt', '304.txt', '305.txt', '306.txt', '307.txt', '292.txt', '308.txt', '309.txt', '310.txt', '311.txt', '312.txt', '313.txt', '314.txt', '315.txt', '316.txt', '317.txt', '318.txt', '319.txt', '320.txt', '321.txt', '323.txt', '322.txt', '324.txt', '325.txt', '326.txt', '327.txt', '329.txt', '328.txt', '330.txt', '331.txt', '332.txt', '333.txt', '334.txt', '335.txt', '336.txt', '337.txt', '338.txt', '339.txt', '340.txt', '341.txt', '342.txt', '343.txt', '344.txt', '345.txt', '346.txt', '347.txt', '348.txt', '349.txt', '350.txt', '351.txt', '352.txt', '353.txt', '354.txt', '355.txt', '356.txt', '357.txt', '358.txt', '359.txt', '360.txt', '361.txt', '362.txt', '363.txt', '364.txt', '365.txt', '366.txt', '367.txt', '368.txt', '369.txt', '370.txt', '371.txt', '372.txt', '373.txt', '374.txt', '375.txt', '376.txt', '377.txt', '378.txt', '381.txt', '379.txt', '380.txt', '383.txt', '384.txt', '385.txt', '386.txt', '387.txt', '388.txt', '389.txt', '390.txt', '391.txt', '392.txt', '393.txt', '394.txt', '395.txt', '396.txt', '397.txt', '382.txt', '398.txt', '400.txt', '402.txt', '403.txt', '404.txt', '405.txt', '406.txt', '407.txt', '408.txt', '409.txt', '410.txt', '411.txt', '412.txt', '413.txt', '414.txt', '399.txt', '415.txt', '416.txt', '417.txt', '401.txt', '418.txt', '419.txt', '420.txt', '421.txt', '422.txt', '424.txt', '423.txt', '425.txt', '426.txt', '427.txt', '428.txt', '429.txt', '430.txt', '431.txt', '432.txt', '433.txt', '434.txt', '436.txt', '435.txt', '437.txt', '438.txt', '439.txt', '440.txt', '441.txt', '442.txt', '443.txt', '444.txt', '445.txt', '446.txt', '447.txt', '448.txt', '449.txt', '450.txt', '451.txt', '453.txt', '452.txt', '454.txt', '455.txt', '457.txt', '458.txt', '459.txt', '460.txt', '461.txt', '462.txt', '463.txt', '465.txt', '464.txt', '467.txt', '466.txt', '469.txt', '468.txt', '471.txt', '472.txt', '470.txt', '473.txt', '474.txt', '475.txt', '476.txt', '477.txt', '478.txt', '480.txt', '479.txt', '481.txt', '482.txt', '483.txt', '484.txt', '485.txt', '487.txt', '488.txt', '486.txt', '489.txt', '490.txt', '492.txt', '493.txt', '494.txt', '491.txt', '495.txt', '496.txt', '497.txt', '498.txt', '499.txt', '500.txt', '501.txt', '502.txt', '503.txt', '504.txt', '505.txt', '506.txt', '507.txt', '508.txt', '509.txt', '510.txt', '511.txt', '512.txt', '513.txt', '514.txt', '515.txt', '516.txt', '517.txt', '518.txt', '519.txt', '520.txt', '521.txt', '522.txt', '523.txt', '524.txt', '525.txt', '526.txt', '527.txt', '528.txt', '529.txt', '531.txt', '530.txt', '532.txt', '533 (!).txt', '534.txt', '535.txt', '536.txt', '537.txt', '538.txt', '539.txt', '540.txt', '541.txt', '542.txt', '543.txt', '545.txt', '546.txt', '548.txt', '547.txt', '549.txt', '550.txt', '552.txt', '551.txt', '553.txt', '554.txt', '555 (!).txt', '556.txt', '557.txt', '544.txt', '558.txt', '559.txt', '560.txt', '561.txt', '562.txt', '563.txt', '564.txt', '565.txt', '567.txt', '568.txt', '569.txt', '570.txt', '571.txt', '572.txt', '574.txt', '576.txt', '575.txt', '577.txt', '578.txt', '579.txt', '581.txt', '582.txt', '583.txt', '584 (!).txt', '585.txt', '586.txt', '587.txt', '588.txt', '589.txt', '590.txt', '592.txt', '593.txt', '594.txt', '596.txt', '598 (!).txt', '597.txt', '599.txt', '600.txt', '601.txt', '602.txt', '610.txt', '612.txt', '613.txt', '611.txt', '614.txt', '591.txt', '615.txt', '616.txt', '617.txt', '618.txt', '619.txt', '620.txt', '621.txt', '622.txt', '623.txt', '624.txt', '625.txt', '626.txt', '627.txt', '1007.txt', '1199.txt', '2002.txt', 'chaves.txt', 'last_04.txt']\n"
     ]
    }
   ],
   "source": [
    "# Собираем только текстовые файлы коллекции\n",
    "fileDir = r\"collection3\"\n",
    "fileExt = r\".txt\"\n",
    "documents_txt = [_ for _ in os.listdir(fileDir) if _.endswith(fileExt)]\n",
    "print(documents_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cf894ab",
   "metadata": {
    "cellId": "ldadxkenodgnu5d6330uu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Пулеметы, автоматы и снайперские винтовки изъя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Глава News International Т.Мокридж покидает св...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nОпрос РБК-Украина: Читатели уверены, что Аза...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Названы кандидаты на пост украинского премьера...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Из-за подчиненного-взяточника должностей лишил...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Эксперт пояснил, как текст про \"отставку\" Якун...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>Сванидзе не одобрил идею о выдвижении Сноудена...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Путин: Позиция Ирана на международной арене за...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Чавес назначил нового вице-президента\\nПрезиде...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Георгий Маргвелашвили будет президентом всей Г...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    Пулеметы, автоматы и снайперские винтовки изъя...\n",
       "1    Глава News International Т.Мокридж покидает св...\n",
       "2    \\nОпрос РБК-Украина: Читатели уверены, что Аза...\n",
       "3    Названы кандидаты на пост украинского премьера...\n",
       "4    Из-за подчиненного-взяточника должностей лишил...\n",
       "..                                                 ...\n",
       "692  Эксперт пояснил, как текст про \"отставку\" Якун...\n",
       "693  Сванидзе не одобрил идею о выдвижении Сноудена...\n",
       "694  Путин: Позиция Ирана на международной арене за...\n",
       "695  Чавес назначил нового вице-президента\\nПрезиде...\n",
       "696  Георгий Маргвелашвили будет президентом всей Г...\n",
       "\n",
       "[697 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Заносим данные файлов txt в датасет\n",
    "text_list = []\n",
    "for file in documents_txt:\n",
    "    doc = open('collection3/' + file, encoding='utf-8')\n",
    "    text = doc.read()\n",
    "    text_list.append(text)\n",
    "    \n",
    "data_text = pd.DataFrame({'text': text_list })\n",
    "data_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337d2b7",
   "metadata": {
    "cellId": "6w0x5nziwdr6cabfmerle",
    "execution_id": "2a49d0a1-45e8-4fa4-a7cc-329ad4a5d686"
   },
   "source": [
    "### <a id='NER_NLTK'>2.1 NER из NLTK</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e83882a6",
   "metadata": {
    "cellId": "qfa1v2pylepl1mb1g3ad3j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Требуется для токенизации\n",
    "nltk.download('punkt')\n",
    "# Требуется для parts of speech tagging\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf822b83",
   "metadata": {
    "cellId": "ftq4wh8ljc6duqzzt26rbj",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Пулеметы', 'NN'),\n",
       " (',', ','),\n",
       " ('автоматы', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('снайперские', 'NNP'),\n",
       " ('винтовки', 'NNP'),\n",
       " ('изъяты', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('арендуемом', 'NNP'),\n",
       " ('американцами', 'NNP'),\n",
       " ('доме', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('Бишкеке', 'VBD'),\n",
       " ('05/08/2008', 'CD'),\n",
       " ('10:35', 'CD'),\n",
       " ('БИШКЕК', 'NN'),\n",
       " (',', ','),\n",
       " ('5', 'CD'),\n",
       " ('августа', 'JJ'),\n",
       " ('/Новости-Грузия/', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Правоохранительные', 'JJ'),\n",
       " ('органы', 'JJ'),\n",
       " ('Киргизии', 'NN'),\n",
       " ('обнаружили', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('доме', 'NNP'),\n",
       " (',', ','),\n",
       " ('арендуемом', 'NNP'),\n",
       " ('гражданами', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('Бишкеке', 'NNP'),\n",
       " (',', ','),\n",
       " ('пулеметы', 'NNP'),\n",
       " (',', ','),\n",
       " ('автоматы', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('снайперские', 'NNP'),\n",
       " ('винтовки', 'NNP'),\n",
       " (',', ','),\n",
       " ('сообщает', 'NNP'),\n",
       " ('во', 'NNP'),\n",
       " ('вторник', 'NNP'),\n",
       " ('пресс-служба', 'JJ'),\n",
       " ('МВД', 'NNP'),\n",
       " ('Киргизии', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " ('В', 'JJ'),\n",
       " ('ходе', 'JJ'),\n",
       " ('проведения', 'JJ'),\n",
       " ('оперативно-профилактического', 'JJ'),\n",
       " ('мероприятия', 'NN'),\n",
       " ('под', 'NNP'),\n",
       " ('кодовым', 'NNP'),\n",
       " ('названием', 'NNP'),\n",
       " ('``', '``'),\n",
       " ('Арсенал', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('в', 'CC'),\n",
       " ('новостройке', 'NNP'),\n",
       " ('Ынтымак', 'NNP'),\n",
       " (',', ','),\n",
       " ('в', 'NNP'),\n",
       " ('доме', 'NNP'),\n",
       " (',', ','),\n",
       " ('принадлежащем', 'NNP'),\n",
       " ('66-летнему', 'CD'),\n",
       " ('гражданину', 'NNP'),\n",
       " ('Киргизии', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('арендуемом', 'NNP'),\n",
       " ('гражданами', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " (',', ','),\n",
       " ('обнаружены', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('изъяты', 'NN'),\n",
       " (':', ':'),\n",
       " ('шесть', 'JJ'),\n",
       " ('крупнокалиберных', 'NNP'),\n",
       " ('пулеметов', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('оптическим', 'NNP'),\n",
       " ('прицелом', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('приборами', 'NNP'),\n",
       " ('ночного', 'NNP'),\n",
       " ('видения', 'NNP'),\n",
       " (',', ','),\n",
       " ('26', 'CD'),\n",
       " ('автоматов', 'NN'),\n",
       " ('калибра', 'VBD'),\n",
       " ('5,56', 'CD'),\n",
       " ('миллиметра', 'NN'),\n",
       " (',', ','),\n",
       " ('два', 'NNP'),\n",
       " ('винчестера', 'NNP'),\n",
       " ('марки', 'NNP'),\n",
       " ('МОСВЕГА', 'NNP'),\n",
       " ('12-го', 'JJ'),\n",
       " ('калибра', 'NNP'),\n",
       " (',', ','),\n",
       " ('четыре', 'NNP'),\n",
       " ('ствола', 'NNP'),\n",
       " ('от', 'NNP'),\n",
       " ('крупнокалиберного', 'NNP'),\n",
       " ('пулемета', 'NNP'),\n",
       " (',', ','),\n",
       " ('два', 'NNP'),\n",
       " ('подствольных', 'NNP'),\n",
       " ('гранатомета', 'NNP'),\n",
       " (',', ','),\n",
       " ('четыре', 'NNP'),\n",
       " ('снайперские', 'NNP'),\n",
       " ('винтовки', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('оптическим', 'NNP'),\n",
       " ('прицелом', 'NNP'),\n",
       " ('защитного', 'NNP'),\n",
       " ('цвета', 'NNP'),\n",
       " (',', ','),\n",
       " ('шесть', 'NNP'),\n",
       " ('пистолетов', 'NNP'),\n",
       " ('калибра', 'VBD'),\n",
       " ('9', 'CD'),\n",
       " ('миллиметров', 'NNP'),\n",
       " ('марки', 'NNP'),\n",
       " ('Беретта', 'NNP'),\n",
       " (',', ','),\n",
       " ('одна', 'NNP'),\n",
       " ('винтовка', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " ('-', ':'),\n",
       " ('говорится', 'NN'),\n",
       " ('в', 'JJ'),\n",
       " ('сообщении', 'NNP'),\n",
       " ('МВД', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Пресс-служба', 'JJ'),\n",
       " ('отмечает', 'NN'),\n",
       " (',', ','),\n",
       " ('что', 'NNP'),\n",
       " ('на', 'NNP'),\n",
       " ('момент', 'NNP'),\n",
       " ('обыска', 'NNP'),\n",
       " ('``', '``'),\n",
       " ('в', 'NNP'),\n",
       " ('доме', 'NNP'),\n",
       " ('находились', 'NNP'),\n",
       " ('несколько', 'NNP'),\n",
       " ('сотрудников', 'NNP'),\n",
       " ('посольства', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " (',', ','),\n",
       " ('обладающих', 'NNP'),\n",
       " ('дипломатическим', 'NNP'),\n",
       " ('иммунитетом', 'NNP'),\n",
       " (',', ','),\n",
       " ('и', 'VBD'),\n",
       " ('10', 'CD'),\n",
       " ('военнослужащих', 'NN'),\n",
       " (',', ','),\n",
       " ('якобы', 'NNP'),\n",
       " ('прибывших', 'NNP'),\n",
       " ('из', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " ('для', 'NNP'),\n",
       " ('проведения', 'NNP'),\n",
       " ('тренинга', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('сотрудниками', 'NNP'),\n",
       " ('спецподразделения', 'NNP'),\n",
       " ('одной', 'NNP'),\n",
       " ('из', 'NNP'),\n",
       " ('силовых', 'NNP'),\n",
       " ('структур', 'NNP'),\n",
       " ('республики', 'NNP'),\n",
       " (',', ','),\n",
       " ('личности', 'NNP'),\n",
       " ('которых', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('настоящее', 'NNP'),\n",
       " ('время', 'NNP'),\n",
       " ('устанавливаются', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " ('.', '.'),\n",
       " ('Согласно', 'VB'),\n",
       " ('сообщению', 'NN'),\n",
       " (',', ','),\n",
       " ('в', 'NNP'),\n",
       " ('доме', 'NNP'),\n",
       " ('было', 'NNP'),\n",
       " ('обнаружено', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('значительное', 'NNP'),\n",
       " ('количество', 'NNP'),\n",
       " ('боеприпасов', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " ('Два', 'JJ'),\n",
       " ('ножа', 'NN'),\n",
       " (',', ','),\n",
       " ('2920', 'CD'),\n",
       " ('штук', 'NN'),\n",
       " ('патронов', 'NNP'),\n",
       " ('калибра', 'VBZ'),\n",
       " ('5,56', 'CD'),\n",
       " ('миллиметра', 'NN'),\n",
       " (',', ','),\n",
       " ('10556', 'CD'),\n",
       " ('штук', 'NN'),\n",
       " ('патронов', 'NNP'),\n",
       " ('калибра', 'VBZ'),\n",
       " ('9', 'CD'),\n",
       " ('миллиметров', 'NN'),\n",
       " (',', ','),\n",
       " ('два', 'NNP'),\n",
       " ('ящика', 'NNP'),\n",
       " ('патронов', 'NNP'),\n",
       " ('калибра', 'VBD'),\n",
       " ('50', 'CD'),\n",
       " ('миллиметров', 'NN'),\n",
       " (',', ','),\n",
       " ('в', 'NNP'),\n",
       " ('каждом', 'VBZ'),\n",
       " ('350', 'CD'),\n",
       " ('штук', 'NN'),\n",
       " (',', ','),\n",
       " ('патроны', 'NNP'),\n",
       " ('калибра', 'VBZ'),\n",
       " ('12', 'CD'),\n",
       " ('миллиметров', 'NN'),\n",
       " ('в', 'NNP'),\n",
       " ('количестве', 'VBZ'),\n",
       " ('478', 'CD'),\n",
       " ('штук', 'NN'),\n",
       " (',', ','),\n",
       " ('маркировочные', 'NNP'),\n",
       " ('(', '('),\n",
       " ('трассирующие', 'NNP'),\n",
       " (')', ')'),\n",
       " ('патроны', 'NN'),\n",
       " ('(', '('),\n",
       " ('красного', 'NNP'),\n",
       " ('цвета', 'NNP'),\n",
       " (')', ')'),\n",
       " ('1000', 'CD'),\n",
       " ('штук', 'NN'),\n",
       " (',', ','),\n",
       " ('66', 'CD'),\n",
       " ('штук', 'NN'),\n",
       " ('пустых', 'NNP'),\n",
       " ('магазинов', 'NNP'),\n",
       " ('от', 'NNP'),\n",
       " ('автоматического', 'NNP'),\n",
       " ('оружия', 'NNP'),\n",
       " (',', ','),\n",
       " ('57', 'CD'),\n",
       " ('штук', 'NN'),\n",
       " ('пустых', 'NNP'),\n",
       " ('магазинов', 'NNP'),\n",
       " ('от', 'NNP'),\n",
       " ('пистолета', 'NNP'),\n",
       " ('Беретта', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " ('-', ':'),\n",
       " ('говорится', 'NN'),\n",
       " ('в', 'JJ'),\n",
       " ('пресс-релизе', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Пресс-служба', 'JJ'),\n",
       " ('МВД', 'NN'),\n",
       " ('сообщила', 'NN'),\n",
       " (',', ','),\n",
       " ('что', 'NNP'),\n",
       " ('расследование', 'NNP'),\n",
       " ('по', 'NNP'),\n",
       " ('данному', 'NNP'),\n",
       " ('факту', 'NNP'),\n",
       " ('проводит', 'NNP'),\n",
       " ('прокуратура', 'NNP'),\n",
       " ('Бишкека', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Сейчас', 'NN'),\n",
       " ('выясняется', 'NN'),\n",
       " (',', ','),\n",
       " ('кому', 'NNP'),\n",
       " ('именно', 'NNP'),\n",
       " ('принадлежит', 'NNP'),\n",
       " ('изъятое', 'NNP'),\n",
       " ('оружие', 'NNP'),\n",
       " (',', ','),\n",
       " ('передает', 'NNP'),\n",
       " ('РИА', 'NNP'),\n",
       " ('Новости', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Оружие', 'NN'),\n",
       " (',', ','),\n",
       " ('изъятое', 'NNP'),\n",
       " ('у', 'NNP'),\n",
       " ('граждан', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " ('правоохранительными', 'NNP'),\n",
       " ('органами', 'NNP'),\n",
       " ('Киргизии', 'NNP'),\n",
       " (',', ','),\n",
       " ('находилось', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('республике', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('ведома', 'NNP'),\n",
       " ('правительства', 'NNP'),\n",
       " ('Киргизии', 'NNP'),\n",
       " (',', ','),\n",
       " ('сообщил', 'NNP'),\n",
       " ('во', 'NNP'),\n",
       " ('вторник', 'NNP'),\n",
       " ('представитель', 'NNP'),\n",
       " ('пресс-службы', 'JJ'),\n",
       " ('посольства', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " ('Все', 'JJ'),\n",
       " ('оборудование', 'NN'),\n",
       " ('находилось', 'NNP'),\n",
       " ('на', 'NNP'),\n",
       " ('территории', 'NNP'),\n",
       " ('Киргизии', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('ведома', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('разрешения', 'NNP'),\n",
       " ('киргизских', 'NNP'),\n",
       " ('властей', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " ('-', ':'),\n",
       " ('сказал', 'NN'),\n",
       " ('собеседник', 'JJ'),\n",
       " ('агентства', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Военнослужащие', 'VB'),\n",
       " ('и', 'JJ'),\n",
       " ('оружие', 'NNP'),\n",
       " ('``', '``'),\n",
       " ('прибыли', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('республику', 'NNP'),\n",
       " ('по', 'NNP'),\n",
       " ('приглашению', 'NNP'),\n",
       " ('правительства', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('целью', 'NNP'),\n",
       " ('обеспечения', 'NNP'),\n",
       " ('антитеррористических', 'NNP'),\n",
       " ('учений', 'NNP'),\n",
       " ('для', 'NNP'),\n",
       " ('министерств', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " ('заявило', 'NNP'),\n",
       " ('американское', 'NNP'),\n",
       " ('дипломатическое', 'NNP'),\n",
       " ('ведомство', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " ('Дом', 'JJ'),\n",
       " ('и', 'NN'),\n",
       " ('оборудование', 'NNP'),\n",
       " ('находились', 'NNP'),\n",
       " ('под', 'NNP'),\n",
       " ('защитой', 'NNP'),\n",
       " ('киргизских', 'NNP'),\n",
       " ('властей', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " ('-', ':'),\n",
       " ('отмечает', 'JJ'),\n",
       " ('пресс-служба', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Посольство', 'JJ'),\n",
       " ('США', 'JJ'),\n",
       " ('считает', 'NNP'),\n",
       " ('случившееся', 'NNP'),\n",
       " ('``', '``'),\n",
       " ('неприятным', 'FW'),\n",
       " ('инцидентом', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('и', 'CC'),\n",
       " ('выражает', 'NNP'),\n",
       " ('надежду', 'NNP'),\n",
       " ('что', 'NNP'),\n",
       " ('``', '``'),\n",
       " ('США', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('Киргизия', 'NNP'),\n",
       " ('могли', 'NNP'),\n",
       " ('бы', 'NNP'),\n",
       " ('продолжить', 'NNP'),\n",
       " ('усилия', 'NNP'),\n",
       " ('по', 'NNP'),\n",
       " ('улучшению', 'NNP'),\n",
       " ('антитеррористических', 'NNP'),\n",
       " ('возможностей', 'NNP'),\n",
       " ('Киргизии', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " ('.', '.'),\n",
       " ('Пресс-служба', 'JJ'),\n",
       " ('американской', 'JJ'),\n",
       " ('военной', 'NN'),\n",
       " ('базы', 'NNP'),\n",
       " ('расположенной', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('международном', 'NNP'),\n",
       " ('аэропорту', 'NNP'),\n",
       " ('``', '``'),\n",
       " ('Манас', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('столицы', 'CC'),\n",
       " ('Киргизии', 'NNP'),\n",
       " ('отказалась', 'NNP'),\n",
       " ('комментировать', 'NNP'),\n",
       " ('данный', 'NNP'),\n",
       " ('инцидент', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('участием', 'NNP'),\n",
       " ('американских', 'NNP'),\n",
       " ('военных', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " ('Всеми', 'JJ'),\n",
       " ('вопросами', 'NN'),\n",
       " (',', ','),\n",
       " ('связанными', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('данным', 'NNP'),\n",
       " ('случаем', 'NNP'),\n",
       " (',', ','),\n",
       " ('занимается', 'NNP'),\n",
       " ('посольство', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " ('-', ':'),\n",
       " ('сообщили', 'NN'),\n",
       " ('РИА', 'JJ'),\n",
       " ('Новости', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('пресс-службе', 'JJ'),\n",
       " ('базы', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример текста\n",
    "document = data_text.text[0]\n",
    "\n",
    "# Разбиваем документ на токены и применяем pos tagging (на выходе список кортежей (токен, часть речи))\n",
    "nltk.pos_tag(nltk.word_tokenize(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b75d2d0f",
   "metadata": {
    "cellId": "0i9ss4kfscxg0ma2izhslugc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('БИШКЕК', 'ORGANIZATION'),\n",
       " ('Киргизии', 'ORGANIZATION'),\n",
       " ('Киргизии', 'PERSON'),\n",
       " ('МВД', 'ORGANIZATION'),\n",
       " ('МВД Киргизии', 'ORGANIZATION'),\n",
       " ('Оружие', 'PERSON'),\n",
       " ('Пулеметы', 'GPE'),\n",
       " ('РИА Новости', 'ORGANIZATION'),\n",
       " ('США', 'ORGANIZATION'),\n",
       " ('Сейчас', 'PERSON')}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Распознаем именнованные сущности с помощью классификатора (Person, Organization, GPE)\n",
    "{(' '.join(c[0] for c in chunk), chunk.label()) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0dedf1d2",
   "metadata": {
    "cellId": "4z42krt5zbecpumntahuq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>LOC 82 89</th>\n",
       "      <th>Бишкеке</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2</td>\n",
       "      <td>LOC 113 119</td>\n",
       "      <td>БИШКЕК</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>ORG 132 146</td>\n",
       "      <td>Новости-Грузия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T4</td>\n",
       "      <td>LOC 175 183</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T5</td>\n",
       "      <td>LOC 225 228</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T6</td>\n",
       "      <td>LOC 231 238</td>\n",
       "      <td>Бишкеке</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T7</td>\n",
       "      <td>ORG 316 319</td>\n",
       "      <td>МВД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T8</td>\n",
       "      <td>LOC 320 328</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T9</td>\n",
       "      <td>LOC 492 500</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T10</td>\n",
       "      <td>LOC 525 528</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T11</td>\n",
       "      <td>ORG 955 958</td>\n",
       "      <td>МВД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T12</td>\n",
       "      <td>LOC 1059 1062</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T13</td>\n",
       "      <td>LOC 1144 1147</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T14</td>\n",
       "      <td>ORG 1804 1807</td>\n",
       "      <td>МВД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T15</td>\n",
       "      <td>LOC 1874 1881</td>\n",
       "      <td>Бишкека</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T16</td>\n",
       "      <td>ORG 1951 1962</td>\n",
       "      <td>РИА Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T17</td>\n",
       "      <td>LOC 1993 1996</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T18</td>\n",
       "      <td>LOC 2026 2034</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T19</td>\n",
       "      <td>LOC 2083 2091</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>T20</td>\n",
       "      <td>LOC 2150 2153</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>T21</td>\n",
       "      <td>LOC 2201 2209</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>T22</td>\n",
       "      <td>LOC 2579 2582</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>T23</td>\n",
       "      <td>LOC 2651 2654</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>T24</td>\n",
       "      <td>LOC 2657 2665</td>\n",
       "      <td>Киргизия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>T25</td>\n",
       "      <td>LOC 2740 2748</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>T26</td>\n",
       "      <td>ORG 2833 2840</td>\n",
       "      <td>Манас</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>T27</td>\n",
       "      <td>LOC 2849 2857</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>T28</td>\n",
       "      <td>LOC 3005 3008</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>T29</td>\n",
       "      <td>ORG 3022 3033</td>\n",
       "      <td>РИА Новости</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T1      LOC 82 89         Бишкеке\n",
       "0    T2    LOC 113 119          БИШКЕК\n",
       "1    T3    ORG 132 146  Новости-Грузия\n",
       "2    T4    LOC 175 183        Киргизии\n",
       "3    T5    LOC 225 228             США\n",
       "4    T6    LOC 231 238         Бишкеке\n",
       "5    T7    ORG 316 319             МВД\n",
       "6    T8    LOC 320 328        Киргизии\n",
       "7    T9    LOC 492 500        Киргизии\n",
       "8   T10    LOC 525 528             США\n",
       "9   T11    ORG 955 958             МВД\n",
       "10  T12  LOC 1059 1062             США\n",
       "11  T13  LOC 1144 1147             США\n",
       "12  T14  ORG 1804 1807             МВД\n",
       "13  T15  LOC 1874 1881         Бишкека\n",
       "14  T16  ORG 1951 1962     РИА Новости\n",
       "15  T17  LOC 1993 1996             США\n",
       "16  T18  LOC 2026 2034        Киргизии\n",
       "17  T19  LOC 2083 2091        Киргизии\n",
       "18  T20  LOC 2150 2153             США\n",
       "19  T21  LOC 2201 2209        Киргизии\n",
       "20  T22  LOC 2579 2582             США\n",
       "21  T23  LOC 2651 2654             США\n",
       "22  T24  LOC 2657 2665        Киргизия\n",
       "23  T25  LOC 2740 2748        Киргизии\n",
       "24  T26  ORG 2833 2840           Манас\n",
       "25  T27  LOC 2849 2857        Киргизии\n",
       "26  T28  LOC 3005 3008             США\n",
       "27  T29  ORG 3022 3033     РИА Новости"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Разметка из collection3\n",
    "pd.read_csv('collection3/003.ann', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0102470d",
   "metadata": {
    "cellId": "o0g45rl7hxihqoymx438et",
    "execution_id": "f2da204c-58c4-48f1-b130-4cebe15c24d6"
   },
   "source": [
    "**Вывод:** NER из nltk нашла все сущности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a563141f",
   "metadata": {
    "cellId": "p5pycb4l9xbxhqrsqg91l",
    "execution_id": "f0b87f48-6ce6-4c03-80af-3b39bd56ea2c"
   },
   "source": [
    "### <a id='NER_Spacy'>2.2 NER из Spacy</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d609ecab",
   "metadata": {
    "cellId": "bn47vmrk53bfg4g12nlgio"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Пулеметы, автоматы и снайперские винтовки изъяты в арендуемом американцами доме в \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Бишкеке\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "</br></br>05/08/2008 10:35</br></br>БИШКЕК, 5 августа /Новости-Грузия/. Правоохранительные органы \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Киргизии\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " обнаружили в доме, арендуемом гражданами \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " в \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Бишкеке\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", пулеметы, автоматы и снайперские винтовки, сообщает во вторник пресс-служба \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    МВД\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Киргизии\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</br></br>&quot;В ходе проведения оперативно-профилактического мероприятия под кодовым названием &quot;\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Арсенал\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "&quot; в новостройке \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ынтымак\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", в доме, принадлежащем 66-летнему гражданину \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Киргизии\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " и арендуемом гражданами \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", обнаружены и изъяты: шесть крупнокалиберных пулеметов с оптическим прицелом и с приборами ночного видения, 26 автоматов калибра 5,56 миллиметра, два винчестера марки МОСВЕГА 12-го калибра, четыре ствола от крупнокалиберного пулемета, два подствольных гранатомета, четыре снайперские винтовки с оптическим прицелом защитного цвета, шесть пистолетов калибра 9 миллиметров марки \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Беретта\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", одна винтовка&quot;, - говорится в сообщении \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    МВД\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</br></br>Пресс-служба отмечает, что на момент обыска &quot;в доме находились несколько сотрудников посольства \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", обладающих дипломатическим иммунитетом, и 10 военнослужащих, якобы прибывших из \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " для проведения тренинга с сотрудниками спецподразделения одной из силовых структур республики, личности которых в настоящее время устанавливаются&quot;.</br></br>Согласно сообщению, в доме было обнаружено и значительное количество боеприпасов. &quot;Два ножа, 2920 штук патронов калибра 5,56 миллиметра, 10556 штук патронов калибра 9 миллиметров, два ящика патронов калибра 50 миллиметров, в каждом 350 штук, патроны калибра 12 миллиметров в количестве 478 штук, маркировочные (трассирующие) патроны (красного цвета) 1000 штук, 66 штук пустых магазинов от автоматического оружия, 57 штук пустых магазинов от пистолета Беретта&quot;, - говорится в пресс-релизе.</br></br>Пресс-служба \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    МВД\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " сообщила, что расследование по данному факту проводит прокуратура \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Бишкека\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". Сейчас выясняется, кому именно принадлежит изъятое оружие, передает \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    РИА Новости\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</br></br>Оружие, изъятое у граждан \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " правоохранительными органами \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Киргизии\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", находилось в республике с ведома правительства \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Киргизии\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", сообщил во вторник представитель пресс-службы посольства \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</br></br>&quot;Все оборудование находилось на территории \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Киргизии\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " с ведома и разрешения киргизских властей&quot;, - сказал собеседник агентства. Военнослужащие и оружие &quot;прибыли в республику по приглашению правительства с целью обеспечения антитеррористических учений для министерств&quot;, заявило американское дипломатическое ведомство.</br></br>&quot;Дом и оборудование находились под защитой киргизских властей&quot;, - отмечает пресс-служба.</br></br>Посольство \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " считает случившееся &quot;неприятным инцидентом&quot; и выражает надежду что &quot;\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " и \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Киргизия\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " могли бы продолжить усилия по улучшению антитеррористических возможностей \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Киргизии\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "&quot;.</br></br>Пресс-служба американской военной базы расположенной в международном аэропорту &quot;\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Манас\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "&quot; столицы \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Киргизии\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " отказалась комментировать данный инцидент с участием американских военных.</br></br>&quot;Всеми вопросами, связанными с данным случаем, занимается посольство \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "&quot;, - сообщили \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    РИА Новости\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " в пресс-службе базы.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = ru_core_news_sm.load()\n",
    "ny_bb = data_text.text[0]\n",
    "article = nlp(ny_bb)\n",
    "displacy.render(article, jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "880e5645",
   "metadata": {
    "cellId": "ecl5m9b5qclzcy6w6poh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пулеметы NOUN nsubj:pass\n",
      ", PUNCT punct\n",
      "автоматы NOUN conj\n",
      "и CCONJ cc\n",
      "снайперские ADJ amod\n",
      "винтовки NOUN conj\n",
      "изъяты VERB ROOT\n",
      "в ADP case\n",
      "арендуемом ADJ amod\n",
      "американцами NOUN amod\n",
      "доме NOUN obl\n",
      "в ADP case\n",
      "Бишкеке PROPN nmod\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "05/08/2008 NUM appos\n",
      "10:35 NUM appos\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "БИШКЕК PROPN obl\n",
      ", PUNCT punct\n",
      "5 ADJ obl\n",
      "августа NOUN flat\n",
      "/Новости NOUN obj\n",
      "- NOUN obj\n",
      "Грузия/. PROPN obj\n",
      "Правоохранительные ADJ amod\n",
      "органы NOUN nsubj\n",
      "Киргизии PROPN nmod\n",
      "обнаружили VERB conj\n",
      "в ADP case\n",
      "доме NOUN obl\n",
      ", PUNCT punct\n",
      "арендуемом VERB acl\n",
      "гражданами NOUN obl:agent\n",
      "США PROPN nmod\n",
      "в ADP case\n",
      "Бишкеке PROPN nmod\n",
      ", PUNCT punct\n",
      "пулеметы NOUN conj\n",
      ", PUNCT punct\n",
      "автоматы NOUN conj\n",
      "и CCONJ cc\n",
      "снайперские ADJ amod\n",
      "винтовки NOUN conj\n",
      ", PUNCT punct\n",
      "сообщает VERB parataxis\n",
      "во ADP case\n",
      "вторник NOUN obl\n",
      "пресс NOUN nsubj\n",
      "- NOUN nsubj\n",
      "служба NOUN nsubj\n",
      "МВД PROPN nmod\n",
      "Киргизии PROPN nmod\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "\" PUNCT punct\n",
      "В ADP case\n",
      "ходе NOUN fixed\n",
      "проведения NOUN obl\n",
      "оперативно ADJ amod\n",
      "- ADJ amod\n",
      "профилактического ADJ amod\n",
      "мероприятия NOUN nmod\n",
      "под ADP case\n",
      "кодовым ADJ amod\n",
      "названием NOUN nmod\n",
      "\" PUNCT punct\n",
      "Арсенал NOUN appos\n",
      "\" PUNCT punct\n",
      "в ADP case\n",
      "новостройке NOUN nmod\n",
      "Ынтымак PROPN appos\n",
      ", PUNCT punct\n",
      "в ADP case\n",
      "доме NOUN obl\n",
      ", PUNCT punct\n",
      "принадлежащем VERB acl\n",
      "66-летнему ADJ amod\n",
      "гражданину NOUN iobj\n",
      "Киргизии PROPN nmod\n",
      "и CCONJ cc\n",
      "арендуемом VERB amod\n",
      "гражданами NOUN conj\n",
      "США PROPN nmod\n",
      ", PUNCT punct\n",
      "обнаружены VERB ROOT\n",
      "и CCONJ cc\n",
      "изъяты VERB conj\n",
      ": PUNCT punct\n",
      "шесть NUM nummod:gov\n",
      "крупнокалиберных ADJ amod\n",
      "пулеметов NOUN parataxis\n",
      "с ADP case\n",
      "оптическим ADJ amod\n",
      "прицелом NOUN nmod\n",
      "и CCONJ cc\n",
      "с ADP case\n",
      "приборами NOUN conj\n",
      "ночного ADJ amod\n",
      "видения NOUN nmod\n",
      ", PUNCT punct\n",
      "26 NUM nummod\n",
      "автоматов NOUN conj\n",
      "калибра NOUN nmod\n",
      "5,56 NUM nummod\n",
      "миллиметра NOUN nmod\n",
      ", PUNCT punct\n",
      "два NUM nummod:gov\n",
      "винчестера NOUN conj\n",
      "марки NOUN nmod\n",
      "МОСВЕГА PROPN appos\n",
      "12-го ADJ amod\n",
      "калибра NOUN nmod\n",
      ", PUNCT punct\n",
      "четыре NUM nummod:gov\n",
      "ствола NOUN conj\n",
      "от ADP case\n",
      "крупнокалиберного ADJ amod\n",
      "пулемета NOUN nmod\n",
      ", PUNCT punct\n",
      "два NUM nummod:gov\n",
      "подствольных ADJ amod\n",
      "гранатомета NOUN conj\n",
      ", PUNCT punct\n",
      "четыре NUM nummod:gov\n",
      "снайперские ADJ amod\n",
      "винтовки NOUN conj\n",
      "с ADP case\n",
      "оптическим ADJ amod\n",
      "прицелом NOUN nmod\n",
      "защитного ADJ amod\n",
      "цвета NOUN nmod\n",
      ", PUNCT punct\n",
      "шесть NUM nummod:gov\n",
      "пистолетов NOUN conj\n",
      "калибра NOUN nmod\n",
      "9 NUM nummod\n",
      "миллиметров NOUN nmod\n",
      "марки NOUN nmod\n",
      "Беретта PROPN appos\n",
      ", PUNCT punct\n",
      "одна NUM nummod\n",
      "винтовка NOUN conj\n",
      "\" PUNCT punct\n",
      ", PUNCT punct\n",
      "- PUNCT punct\n",
      "говорится VERB parataxis\n",
      "в ADP case\n",
      "сообщении NOUN obl\n",
      "МВД PROPN nmod\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "Пресс NOUN nsubj\n",
      "- NOUN nsubj\n",
      "служба NOUN nsubj\n",
      "отмечает VERB ROOT\n",
      ", PUNCT punct\n",
      "что SCONJ mark\n",
      "на ADP case\n",
      "момент NOUN obl\n",
      "обыска NOUN nmod\n",
      "\" PUNCT punct\n",
      "в ADP case\n",
      "доме NOUN obl\n",
      "находились VERB ccomp\n",
      "несколько NUM nummod:gov\n",
      "сотрудников NOUN nsubj\n",
      "посольства NOUN nmod\n",
      "США PROPN nmod\n",
      ", PUNCT punct\n",
      "обладающих VERB acl\n",
      "дипломатическим ADJ amod\n",
      "иммунитетом NOUN obj\n",
      ", PUNCT punct\n",
      "и CCONJ cc\n",
      "10 NUM nummod\n",
      "военнослужащих NOUN conj\n",
      ", PUNCT punct\n",
      "якобы ADV advmod\n",
      "прибывших VERB acl\n",
      "из ADP case\n",
      "США PROPN obl\n",
      "для ADP case\n",
      "проведения NOUN obl\n",
      "тренинга NOUN nmod\n",
      "с ADP case\n",
      "сотрудниками NOUN nmod\n",
      "спецподразделения NOUN nmod\n",
      "одной NUM nmod\n",
      "из ADP case\n",
      "силовых ADJ amod\n",
      "структур NOUN nmod\n",
      "республики NOUN nmod\n",
      ", PUNCT punct\n",
      "личности NOUN nsubj:pass\n",
      "которых PRON nmod\n",
      "в ADV advmod\n",
      "настоящее ADJ fixed\n",
      "время NOUN fixed\n",
      "устанавливаются VERB acl:relcl\n",
      "\" PUNCT punct\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "Согласно ADP case\n",
      "сообщению NOUN parataxis\n",
      ", PUNCT punct\n",
      "в ADP case\n",
      "доме NOUN obl\n",
      "было AUX aux:pass\n",
      "обнаружено VERB ROOT\n",
      "и PART advmod\n",
      "значительное ADJ amod\n",
      "количество NOUN nsubj:pass\n",
      "боеприпасов NOUN nmod\n",
      ". PUNCT punct\n",
      "\" PUNCT punct\n",
      "Два NUM nummod:gov\n",
      "ножа NOUN ROOT\n",
      ", PUNCT punct\n",
      "2920 NUM nummod\n",
      "штук NOUN conj\n",
      "патронов NOUN nmod\n",
      "калибра NOUN nmod\n",
      "5,56 NUM nummod\n",
      "миллиметра NOUN nmod\n",
      ", PUNCT punct\n",
      "10556 NUM nummod\n",
      "штук NOUN conj\n",
      "патронов NOUN nmod\n",
      "калибра NOUN nmod\n",
      "9 NUM nummod\n",
      "миллиметров NOUN nmod\n",
      ", PUNCT punct\n",
      "два NUM nummod:gov\n",
      "ящика NOUN conj\n",
      "патронов NOUN nmod\n",
      "калибра NOUN nmod\n",
      "50 NUM nummod\n",
      "миллиметров NOUN nmod\n",
      ", PUNCT punct\n",
      "в ADP case\n",
      "каждом DET det\n",
      "350 NUM nummod\n",
      "штук NOUN conj\n",
      ", PUNCT punct\n",
      "патроны NOUN conj\n",
      "калибра NOUN nmod\n",
      "12 NUM nummod\n",
      "миллиметров NOUN nmod\n",
      "в ADP case\n",
      "количестве NOUN nmod\n",
      "478 NUM nummod\n",
      "штук NOUN nmod\n",
      ", PUNCT punct\n",
      "маркировочные ADJ amod\n",
      "( PUNCT punct\n",
      "трассирующие VERB appos\n",
      ") PUNCT punct\n",
      "патроны NOUN conj\n",
      "( PUNCT punct\n",
      "красного ADJ amod\n",
      "цвета NOUN parataxis\n",
      ") PUNCT punct\n",
      "1000 NUM nummod\n",
      "штук NOUN nmod\n",
      ", PUNCT punct\n",
      "66 NUM nummod\n",
      "штук NOUN conj\n",
      "пустых ADJ amod\n",
      "магазинов NOUN nmod\n",
      "от ADP case\n",
      "автоматического ADJ amod\n",
      "оружия NOUN nmod\n",
      ", PUNCT punct\n",
      "57 NUM nummod\n",
      "штук NOUN conj\n",
      "пустых ADJ amod\n",
      "магазинов NOUN nmod\n",
      "от ADP case\n",
      "пистолета NOUN nmod\n",
      "Беретта PROPN nmod\n",
      "\" PUNCT punct\n",
      ", PUNCT punct\n",
      "- PUNCT punct\n",
      "говорится VERB parataxis\n",
      "в ADP case\n",
      "пресс NOUN obl\n",
      "- NOUN obl\n",
      "релизе NOUN obl\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "Пресс NOUN nsubj\n",
      "- NOUN nsubj\n",
      "служба NOUN nsubj\n",
      "МВД PROPN nmod\n",
      "сообщила VERB ROOT\n",
      ", PUNCT punct\n",
      "что SCONJ mark\n",
      "расследование NOUN obj\n",
      "по ADP case\n",
      "данному ADJ amod\n",
      "факту NOUN nmod\n",
      "проводит VERB ccomp\n",
      "прокуратура NOUN nsubj\n",
      "Бишкека PROPN nmod\n",
      ". PUNCT punct\n",
      "Сейчас ADV advmod\n",
      "выясняется VERB ROOT\n",
      ", PUNCT punct\n",
      "кому PRON iobj\n",
      "именно PART advmod\n",
      "принадлежит VERB ccomp\n",
      "изъятое VERB amod\n",
      "оружие NOUN nsubj\n",
      ", PUNCT punct\n",
      "передает VERB parataxis\n",
      "РИА PROPN nsubj\n",
      "Новости PROPN appos\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "Оружие NOUN nsubj\n",
      ", PUNCT punct\n",
      "изъятое VERB acl\n",
      "у ADP case\n",
      "граждан NOUN obl\n",
      "США PROPN nmod\n",
      "правоохранительными ADJ amod\n",
      "органами NOUN obl\n",
      "Киргизии PROPN nmod\n",
      ", PUNCT punct\n",
      "находилось VERB ROOT\n",
      "в ADP case\n",
      "республике NOUN obl\n",
      "с ADP case\n",
      "ведома NOUN obl\n",
      "правительства NOUN nmod\n",
      "Киргизии PROPN nmod\n",
      ", PUNCT punct\n",
      "сообщил VERB parataxis\n",
      "во ADP case\n",
      "вторник NOUN obl\n",
      "представитель NOUN nsubj\n",
      "пресс NOUN nmod\n",
      "- NOUN nmod\n",
      "службы NOUN nmod\n",
      "посольства NOUN nmod\n",
      "США PROPN nmod\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "\" PUNCT punct\n",
      "Все DET det\n",
      "оборудование NOUN nsubj\n",
      "находилось VERB ROOT\n",
      "на ADP case\n",
      "территории NOUN obl\n",
      "Киргизии PROPN nmod\n",
      "с ADP case\n",
      "ведома NOUN obl\n",
      "и CCONJ cc\n",
      "разрешения NOUN conj\n",
      "киргизских ADJ amod\n",
      "властей NOUN nmod\n",
      "\" PUNCT punct\n",
      ", PUNCT punct\n",
      "- PUNCT punct\n",
      "сказал VERB parataxis\n",
      "собеседник NOUN nsubj\n",
      "агентства NOUN nmod\n",
      ". PUNCT punct\n",
      "Военнослужащие NOUN nsubj\n",
      "и CCONJ cc\n",
      "оружие NOUN conj\n",
      "\" PUNCT punct\n",
      "прибыли VERB ROOT\n",
      "в ADP case\n",
      "республику NOUN obl\n",
      "по ADP case\n",
      "приглашению NOUN obl\n",
      "правительства NOUN nmod\n",
      "с ADP case\n",
      "целью NOUN obl\n",
      "обеспечения NOUN nmod\n",
      "антитеррористических ADJ amod\n",
      "учений NOUN nmod\n",
      "для ADP case\n",
      "министерств NOUN nmod\n",
      "\" PUNCT punct\n",
      ", PUNCT punct\n",
      "заявило VERB parataxis\n",
      "американское ADJ amod\n",
      "дипломатическое ADJ amod\n",
      "ведомство NOUN nsubj\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "\" PUNCT punct\n",
      "Дом NOUN nsubj\n",
      "и CCONJ cc\n",
      "оборудование NOUN conj\n",
      "находились VERB ROOT\n",
      "под ADP case\n",
      "защитой NOUN obl\n",
      "киргизских ADJ amod\n",
      "властей NOUN nmod\n",
      "\" PUNCT punct\n",
      ", PUNCT punct\n",
      "- PUNCT punct\n",
      "отмечает VERB parataxis\n",
      "пресс NOUN nsubj\n",
      "- NOUN nsubj\n",
      "служба NOUN nsubj\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "Посольство NOUN nsubj\n",
      "США PROPN nmod\n",
      "считает VERB ROOT\n",
      "случившееся VERB xcomp\n",
      "\" PUNCT punct\n",
      "неприятным ADJ amod\n",
      "инцидентом NOUN xcomp\n",
      "\" PUNCT punct\n",
      "и CCONJ cc\n",
      "выражает VERB conj\n",
      "надежду NOUN obj\n",
      "что SCONJ mark\n",
      "\" PUNCT punct\n",
      "США PROPN nsubj\n",
      "и CCONJ cc\n",
      "Киргизия PROPN conj\n",
      "могли VERB acl\n",
      "бы AUX aux\n",
      "продолжить VERB xcomp\n",
      "усилия NOUN obj\n",
      "по ADP case\n",
      "улучшению NOUN nmod\n",
      "антитеррористических ADJ amod\n",
      "возможностей NOUN nmod\n",
      "Киргизии PROPN nmod\n",
      "\" PUNCT punct\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "Пресс NOUN nsubj\n",
      "- NOUN nsubj\n",
      "служба NOUN nsubj\n",
      "американской ADJ amod\n",
      "военной ADJ amod\n",
      "базы NOUN nmod\n",
      "расположенной ADJ amod\n",
      "в ADP case\n",
      "международном ADJ amod\n",
      "аэропорту NOUN nmod\n",
      "\" PUNCT punct\n",
      "Манас PROPN appos\n",
      "\" PUNCT punct\n",
      "столицы NOUN nmod\n",
      "Киргизии PROPN nmod\n",
      "отказалась VERB ROOT\n",
      "комментировать VERB xcomp\n",
      "данный ADJ amod\n",
      "инцидент NOUN obj\n",
      "с ADP case\n",
      "участием NOUN nmod\n",
      "американских ADJ amod\n",
      "военных NOUN nmod\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "\" PUNCT punct\n",
      "Всеми DET det\n",
      "вопросами NOUN obl\n",
      ", PUNCT punct\n",
      "связанными VERB acl\n",
      "с ADP case\n",
      "данным ADJ amod\n",
      "случаем NOUN obl\n",
      ", PUNCT punct\n",
      "занимается VERB ROOT\n",
      "посольство NOUN nsubj\n",
      "США PROPN nmod\n",
      "\" PUNCT punct\n",
      ", PUNCT punct\n",
      "- PUNCT punct\n",
      "сообщили VERB parataxis\n",
      "РИА PROPN iobj\n",
      "Новости PROPN appos\n",
      "в ADP case\n",
      "пресс NOUN obl\n",
      "- NOUN obl\n",
      "службе NOUN obl\n",
      "базы NOUN nmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "# Список токенов, частей речи и сущностей\n",
    "for token in article:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cc8aa5f",
   "metadata": {
    "cellId": "7mi0fehi6so0bpvx08j043d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>LOC 82 89</td>\n",
       "      <td>Бишкеке</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>LOC 113 119</td>\n",
       "      <td>БИШКЕК</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>ORG 132 146</td>\n",
       "      <td>Новости-Грузия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>LOC 175 183</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>LOC 225 228</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>LOC 231 238</td>\n",
       "      <td>Бишкеке</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T7</td>\n",
       "      <td>ORG 316 319</td>\n",
       "      <td>МВД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T8</td>\n",
       "      <td>LOC 320 328</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T9</td>\n",
       "      <td>LOC 492 500</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T10</td>\n",
       "      <td>LOC 525 528</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T11</td>\n",
       "      <td>ORG 955 958</td>\n",
       "      <td>МВД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T12</td>\n",
       "      <td>LOC 1059 1062</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T13</td>\n",
       "      <td>LOC 1144 1147</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T14</td>\n",
       "      <td>ORG 1804 1807</td>\n",
       "      <td>МВД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T15</td>\n",
       "      <td>LOC 1874 1881</td>\n",
       "      <td>Бишкека</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T16</td>\n",
       "      <td>ORG 1951 1962</td>\n",
       "      <td>РИА Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T17</td>\n",
       "      <td>LOC 1993 1996</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T18</td>\n",
       "      <td>LOC 2026 2034</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>T19</td>\n",
       "      <td>LOC 2083 2091</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>T20</td>\n",
       "      <td>LOC 2150 2153</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>T21</td>\n",
       "      <td>LOC 2201 2209</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>T22</td>\n",
       "      <td>LOC 2579 2582</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>T23</td>\n",
       "      <td>LOC 2651 2654</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>T24</td>\n",
       "      <td>LOC 2657 2665</td>\n",
       "      <td>Киргизия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>T25</td>\n",
       "      <td>LOC 2740 2748</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>T26</td>\n",
       "      <td>ORG 2833 2840</td>\n",
       "      <td>Манас</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>T27</td>\n",
       "      <td>LOC 2849 2857</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>T28</td>\n",
       "      <td>LOC 3005 3008</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>T29</td>\n",
       "      <td>ORG 3022 3033</td>\n",
       "      <td>РИА Новости</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0              1               2\n",
       "0    T1      LOC 82 89         Бишкеке\n",
       "1    T2    LOC 113 119          БИШКЕК\n",
       "2    T3    ORG 132 146  Новости-Грузия\n",
       "3    T4    LOC 175 183        Киргизии\n",
       "4    T5    LOC 225 228             США\n",
       "5    T6    LOC 231 238         Бишкеке\n",
       "6    T7    ORG 316 319             МВД\n",
       "7    T8    LOC 320 328        Киргизии\n",
       "8    T9    LOC 492 500        Киргизии\n",
       "9   T10    LOC 525 528             США\n",
       "10  T11    ORG 955 958             МВД\n",
       "11  T12  LOC 1059 1062             США\n",
       "12  T13  LOC 1144 1147             США\n",
       "13  T14  ORG 1804 1807             МВД\n",
       "14  T15  LOC 1874 1881         Бишкека\n",
       "15  T16  ORG 1951 1962     РИА Новости\n",
       "16  T17  LOC 1993 1996             США\n",
       "17  T18  LOC 2026 2034        Киргизии\n",
       "18  T19  LOC 2083 2091        Киргизии\n",
       "19  T20  LOC 2150 2153             США\n",
       "20  T21  LOC 2201 2209        Киргизии\n",
       "21  T22  LOC 2579 2582             США\n",
       "22  T23  LOC 2651 2654             США\n",
       "23  T24  LOC 2657 2665        Киргизия\n",
       "24  T25  LOC 2740 2748        Киргизии\n",
       "25  T26  ORG 2833 2840           Манас\n",
       "26  T27  LOC 2849 2857        Киргизии\n",
       "27  T28  LOC 3005 3008             США\n",
       "28  T29  ORG 3022 3033     РИА Новости"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Разметка из collection3\n",
    "pd.read_csv('collection3/003.ann', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269205d",
   "metadata": {
    "cellId": "5bki7kr0rs8t47b7j90vtd",
    "execution_id": "a3f174b7-dd1d-40c7-b7fb-0ef8be16defb"
   },
   "source": [
    "**Вывод:** NER из spacy нашла все сущности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c2588",
   "metadata": {
    "cellId": "3hdhgaq5rs720rax897iid",
    "execution_id": "708df97b-6ba2-43b6-b9dc-8ed68844298a"
   },
   "source": [
    "### <a id='NER_slovnet'>2.3 NER из slovnet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08de6c6e",
   "metadata": {
    "cellId": "9ubmfr8rlg82tshksgaj69"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'slovnet/navec_news_v1_1B_250K_300d_100q.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-102e266e4b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnavec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNavec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'slovnet/navec_news_v1_1B_250K_300d_100q.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'slovnet/slovnet_ner_news_v1.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnavec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnavec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/navec/navec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mTar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/navec/tar.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1601\u001b[0m                     \u001b[0msaved_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mReadError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'slovnet/navec_news_v1_1B_250K_300d_100q.tar'"
     ]
    }
   ],
   "source": [
    "text = data_text.text[0]\n",
    "navec = Navec.load('slovnet/navec_news_v1_1B_250K_300d_100q.tar')\n",
    "ner = NER.load('slovnet/slovnet_ner_news_v1.tar')\n",
    "ner.navec(navec)\n",
    "\n",
    "markup = ner(text)\n",
    "show_markup(markup.text, markup.spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa1a6c",
   "metadata": {
    "cellId": "y4yu98wk60fd16gu15vz2f",
    "execution_id": "3649d3fa-4fb7-49fa-b0af-b10b42537549"
   },
   "source": [
    "**Вывод:** NER из slovnet "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40609fd2",
   "metadata": {
    "cellId": "u66yyxxnxohc7yvmj5e4l",
    "execution_id": "2c93ddfa-2724-4eb7-89de-36aa1a4c24fb"
   },
   "source": [
    "### <a id='NER_deeppavlov'>2.4 NER из deeppavlov</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8c1722c",
   "metadata": {
    "cellId": "30rxfic6ezsih2m2pt2bk",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Struct' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-90688bf118cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeeppavlov_ner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrus_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdeeppavlov_ner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrus_document\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/deeppavlov/core/commands/infer.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(config, mode, load_trained, install, download)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 load_trained: bool = False, install: bool = False, download: bool = False) -> Chainer:\n\u001b[1;32m     33\u001b[0m     \u001b[0;34m\"\"\"Build and return the model described in corresponding configuration file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minstall\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/deeppavlov/core/commands/utils.py\u001b[0m in \u001b[0;36mparse_config\u001b[0;34m(config, overwrite)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_overwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mupdated_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_update_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables_exact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_variables_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdated_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/deeppavlov/core/commands/utils.py\u001b[0m in \u001b[0;36m_update_requirements\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mrequirements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequirements_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mrequirements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'requirements'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Struct' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "deeppavlov_ner = build_model(configs.ner, download=True)\n",
    "rus_document = data_text.text[0]\n",
    "deeppavlov_ner([rus_document])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9b2c4",
   "metadata": {
    "cellId": "59a56o4yqa8dkwswk31elf",
    "execution_id": "8a75339b-11cb-4105-bfc8-a02746ad0e36"
   },
   "source": [
    "### <a id='NER_свой'>2.5 Самописный NER</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b1794dc",
   "metadata": {
    "cellId": "zhav8jh56wr2qmee3qvoob"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['03_12_12a.ann', '03_12_12c.ann', '03_12_12h.ann', '004.ann', '03_12_12b.ann', '03_12_12g.ann', '003.ann', '03_12_12d.ann', '04_03_13a_sorokin.ann', '04_02_13a_abdulatipov.ann', '04_12_12f.ann', '04_12_12h_corr.ann', '04_12_12b.ann', '04_12_12d.ann', '007.ann', '04_12_12g.ann', '005.ann', '006.ann', '09_01_13.ann', '008.ann', '009.ann', '09_01_13a.ann', '09_01_13e.ann', '09_01_13c.ann', '010.ann', '09_01_13i.ann', '09_01_13d.ann', '09_01_13h.ann', '10_01_13a.ann', '10_01_13i.ann', '10_01_13d.ann', '11_01_13e.ann', '011.ann', '11_01_13b.ann', '014.ann', '14_01_13i.ann', '14_01_13c.ann', '15_01_13a.ann', '14_01_13g.ann', '013.ann', '15_01_13e.ann', '012.ann', '016.ann', '018.ann', '019.ann', '017.ann', '15_01_13b.ann', '19_11_12d.ann', '15_01_13f.ann', '015 (!).ann', '19_11_12h.ann', '20_11_12a.ann', '020.ann', '20_11_12b.ann', '20_11_12d.ann', '20_11_12c.ann', '20_11_12i.ann', '021.ann', '21_11_12c.ann', '21_11_12h.ann', '21_11_12i.ann', '21_11_12j.ann', '022.ann', '22_11_12a.ann', '22_11_12c.ann', '22_11_12d.ann', '22_11_12g.ann', '22_11_12h.ann', '22_11_12i.ann', '22_11_12j.ann', '023.ann', '23_11_12a.ann', '23_11_12b.ann', '23_11_12c.ann', '23_11_12d.ann', '23_11_12e.ann', '23_11_12f.ann', '025.ann', '25_12_12a.ann', '25_12_12c.ann', '25_12_12d.ann', '25_12_12e.ann', '026.ann', '26_11_12b.ann', '26_11_12c.ann', '26_11_12e.ann', '26_11_12f.ann', '027.ann', '27_11_12a.ann', '27_11_12c.ann', '27_11_12d.ann', '27_11_12e.ann', '028.ann', '27_11_12j.ann', '28_11_12a.ann', '28_11_12f.ann', '28_11_12g.ann', '28_11_12h.ann', '28_11_12i.ann', '28_11_12j.ann', '029.ann', '29_11_12a.ann', '29_11_12b.ann', '030.ann', '30_11_12h.ann', '30_11_12b.ann', '30_11_12i.ann', '031.ann', '032.ann', '033.ann', '034.ann', '035.ann', '037.ann', '036.ann', '038.ann', '039.ann', '040.ann', '041.ann', '042.ann', '043.ann', '044.ann', '046.ann', '045.ann', '047.ann', '048.ann', '050.ann', '051.ann', '052.ann', '053.ann', '054.ann', '055.ann', '056.ann', '057.ann', '058.ann', '059.ann', '060.ann', '061.ann', '062.ann', '049.ann', '063.ann', '064.ann', '065.ann', '066.ann', '067.ann', '068.ann', '069.ann', '070.ann', '071.ann', '072.ann', '073.ann', '074.ann', '075.ann', '076.ann', '077.ann', '078.ann', '079.ann', '080.ann', '081.ann', '082.ann', '083.ann', '084.ann', '085.ann', '086.ann', '087.ann', '088.ann', '089.ann', '090.ann', '091.ann', '092.ann', '093.ann', '094.ann', '095.ann', '096.ann', '097.ann', '098.ann', '099.ann', '100.ann', '101.ann', '102.ann', '103.ann', '104.ann', '105.ann', '106.ann', '107.ann', '108.ann', '109.ann', '110.ann', '111.ann', '112.ann', '113.ann', '114.ann', '115.ann', '116.ann', '117.ann', '118.ann', '119.ann', '120.ann', '121.ann', '122.ann', '123.ann', '124.ann', '125.ann', '126.ann', '127.ann', '129.ann', '130.ann', '131.ann', '132.ann', '133.ann', '134.ann', '135.ann', '136.ann', '137.ann', '139.ann', '138.ann', '128.ann', '140.ann', '141.ann', '142.ann', '143.ann', '144.ann', '145.ann', '146.ann', '147.ann', '148.ann', '149.ann', '150.ann', '151.ann', '152.ann', '153.ann', '154.ann', '155.ann', '156.ann', '157.ann', '158.ann', '159.ann', '160.ann', '161.ann', '162.ann', '163.ann', '164.ann', '165.ann', '166.ann', '167.ann', '168.ann', '169.ann', '171.ann', '170.ann', '173.ann', '172.ann', '174.ann', '175.ann', '176.ann', '177.ann', '178.ann', '179.ann', '180.ann', '181.ann', '182.ann', '183.ann', '184.ann', '185.ann', '186.ann', '187.ann', '188.ann', '189.ann', '190.ann', '191.ann', '192.ann', '193.ann', '194.ann', '195.ann', '196.ann', '197.ann', '198.ann', '199.ann', '200.ann', '201.ann', '202.ann', '203.ann', '204.ann', '205.ann', '206.ann', '207.ann', '208.ann', '209.ann', '210.ann', '211.ann', '212.ann', '213.ann', '214.ann', '215.ann', '216.ann', '217.ann', '219.ann', '218.ann', '220.ann', '221.ann', '222.ann', '223.ann', '224.ann', '225.ann', '226.ann', '227.ann', '228.ann', '229.ann', '230.ann', '231.ann', '232.ann', '233.ann', '234.ann', '235.ann', '236.ann', '237.ann', '238.ann', '239.ann', '241.ann', '240.ann', '243.ann', '244.ann', '245.ann', '246.ann', '247.ann', '248.ann', '249.ann', '250.ann', '251.ann', '252.ann', '253.ann', '254.ann', '255.ann', '242.ann', '257.ann', '256.ann', '258.ann', '259.ann', '261.ann', '260.ann', '262.ann', '263.ann', '264.ann', '265.ann', '266.ann', '267.ann', '268.ann', '269.ann', '270.ann', '271.ann', '272.ann', '273.ann', '274.ann', '275.ann', '276.ann', '277.ann', '278.ann', '280.ann', '281.ann', '282.ann', '283.ann', '284.ann', '285.ann', '286.ann', '287.ann', '288.ann', '289.ann', '290.ann', '291.ann', '292.ann', '293.ann', '279.ann', '294.ann', '295.ann', '296.ann', '297.ann', '298.ann', '299.ann', '300.ann', '301.ann', '302.ann', '303.ann', '304.ann', '305.ann', '306.ann', '307.ann', '308.ann', '309.ann', '310.ann', '311.ann', '312.ann', '313.ann', '314.ann', '315.ann', '316.ann', '317.ann', '318.ann', '319.ann', '320.ann', '321.ann', '322.ann', '323.ann', '324.ann', '325.ann', '326.ann', '327.ann', '328.ann', '330.ann', '331.ann', '329.ann', '332.ann', '333.ann', '334.ann', '335.ann', '336.ann', '337.ann', '338.ann', '339.ann', '340.ann', '341.ann', '342.ann', '343.ann', '344.ann', '345.ann', '346.ann', '347.ann', '348.ann', '349.ann', '350.ann', '351.ann', '352.ann', '353.ann', '354.ann', '355.ann', '356.ann', '357.ann', '358.ann', '359.ann', '360.ann', '361.ann', '362.ann', '363.ann', '364.ann', '365.ann', '366.ann', '367.ann', '368.ann', '369.ann', '370.ann', '371.ann', '372.ann', '373.ann', '374.ann', '375.ann', '376.ann', '377.ann', '379.ann', '378.ann', '380.ann', '381.ann', '383.ann', '382.ann', '384.ann', '385.ann', '386.ann', '387.ann', '388.ann', '389.ann', '390.ann', '391.ann', '392.ann', '393.ann', '394.ann', '395.ann', '396.ann', '397.ann', '398.ann', '399.ann', '400.ann', '401.ann', '403.ann', '402.ann', '404.ann', '405.ann', '406.ann', '407.ann', '408.ann', '409.ann', '410.ann', '411.ann', '412.ann', '413.ann', '414.ann', '415.ann', '416.ann', '417.ann', '418.ann', '419.ann', '420.ann', '421.ann', '422.ann', '423.ann', '424.ann', '425.ann', '427.ann', '428.ann', '429.ann', '430.ann', '431.ann', '432.ann', '433.ann', '434.ann', '435.ann', '436.ann', '437.ann', '438.ann', '439.ann', '426.ann', '440.ann', '441.ann', '442.ann', '445.ann', '443.ann', '446.ann', '444.ann', '447.ann', '448.ann', '449.ann', '450.ann', '451.ann', '452.ann', '453.ann', '454.ann', '455.ann', '457.ann', '458.ann', '459.ann', '460.ann', '461.ann', '462.ann', '463.ann', '464.ann', '465.ann', '466.ann', '467.ann', '468.ann', '470.ann', '469.ann', '472.ann', '474.ann', '471.ann', '475.ann', '473.ann', '476.ann', '477.ann', '478.ann', '479.ann', '480.ann', '482.ann', '481.ann', '483.ann', '484.ann', '485.ann', '486.ann', '487.ann', '488.ann', '489.ann', '490.ann', '492.ann', '491.ann', '493.ann', '494.ann', '495.ann', '498.ann', '496.ann', '500.ann', '499.ann', '497.ann', '501.ann', '502.ann', '504.ann', '503.ann', '505.ann', '506.ann', '507.ann', '508.ann', '509.ann', '510.ann', '511.ann', '512.ann', '513.ann', '514.ann', '515.ann', '517.ann', '516.ann', '518.ann', '519.ann', '520.ann', '521.ann', '522.ann', '523.ann', '524.ann', '525.ann', '526.ann', '527.ann', '528.ann', '529.ann', '530.ann', '531.ann', '532.ann', '533 (!).ann', '534.ann', '535.ann', '536.ann', '537.ann', '538.ann', '539.ann', '540.ann', '541.ann', '542.ann', '543.ann', '544.ann', '545.ann', '546.ann', '547.ann', '548.ann', '549.ann', '550.ann', '552.ann', '551.ann', '553.ann', '554.ann', '555 (!).ann', '556.ann', '557.ann', '558.ann', '559.ann', '560.ann', '561.ann', '562.ann', '563.ann', '564.ann', '565.ann', '567.ann', '568.ann', '569.ann', '570.ann', '571.ann', '572.ann', '574.ann', '575.ann', '576.ann', '577.ann', '579.ann', '578.ann', '581.ann', '582.ann', '583.ann', '584 (!).ann', '585.ann', '586.ann', '587.ann', '588.ann', '589.ann', '590.ann', '591.ann', '592.ann', '593.ann', '594.ann', '596.ann', '597.ann', '598 (!).ann', '599.ann', '600.ann', '601.ann', '602.ann', '610.ann', '611.ann', '612.ann', '614.ann', '615.ann', '616.ann', '617.ann', '618.ann', '619.ann', '621.ann', '622.ann', '623.ann', '624.ann', '625.ann', '626.ann', '613.ann', '627.ann', '1150.ann', '620.ann', '1042.ann', 'last_03.ann', 'last_43.ann']\n"
     ]
    }
   ],
   "source": [
    "# Собираем только ann файлы коллекции\n",
    "fileDir = r\"collection3\"\n",
    "fileExt = r\".ann\"\n",
    "documents_ann = [_ for _ in os.listdir(fileDir) if _.endswith(fileExt)]\n",
    "print(documents_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4af3b4c",
   "metadata": {
    "cellId": "mn6ss9snwxa4fo3qwxx7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>LOC 82 89</td>\n",
       "      <td>Бишкеке</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>LOC 113 119</td>\n",
       "      <td>БИШКЕК</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>ORG 132 146</td>\n",
       "      <td>Новости-Грузия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>LOC 175 183</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>LOC 225 228</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>LOC 231 238</td>\n",
       "      <td>Бишкеке</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T7</td>\n",
       "      <td>ORG 316 319</td>\n",
       "      <td>МВД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T8</td>\n",
       "      <td>LOC 320 328</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T9</td>\n",
       "      <td>LOC 492 500</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T10</td>\n",
       "      <td>LOC 525 528</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T11</td>\n",
       "      <td>ORG 955 958</td>\n",
       "      <td>МВД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T12</td>\n",
       "      <td>LOC 1059 1062</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T13</td>\n",
       "      <td>LOC 1144 1147</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T14</td>\n",
       "      <td>ORG 1804 1807</td>\n",
       "      <td>МВД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T15</td>\n",
       "      <td>LOC 1874 1881</td>\n",
       "      <td>Бишкека</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T16</td>\n",
       "      <td>ORG 1951 1962</td>\n",
       "      <td>РИА Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T17</td>\n",
       "      <td>LOC 1993 1996</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T18</td>\n",
       "      <td>LOC 2026 2034</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>T19</td>\n",
       "      <td>LOC 2083 2091</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>T20</td>\n",
       "      <td>LOC 2150 2153</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>T21</td>\n",
       "      <td>LOC 2201 2209</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>T22</td>\n",
       "      <td>LOC 2579 2582</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>T23</td>\n",
       "      <td>LOC 2651 2654</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>T24</td>\n",
       "      <td>LOC 2657 2665</td>\n",
       "      <td>Киргизия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>T25</td>\n",
       "      <td>LOC 2740 2748</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>T26</td>\n",
       "      <td>ORG 2833 2840</td>\n",
       "      <td>Манас</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>T27</td>\n",
       "      <td>LOC 2849 2857</td>\n",
       "      <td>Киргизии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>T28</td>\n",
       "      <td>LOC 3005 3008</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>T29</td>\n",
       "      <td>ORG 3022 3033</td>\n",
       "      <td>РИА Новости</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0              1               2\n",
       "0    T1      LOC 82 89         Бишкеке\n",
       "1    T2    LOC 113 119          БИШКЕК\n",
       "2    T3    ORG 132 146  Новости-Грузия\n",
       "3    T4    LOC 175 183        Киргизии\n",
       "4    T5    LOC 225 228             США\n",
       "5    T6    LOC 231 238         Бишкеке\n",
       "6    T7    ORG 316 319             МВД\n",
       "7    T8    LOC 320 328        Киргизии\n",
       "8    T9    LOC 492 500        Киргизии\n",
       "9   T10    LOC 525 528             США\n",
       "10  T11    ORG 955 958             МВД\n",
       "11  T12  LOC 1059 1062             США\n",
       "12  T13  LOC 1144 1147             США\n",
       "13  T14  ORG 1804 1807             МВД\n",
       "14  T15  LOC 1874 1881         Бишкека\n",
       "15  T16  ORG 1951 1962     РИА Новости\n",
       "16  T17  LOC 1993 1996             США\n",
       "17  T18  LOC 2026 2034        Киргизии\n",
       "18  T19  LOC 2083 2091        Киргизии\n",
       "19  T20  LOC 2150 2153             США\n",
       "20  T21  LOC 2201 2209        Киргизии\n",
       "21  T22  LOC 2579 2582             США\n",
       "22  T23  LOC 2651 2654             США\n",
       "23  T24  LOC 2657 2665        Киргизия\n",
       "24  T25  LOC 2740 2748        Киргизии\n",
       "25  T26  ORG 2833 2840           Манас\n",
       "26  T27  LOC 2849 2857        Киргизии\n",
       "27  T28  LOC 3005 3008             США\n",
       "28  T29  ORG 3022 3033     РИА Новости"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = pd.read_csv('collection3/003.ann', delimiter='\\t', header=None)\n",
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2eaad9fe",
   "metadata": {
    "cellId": "uc2vfohqgc6astiy3jtpp"
   },
   "outputs": [],
   "source": [
    "# Составляем списки токенов и интенсов (из файла .ann делается словарь {слово : интенс}, из словаря каждому токену сопоствляем интенс)\n",
    "docs = []\n",
    "for i in range(len(documents_ann)):\n",
    "    words = []\n",
    "    labels = []\n",
    "    # Подготавливаем текст\n",
    "    text = data_text['text'][i]\n",
    "    \n",
    "    df = pd.read_csv('collection3/' + documents_ann[i], delimiter='\\t', header=None)\n",
    "    df_ann = pd.DataFrame()\n",
    "    df_ann['Token'] = df.loc[:, 2]\n",
    "    split_1 = [loc.split() for loc in df.loc[:, 1].values]\n",
    "    df_ann['Entity'] = [loc[0] for loc in split_1]\n",
    "       \n",
    "    dic = {}\n",
    "    for j in range(len(df)):\n",
    "        token = df_ann['Token'][j].lower().split()\n",
    "        entity = df_ann['Entity'][j]\n",
    "        for tok in token:\n",
    "            dic[tok] = entity\n",
    "\n",
    "    for token in tokenize(text):\n",
    "        if (token.text.lower() in dic.keys()):\n",
    "            words.append(token.text)\n",
    "            labels.append(dic[token.text.lower()])\n",
    "        else:\n",
    "            words.append(token.text)\n",
    "            labels.append('OUT')\n",
    "    \n",
    "    docs.append([words, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6049bc7",
   "metadata": {
    "cellId": "ma22m9hzec84i8tfc4it9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Пулеметы', ',', 'автоматы', 'и', 'снайперские', 'винтовки', 'изъяты', 'в', 'арендуемом', 'американцами', 'доме', 'в', 'Бишкеке', '05/08/2008', '10', ':', '35', 'БИШКЕК', ',', '5', 'августа', '/', 'Новости-Грузия', '/', '.', 'Правоохранительные', 'органы', 'Киргизии', 'обнаружили', 'в', 'доме', ',', 'арендуемом', 'гражданами', 'США', 'в', 'Бишкеке', ',', 'пулеметы', ',', 'автоматы', 'и', 'снайперские', 'винтовки', ',', 'сообщает', 'во', 'вторник', 'пресс-служба', 'МВД', 'Киргизии', '.', '\"', 'В', 'ходе', 'проведения', 'оперативно-профилактического', 'мероприятия', 'под', 'кодовым', 'названием', '\"', 'Арсенал', '\"', 'в', 'новостройке', 'Ынтымак', ',', 'в', 'доме', ',', 'принадлежащем', '66-летнему', 'гражданину', 'Киргизии', 'и', 'арендуемом', 'гражданами', 'США', ',', 'обнаружены', 'и', 'изъяты', ':', 'шесть', 'крупнокалиберных', 'пулеметов', 'с', 'оптическим', 'прицелом', 'и', 'с', 'приборами', 'ночного', 'видения', ',', '26', 'автоматов', 'калибра', '5,56', 'миллиметра', ',', 'два', 'винчестера', 'марки', 'МОСВЕГА', '12-го', 'калибра', ',', 'четыре', 'ствола', 'от', 'крупнокалиберного', 'пулемета', ',', 'два', 'подствольных', 'гранатомета', ',', 'четыре', 'снайперские', 'винтовки', 'с', 'оптическим', 'прицелом', 'защитного', 'цвета', ',', 'шесть', 'пистолетов', 'калибра', '9', 'миллиметров', 'марки', 'Беретта', ',', 'одна', 'винтовка', '\"', ',', '-', 'говорится', 'в', 'сообщении', 'МВД', '.', 'Пресс-служба', 'отмечает', ',', 'что', 'на', 'момент', 'обыска', '\"', 'в', 'доме', 'находились', 'несколько', 'сотрудников', 'посольства', 'США', ',', 'обладающих', 'дипломатическим', 'иммунитетом', ',', 'и', '10', 'военнослужащих', ',', 'якобы', 'прибывших', 'из', 'США', 'для', 'проведения', 'тренинга', 'с', 'сотрудниками', 'спецподразделения', 'одной', 'из', 'силовых', 'структур', 'республики', ',', 'личности', 'которых', 'в', 'настоящее', 'время', 'устанавливаются', '\"', '.', 'Согласно', 'сообщению', ',', 'в', 'доме', 'было', 'обнаружено', 'и', 'значительное', 'количество', 'боеприпасов', '.', '\"', 'Два', 'ножа', ',', '2920', 'штук', 'патронов', 'калибра', '5,56', 'миллиметра', ',', '10556', 'штук', 'патронов', 'калибра', '9', 'миллиметров', ',', 'два', 'ящика', 'патронов', 'калибра', '50', 'миллиметров', ',', 'в', 'каждом', '350', 'штук', ',', 'патроны', 'калибра', '12', 'миллиметров', 'в', 'количестве', '478', 'штук', ',', 'маркировочные', '(', 'трассирующие', ')', 'патроны', '(', 'красного', 'цвета', ')', '1000', 'штук', ',', '66', 'штук', 'пустых', 'магазинов', 'от', 'автоматического', 'оружия', ',', '57', 'штук', 'пустых', 'магазинов', 'от', 'пистолета', 'Беретта', '\"', ',', '-', 'говорится', 'в', 'пресс-релизе', '.', 'Пресс-служба', 'МВД', 'сообщила', ',', 'что', 'расследование', 'по', 'данному', 'факту', 'проводит', 'прокуратура', 'Бишкека', '.', 'Сейчас', 'выясняется', ',', 'кому', 'именно', 'принадлежит', 'изъятое', 'оружие', ',', 'передает', 'РИА', 'Новости', '.', 'Оружие', ',', 'изъятое', 'у', 'граждан', 'США', 'правоохранительными', 'органами', 'Киргизии', ',', 'находилось', 'в', 'республике', 'с', 'ведома', 'правительства', 'Киргизии', ',', 'сообщил', 'во', 'вторник', 'представитель', 'пресс-службы', 'посольства', 'США', '.', '\"', 'Все', 'оборудование', 'находилось', 'на', 'территории', 'Киргизии', 'с', 'ведома', 'и', 'разрешения', 'киргизских', 'властей', '\"', ',', '-', 'сказал', 'собеседник', 'агентства', '.', 'Военнослужащие', 'и', 'оружие', '\"', 'прибыли', 'в', 'республику', 'по', 'приглашению', 'правительства', 'с', 'целью', 'обеспечения', 'антитеррористических', 'учений', 'для', 'министерств', '\"', ',', 'заявило', 'американское', 'дипломатическое', 'ведомство', '.', '\"', 'Дом', 'и', 'оборудование', 'находились', 'под', 'защитой', 'киргизских', 'властей', '\"', ',', '-', 'отмечает', 'пресс-служба', '.', 'Посольство', 'США', 'считает', 'случившееся', '\"', 'неприятным', 'инцидентом', '\"', 'и', 'выражает', 'надежду', 'что', '\"', 'США', 'и', 'Киргизия', 'могли', 'бы', 'продолжить', 'усилия', 'по', 'улучшению', 'антитеррористических', 'возможностей', 'Киргизии', '\"', '.', 'Пресс-служба', 'американской', 'военной', 'базы', 'расположенной', 'в', 'международном', 'аэропорту', '\"', 'Манас', '\"', 'столицы', 'Киргизии', 'отказалась', 'комментировать', 'данный', 'инцидент', 'с', 'участием', 'американских', 'военных', '.', '\"', 'Всеми', 'вопросами', ',', 'связанными', 'с', 'данным', 'случаем', ',', 'занимается', 'посольство', 'США', '\"', ',', '-', 'сообщили', 'РИА', 'Новости', 'в', 'пресс-службе', 'базы', '.']\n",
      "['OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(docs[0][0]), print(docs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8f0cac4",
   "metadata": {
    "cellId": "gp1i8ui5w1euf00av3qiw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пулеметы\tOUT\n",
      ",\tOUT\n",
      "автоматы\tOUT\n",
      "и\tOUT\n",
      "снайперские\tOUT\n",
      "винтовки\tOUT\n",
      "изъяты\tOUT\n",
      "в\tOUT\n",
      "арендуемом\tOUT\n",
      "американцами\tOUT\n",
      "доме\tOUT\n",
      "в\tOUT\n",
      "Бишкеке\tOUT\n",
      "05/08/2008\tOUT\n",
      "10\tOUT\n",
      ":\tOUT\n",
      "35\tOUT\n",
      "БИШКЕК\tOUT\n",
      ",\tOUT\n",
      "5\tOUT\n",
      "августа\tOUT\n",
      "/\tOUT\n",
      "Новости-Грузия\tOUT\n",
      "/\tOUT\n",
      ".\tOUT\n",
      "Правоохранительные\tOUT\n",
      "органы\tOUT\n",
      "Киргизии\tOUT\n",
      "обнаружили\tOUT\n",
      "в\tOUT\n",
      "доме\tOUT\n",
      ",\tOUT\n",
      "арендуемом\tOUT\n",
      "гражданами\tOUT\n",
      "США\tOUT\n",
      "в\tOUT\n",
      "Бишкеке\tOUT\n",
      ",\tOUT\n",
      "пулеметы\tOUT\n",
      ",\tOUT\n",
      "автоматы\tOUT\n",
      "и\tOUT\n",
      "снайперские\tOUT\n",
      "винтовки\tOUT\n",
      ",\tOUT\n",
      "сообщает\tOUT\n",
      "во\tOUT\n",
      "вторник\tOUT\n",
      "пресс-служба\tOUT\n",
      "МВД\tOUT\n",
      "Киргизии\tOUT\n",
      ".\tOUT\n",
      "\"\tOUT\n",
      "В\tOUT\n",
      "ходе\tOUT\n",
      "проведения\tOUT\n",
      "оперативно-профилактического\tOUT\n",
      "мероприятия\tOUT\n",
      "под\tOUT\n",
      "кодовым\tOUT\n",
      "названием\tOUT\n",
      "\"\tOUT\n",
      "Арсенал\tOUT\n",
      "\"\tOUT\n",
      "в\tOUT\n",
      "новостройке\tOUT\n",
      "Ынтымак\tOUT\n",
      ",\tOUT\n",
      "в\tOUT\n",
      "доме\tOUT\n",
      ",\tOUT\n",
      "принадлежащем\tOUT\n",
      "66-летнему\tOUT\n",
      "гражданину\tOUT\n",
      "Киргизии\tOUT\n",
      "и\tOUT\n",
      "арендуемом\tOUT\n",
      "гражданами\tOUT\n",
      "США\tOUT\n",
      ",\tOUT\n",
      "обнаружены\tOUT\n",
      "и\tOUT\n",
      "изъяты\tOUT\n",
      ":\tOUT\n",
      "шесть\tOUT\n",
      "крупнокалиберных\tOUT\n",
      "пулеметов\tOUT\n",
      "с\tOUT\n",
      "оптическим\tOUT\n",
      "прицелом\tOUT\n",
      "и\tOUT\n",
      "с\tOUT\n",
      "приборами\tOUT\n",
      "ночного\tOUT\n",
      "видения\tOUT\n",
      ",\tOUT\n",
      "26\tOUT\n",
      "автоматов\tOUT\n",
      "калибра\tOUT\n",
      "5,56\tOUT\n",
      "миллиметра\tOUT\n",
      ",\tOUT\n",
      "два\tOUT\n",
      "винчестера\tOUT\n",
      "марки\tOUT\n",
      "МОСВЕГА\tOUT\n",
      "12-го\tOUT\n",
      "калибра\tOUT\n",
      ",\tOUT\n",
      "четыре\tOUT\n",
      "ствола\tOUT\n",
      "от\tOUT\n",
      "крупнокалиберного\tOUT\n",
      "пулемета\tOUT\n",
      ",\tOUT\n",
      "два\tOUT\n",
      "подствольных\tOUT\n",
      "гранатомета\tOUT\n",
      ",\tOUT\n",
      "четыре\tOUT\n",
      "снайперские\tOUT\n",
      "винтовки\tOUT\n",
      "с\tOUT\n",
      "оптическим\tOUT\n",
      "прицелом\tOUT\n",
      "защитного\tOUT\n",
      "цвета\tOUT\n",
      ",\tOUT\n",
      "шесть\tOUT\n",
      "пистолетов\tOUT\n",
      "калибра\tOUT\n",
      "9\tOUT\n",
      "миллиметров\tOUT\n",
      "марки\tOUT\n",
      "Беретта\tOUT\n",
      ",\tOUT\n",
      "одна\tOUT\n",
      "винтовка\tOUT\n",
      "\"\tOUT\n",
      ",\tOUT\n",
      "-\tOUT\n",
      "говорится\tOUT\n",
      "в\tOUT\n",
      "сообщении\tOUT\n",
      "МВД\tOUT\n",
      ".\tOUT\n",
      "Пресс-служба\tOUT\n",
      "отмечает\tOUT\n",
      ",\tOUT\n",
      "что\tOUT\n",
      "на\tOUT\n",
      "момент\tOUT\n",
      "обыска\tOUT\n",
      "\"\tOUT\n",
      "в\tOUT\n",
      "доме\tOUT\n",
      "находились\tOUT\n",
      "несколько\tOUT\n",
      "сотрудников\tOUT\n",
      "посольства\tOUT\n",
      "США\tOUT\n",
      ",\tOUT\n",
      "обладающих\tOUT\n",
      "дипломатическим\tOUT\n",
      "иммунитетом\tOUT\n",
      ",\tOUT\n",
      "и\tOUT\n",
      "10\tOUT\n",
      "военнослужащих\tOUT\n",
      ",\tOUT\n",
      "якобы\tOUT\n",
      "прибывших\tOUT\n",
      "из\tOUT\n",
      "США\tOUT\n",
      "для\tOUT\n",
      "проведения\tOUT\n",
      "тренинга\tOUT\n",
      "с\tOUT\n",
      "сотрудниками\tOUT\n",
      "спецподразделения\tOUT\n",
      "одной\tOUT\n",
      "из\tOUT\n",
      "силовых\tOUT\n",
      "структур\tOUT\n",
      "республики\tOUT\n",
      ",\tOUT\n",
      "личности\tOUT\n",
      "которых\tOUT\n",
      "в\tOUT\n",
      "настоящее\tOUT\n",
      "время\tOUT\n",
      "устанавливаются\tOUT\n",
      "\"\tOUT\n",
      ".\tOUT\n",
      "Согласно\tOUT\n",
      "сообщению\tOUT\n",
      ",\tOUT\n",
      "в\tOUT\n",
      "доме\tOUT\n",
      "было\tOUT\n",
      "обнаружено\tOUT\n",
      "и\tOUT\n",
      "значительное\tOUT\n",
      "количество\tOUT\n",
      "боеприпасов\tOUT\n",
      ".\tOUT\n",
      "\"\tOUT\n",
      "Два\tOUT\n",
      "ножа\tOUT\n",
      ",\tOUT\n",
      "2920\tOUT\n",
      "штук\tOUT\n",
      "патронов\tOUT\n",
      "калибра\tOUT\n",
      "5,56\tOUT\n",
      "миллиметра\tOUT\n",
      ",\tOUT\n",
      "10556\tOUT\n",
      "штук\tOUT\n",
      "патронов\tOUT\n",
      "калибра\tOUT\n",
      "9\tOUT\n",
      "миллиметров\tOUT\n",
      ",\tOUT\n",
      "два\tOUT\n",
      "ящика\tOUT\n",
      "патронов\tOUT\n",
      "калибра\tOUT\n",
      "50\tOUT\n",
      "миллиметров\tOUT\n",
      ",\tOUT\n",
      "в\tOUT\n",
      "каждом\tOUT\n",
      "350\tOUT\n",
      "штук\tOUT\n",
      ",\tOUT\n",
      "патроны\tOUT\n",
      "калибра\tOUT\n",
      "12\tOUT\n",
      "миллиметров\tOUT\n",
      "в\tOUT\n",
      "количестве\tOUT\n",
      "478\tOUT\n",
      "штук\tOUT\n",
      ",\tOUT\n",
      "маркировочные\tOUT\n",
      "(\tOUT\n",
      "трассирующие\tOUT\n",
      ")\tOUT\n",
      "патроны\tOUT\n",
      "(\tOUT\n",
      "красного\tOUT\n",
      "цвета\tOUT\n",
      ")\tOUT\n",
      "1000\tOUT\n",
      "штук\tOUT\n",
      ",\tOUT\n",
      "66\tOUT\n",
      "штук\tOUT\n",
      "пустых\tOUT\n",
      "магазинов\tOUT\n",
      "от\tOUT\n",
      "автоматического\tOUT\n",
      "оружия\tOUT\n",
      ",\tOUT\n",
      "57\tOUT\n",
      "штук\tOUT\n",
      "пустых\tOUT\n",
      "магазинов\tOUT\n",
      "от\tOUT\n",
      "пистолета\tOUT\n",
      "Беретта\tOUT\n",
      "\"\tOUT\n",
      ",\tOUT\n",
      "-\tOUT\n",
      "говорится\tOUT\n",
      "в\tOUT\n",
      "пресс-релизе\tOUT\n",
      ".\tOUT\n",
      "Пресс-служба\tOUT\n",
      "МВД\tOUT\n",
      "сообщила\tOUT\n",
      ",\tOUT\n",
      "что\tOUT\n",
      "расследование\tOUT\n",
      "по\tOUT\n",
      "данному\tOUT\n",
      "факту\tOUT\n",
      "проводит\tOUT\n",
      "прокуратура\tOUT\n",
      "Бишкека\tOUT\n",
      ".\tOUT\n",
      "Сейчас\tOUT\n",
      "выясняется\tOUT\n",
      ",\tOUT\n",
      "кому\tOUT\n",
      "именно\tOUT\n",
      "принадлежит\tOUT\n",
      "изъятое\tOUT\n",
      "оружие\tOUT\n",
      ",\tOUT\n",
      "передает\tOUT\n",
      "РИА\tOUT\n",
      "Новости\tOUT\n",
      ".\tOUT\n",
      "Оружие\tOUT\n",
      ",\tOUT\n",
      "изъятое\tOUT\n",
      "у\tOUT\n",
      "граждан\tOUT\n",
      "США\tOUT\n",
      "правоохранительными\tOUT\n",
      "органами\tOUT\n",
      "Киргизии\tOUT\n",
      ",\tOUT\n",
      "находилось\tOUT\n",
      "в\tOUT\n",
      "республике\tOUT\n",
      "с\tOUT\n",
      "ведома\tOUT\n",
      "правительства\tOUT\n",
      "Киргизии\tOUT\n",
      ",\tOUT\n",
      "сообщил\tOUT\n",
      "во\tOUT\n",
      "вторник\tOUT\n",
      "представитель\tOUT\n",
      "пресс-службы\tOUT\n",
      "посольства\tOUT\n",
      "США\tOUT\n",
      ".\tOUT\n",
      "\"\tOUT\n",
      "Все\tOUT\n",
      "оборудование\tOUT\n",
      "находилось\tOUT\n",
      "на\tOUT\n",
      "территории\tOUT\n",
      "Киргизии\tOUT\n",
      "с\tOUT\n",
      "ведома\tOUT\n",
      "и\tOUT\n",
      "разрешения\tOUT\n",
      "киргизских\tOUT\n",
      "властей\tOUT\n",
      "\"\tOUT\n",
      ",\tOUT\n",
      "-\tOUT\n",
      "сказал\tOUT\n",
      "собеседник\tOUT\n",
      "агентства\tOUT\n",
      ".\tOUT\n",
      "Военнослужащие\tOUT\n",
      "и\tOUT\n",
      "оружие\tOUT\n",
      "\"\tOUT\n",
      "прибыли\tOUT\n",
      "в\tOUT\n",
      "республику\tOUT\n",
      "по\tOUT\n",
      "приглашению\tOUT\n",
      "правительства\tOUT\n",
      "с\tOUT\n",
      "целью\tOUT\n",
      "обеспечения\tOUT\n",
      "антитеррористических\tOUT\n",
      "учений\tOUT\n",
      "для\tOUT\n",
      "министерств\tOUT\n",
      "\"\tOUT\n",
      ",\tOUT\n",
      "заявило\tOUT\n",
      "американское\tOUT\n",
      "дипломатическое\tOUT\n",
      "ведомство\tOUT\n",
      ".\tOUT\n",
      "\"\tOUT\n",
      "Дом\tOUT\n",
      "и\tOUT\n",
      "оборудование\tOUT\n",
      "находились\tOUT\n",
      "под\tOUT\n",
      "защитой\tOUT\n",
      "киргизских\tOUT\n",
      "властей\tOUT\n",
      "\"\tOUT\n",
      ",\tOUT\n",
      "-\tOUT\n",
      "отмечает\tOUT\n",
      "пресс-служба\tOUT\n",
      ".\tOUT\n",
      "Посольство\tOUT\n",
      "США\tOUT\n",
      "считает\tOUT\n",
      "случившееся\tOUT\n",
      "\"\tOUT\n",
      "неприятным\tOUT\n",
      "инцидентом\tOUT\n",
      "\"\tOUT\n",
      "и\tOUT\n",
      "выражает\tOUT\n",
      "надежду\tOUT\n",
      "что\tOUT\n",
      "\"\tOUT\n",
      "США\tOUT\n",
      "и\tOUT\n",
      "Киргизия\tOUT\n",
      "могли\tOUT\n",
      "бы\tOUT\n",
      "продолжить\tOUT\n",
      "усилия\tOUT\n",
      "по\tOUT\n",
      "улучшению\tOUT\n",
      "антитеррористических\tOUT\n",
      "возможностей\tOUT\n",
      "Киргизии\tOUT\n",
      "\"\tOUT\n",
      ".\tOUT\n",
      "Пресс-служба\tOUT\n",
      "американской\tOUT\n",
      "военной\tOUT\n",
      "базы\tOUT\n",
      "расположенной\tOUT\n",
      "в\tOUT\n",
      "международном\tOUT\n",
      "аэропорту\tOUT\n",
      "\"\tOUT\n",
      "Манас\tOUT\n",
      "\"\tOUT\n",
      "столицы\tOUT\n",
      "Киргизии\tOUT\n",
      "отказалась\tOUT\n",
      "комментировать\tOUT\n",
      "данный\tOUT\n",
      "инцидент\tOUT\n",
      "с\tOUT\n",
      "участием\tOUT\n",
      "американских\tOUT\n",
      "военных\tOUT\n",
      ".\tOUT\n",
      "\"\tOUT\n",
      "Всеми\tOUT\n",
      "вопросами\tOUT\n",
      ",\tOUT\n",
      "связанными\tOUT\n",
      "с\tOUT\n",
      "данным\tOUT\n",
      "случаем\tOUT\n",
      ",\tOUT\n",
      "занимается\tOUT\n",
      "посольство\tOUT\n",
      "США\tOUT\n",
      "\"\tOUT\n",
      ",\tOUT\n",
      "-\tOUT\n",
      "сообщили\tOUT\n",
      "РИА\tOUT\n",
      "Новости\tOUT\n",
      "в\tOUT\n",
      "пресс-службе\tOUT\n",
      "базы\tOUT\n",
      ".\tOUT\n"
     ]
    }
   ],
   "source": [
    "data, labels = list(zip(*docs))\n",
    "for w, e in zip(data[0], labels[0]):\n",
    "    print(f'{w}\\t{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26783bce",
   "metadata": {
    "cellId": "zac6yewwl2h28yc3d127p"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>data</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Пулеметы</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>автоматы</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>и</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>снайперские</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>винтовки</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>изъяты</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>арендуемом</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>американцами</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>доме</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Бишкеке</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>05/08/2008</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>:</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>БИШКЕК</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>августа</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>/</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>Новости-Грузия</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>/</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>Правоохранительные</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>органы</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>Киргизии</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>обнаружили</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>доме</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>арендуемом</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>гражданами</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>США</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>Бишкеке</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>пулеметы</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>автоматы</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>и</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>снайперские</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>винтовки</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>сообщает</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>во</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>вторник</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>пресс-служба</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>МВД</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent_id                data entities\n",
       "0         0            Пулеметы      OUT\n",
       "1         0                   ,      OUT\n",
       "2         0            автоматы      OUT\n",
       "3         0                   и      OUT\n",
       "4         0         снайперские      OUT\n",
       "5         0            винтовки      OUT\n",
       "6         0              изъяты      OUT\n",
       "7         0                   в      OUT\n",
       "8         0          арендуемом      OUT\n",
       "9         0        американцами      OUT\n",
       "10        0                доме      OUT\n",
       "11        0                   в      OUT\n",
       "12        0             Бишкеке      OUT\n",
       "13        0          05/08/2008      OUT\n",
       "14        0                  10      OUT\n",
       "15        0                   :      OUT\n",
       "16        0                  35      OUT\n",
       "17        0              БИШКЕК      OUT\n",
       "18        0                   ,      OUT\n",
       "19        0                   5      OUT\n",
       "20        0             августа      OUT\n",
       "21        0                   /      OUT\n",
       "22        0      Новости-Грузия      OUT\n",
       "23        0                   /      OUT\n",
       "24        0                   .      OUT\n",
       "25        0  Правоохранительные      OUT\n",
       "26        0              органы      OUT\n",
       "27        0            Киргизии      OUT\n",
       "28        0          обнаружили      OUT\n",
       "29        0                   в      OUT\n",
       "30        0                доме      OUT\n",
       "31        0                   ,      OUT\n",
       "32        0          арендуемом      OUT\n",
       "33        0          гражданами      OUT\n",
       "34        0                 США      OUT\n",
       "35        0                   в      OUT\n",
       "36        0             Бишкеке      OUT\n",
       "37        0                   ,      OUT\n",
       "38        0            пулеметы      OUT\n",
       "39        0                   ,      OUT\n",
       "40        0            автоматы      OUT\n",
       "41        0                   и      OUT\n",
       "42        0         снайперские      OUT\n",
       "43        0            винтовки      OUT\n",
       "44        0                   ,      OUT\n",
       "45        0            сообщает      OUT\n",
       "46        0                  во      OUT\n",
       "47        0             вторник      OUT\n",
       "48        0        пресс-служба      OUT\n",
       "49        0                 МВД      OUT"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'sent_id': [i for j in [[i] * len(s) for i, s in enumerate(data)] for i in j],\n",
    "                   'data': [i for j in data for i in j],\n",
    "                   'entities': [i for j in labels for i in j]})\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136d8834",
   "metadata": {
    "cellId": "uz345s4at6g02isnizp1z7g",
    "execution_id": "db3de23a-cbee-4807-b8c9-12ea824e28fc"
   },
   "source": [
    "**Будем передавать в модель токен с соседями**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bfdc0750",
   "metadata": {
    "cellId": "6yus1xzs9zp6mkbar5ulbn"
   },
   "outputs": [],
   "source": [
    "# Преобразуем датасет: \n",
    "# Группируем записи по номеру предложения (аггфункция - список кортежей (токен, лейбл))\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s['data'].values.tolist(), \n",
    "                                                           s['entities'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('sent_id').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None\n",
    "\n",
    "# Преобразует датасет df\n",
    "getter = SentenceGetter(df)\n",
    "# Получаем список номеров преложений датасета df\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72afd529",
   "metadata": {
    "cellId": "knf1deqpjhqw14giscz4e"
   },
   "outputs": [],
   "source": [
    "# Преобразуем слова в признаки:\n",
    "# Для каждого слова-токена составляем словарь признаков, \n",
    "# Определяем является ли оно начаотным, конечным в предложении\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isdigit()': word.isdigit()\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i - 1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower()\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i + 1][0]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower()\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "# Преобразуем предложения:\n",
    "# Каждое слово предложения преобразуем в признаки\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "# Список всех лейблов предложения\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "# Список всех токенов предложения\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4fca14c",
   "metadata": {
    "cellId": "7bh9393x5v5fceon1yanew"
   },
   "outputs": [],
   "source": [
    "# Собираем данные и метки\n",
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c16fc55c",
   "metadata": {
    "cellId": "n0cprzsryfscyhdaeksqs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'азаров',\n",
       " 'word[-3:]': 'ров',\n",
       " 'word[-2:]': 'ов',\n",
       " 'word.isdigit()': False,\n",
       " '-1:word.lower()': 'что',\n",
       " '+1:word.lower()': 'останется'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Передаем в датасет токен с соседями (первый индекс -- предложение, 2 индекс -- слово)\n",
    "X[2][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee667b0a",
   "metadata": {
    "cellId": "ra6ko0xhjh84wwf5n7su9r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65a8ea54",
   "metadata": {
    "cellId": "lka7veehzbyub8kr4az4"
   },
   "outputs": [],
   "source": [
    "# Разбиваем данные на train и test\n",
    "X_train = X[:700]\n",
    "X_test = X[700:]\n",
    "y_train = y[:700]\n",
    "y_test = y[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a3a8a2e",
   "metadata": {
    "cellId": "9wff45tab3rrbn65ikfuul"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 696/696 [00:01<00:00, 684.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 88941\n",
      "Seconds required: 0.224\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 1000\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.11  loss=89535.40 active=88196 feature_norm=1.00\n",
      "Iter 2   time=0.06  loss=67149.76 active=84311 feature_norm=1.80\n",
      "Iter 3   time=0.06  loss=66018.52 active=87657 feature_norm=1.70\n",
      "Iter 4   time=0.06  loss=65185.83 active=86205 feature_norm=1.58\n",
      "Iter 5   time=0.06  loss=64640.91 active=88260 feature_norm=1.60\n",
      "Iter 6   time=0.06  loss=55069.05 active=77481 feature_norm=3.72\n",
      "Iter 7   time=0.12  loss=53204.03 active=78685 feature_norm=4.71\n",
      "Iter 8   time=0.06  loss=50874.16 active=79450 feature_norm=5.30\n",
      "Iter 9   time=0.06  loss=47660.17 active=78241 feature_norm=7.02\n",
      "Iter 10  time=0.06  loss=45354.50 active=75836 feature_norm=8.91\n",
      "Iter 11  time=0.07  loss=43477.23 active=71172 feature_norm=10.82\n",
      "Iter 12  time=0.07  loss=40834.83 active=61057 feature_norm=14.45\n",
      "Iter 13  time=0.07  loss=39010.34 active=60954 feature_norm=15.83\n",
      "Iter 14  time=0.07  loss=37434.69 active=60355 feature_norm=18.01\n",
      "Iter 15  time=0.07  loss=36095.46 active=60371 feature_norm=19.53\n",
      "Iter 16  time=0.06  loss=33722.45 active=58931 feature_norm=24.02\n",
      "Iter 17  time=0.06  loss=32560.46 active=54776 feature_norm=29.67\n",
      "Iter 18  time=0.06  loss=31080.41 active=57042 feature_norm=30.56\n",
      "Iter 19  time=0.07  loss=30333.56 active=56614 feature_norm=32.71\n",
      "Iter 20  time=0.07  loss=28421.89 active=54812 feature_norm=41.19\n",
      "Iter 21  time=0.07  loss=26863.82 active=53894 feature_norm=46.99\n",
      "Iter 22  time=0.07  loss=25529.52 active=52932 feature_norm=54.19\n",
      "Iter 23  time=0.06  loss=24210.71 active=52749 feature_norm=61.14\n",
      "Iter 24  time=0.06  loss=22811.84 active=52163 feature_norm=70.99\n",
      "Iter 25  time=0.06  loss=21708.82 active=50818 feature_norm=79.55\n",
      "Iter 26  time=0.07  loss=20654.96 active=49731 feature_norm=90.02\n",
      "Iter 27  time=0.07  loss=19777.24 active=48873 feature_norm=97.72\n",
      "Iter 28  time=0.07  loss=18863.63 active=47640 feature_norm=109.89\n",
      "Iter 29  time=0.07  loss=18205.26 active=47063 feature_norm=117.15\n",
      "Iter 30  time=0.06  loss=17609.27 active=46618 feature_norm=127.50\n",
      "Iter 31  time=0.06  loss=17138.45 active=46260 feature_norm=133.82\n",
      "Iter 32  time=0.06  loss=16789.16 active=44935 feature_norm=142.55\n",
      "Iter 33  time=0.07  loss=16541.92 active=43615 feature_norm=145.47\n",
      "Iter 34  time=0.07  loss=16341.62 active=43349 feature_norm=150.91\n",
      "Iter 35  time=0.07  loss=16175.32 active=41902 feature_norm=153.72\n",
      "Iter 36  time=0.06  loss=16060.61 active=41094 feature_norm=157.24\n",
      "Iter 37  time=0.07  loss=15962.82 active=40422 feature_norm=158.69\n",
      "Iter 38  time=0.06  loss=15879.35 active=40226 feature_norm=160.92\n",
      "Iter 39  time=0.06  loss=15818.84 active=40069 feature_norm=161.38\n",
      "Iter 40  time=0.07  loss=15752.05 active=39511 feature_norm=162.65\n",
      "Iter 41  time=0.07  loss=15690.45 active=38750 feature_norm=162.93\n",
      "Iter 42  time=0.07  loss=15638.94 active=38216 feature_norm=163.89\n",
      "Iter 43  time=0.06  loss=15599.06 active=37398 feature_norm=163.97\n",
      "Iter 44  time=0.07  loss=15560.63 active=36909 feature_norm=164.54\n",
      "Iter 45  time=0.06  loss=15519.31 active=35780 feature_norm=164.74\n",
      "Iter 46  time=0.07  loss=15488.99 active=35158 feature_norm=165.33\n",
      "Iter 47  time=0.06  loss=15461.79 active=35121 feature_norm=165.30\n",
      "Iter 48  time=0.07  loss=15434.50 active=34829 feature_norm=165.75\n",
      "Iter 49  time=0.07  loss=15406.79 active=34636 feature_norm=165.85\n",
      "Iter 50  time=0.06  loss=15383.67 active=34252 feature_norm=166.29\n",
      "Iter 51  time=0.07  loss=15363.90 active=33915 feature_norm=166.40\n",
      "Iter 52  time=0.07  loss=15346.12 active=33716 feature_norm=166.79\n",
      "Iter 53  time=0.07  loss=15329.78 active=33674 feature_norm=166.85\n",
      "Iter 54  time=0.06  loss=15314.90 active=33498 feature_norm=167.17\n",
      "Iter 55  time=0.06  loss=15300.47 active=33423 feature_norm=167.19\n",
      "Iter 56  time=0.07  loss=15287.49 active=33284 feature_norm=167.49\n",
      "Iter 57  time=0.06  loss=15275.53 active=33206 feature_norm=167.53\n",
      "Iter 58  time=0.06  loss=15264.14 active=33104 feature_norm=167.73\n",
      "Iter 59  time=0.06  loss=15253.70 active=33049 feature_norm=167.77\n",
      "Iter 60  time=0.06  loss=15244.08 active=32951 feature_norm=167.95\n",
      "Iter 61  time=0.06  loss=15235.00 active=32931 feature_norm=167.96\n",
      "Iter 62  time=0.06  loss=15225.46 active=32787 feature_norm=168.11\n",
      "Iter 63  time=0.06  loss=15217.22 active=32739 feature_norm=168.12\n",
      "Iter 64  time=0.06  loss=15209.86 active=32671 feature_norm=168.28\n",
      "Iter 65  time=0.06  loss=15203.28 active=32667 feature_norm=168.25\n",
      "Iter 66  time=0.07  loss=15196.50 active=32637 feature_norm=168.37\n",
      "Iter 67  time=0.06  loss=15190.19 active=32591 feature_norm=168.34\n",
      "Iter 68  time=0.07  loss=15184.26 active=32517 feature_norm=168.48\n",
      "Iter 69  time=0.06  loss=15178.97 active=32500 feature_norm=168.42\n",
      "Iter 70  time=0.06  loss=15173.92 active=32467 feature_norm=168.50\n",
      "Iter 71  time=0.06  loss=15168.54 active=32423 feature_norm=168.45\n",
      "Iter 72  time=0.06  loss=15163.06 active=32361 feature_norm=168.50\n",
      "Iter 73  time=0.06  loss=15158.62 active=32320 feature_norm=168.42\n",
      "Iter 74  time=0.06  loss=15154.26 active=32255 feature_norm=168.48\n",
      "Iter 75  time=0.06  loss=15150.22 active=32235 feature_norm=168.42\n",
      "Iter 76  time=0.07  loss=15145.68 active=32192 feature_norm=168.45\n",
      "Iter 77  time=0.06  loss=15142.03 active=32165 feature_norm=168.38\n",
      "Iter 78  time=0.06  loss=15138.46 active=32145 feature_norm=168.44\n",
      "Iter 79  time=0.06  loss=15135.49 active=32132 feature_norm=168.37\n",
      "Iter 80  time=0.07  loss=15132.26 active=32112 feature_norm=168.41\n",
      "Iter 81  time=0.07  loss=15129.78 active=32089 feature_norm=168.33\n",
      "Iter 82  time=0.06  loss=15126.93 active=32059 feature_norm=168.39\n",
      "Iter 83  time=0.07  loss=15124.62 active=32060 feature_norm=168.33\n",
      "Iter 84  time=0.07  loss=15122.17 active=32045 feature_norm=168.35\n",
      "Iter 85  time=0.06  loss=15120.09 active=32036 feature_norm=168.30\n",
      "Iter 86  time=0.06  loss=15118.01 active=31994 feature_norm=168.36\n",
      "Iter 87  time=0.07  loss=15115.95 active=31983 feature_norm=168.30\n",
      "Iter 88  time=0.06  loss=15114.16 active=31983 feature_norm=168.34\n",
      "Iter 89  time=0.06  loss=15112.37 active=31974 feature_norm=168.30\n",
      "Iter 90  time=0.06  loss=15110.87 active=31960 feature_norm=168.36\n",
      "Iter 91  time=0.06  loss=15109.16 active=31952 feature_norm=168.31\n",
      "Iter 92  time=0.06  loss=15107.74 active=31930 feature_norm=168.37\n",
      "Iter 93  time=0.06  loss=15106.10 active=31957 feature_norm=168.33\n",
      "Iter 94  time=0.06  loss=15104.55 active=31943 feature_norm=168.37\n",
      "Iter 95  time=0.06  loss=15103.14 active=31917 feature_norm=168.35\n",
      "Iter 96  time=0.06  loss=15101.82 active=31907 feature_norm=168.42\n",
      "Iter 97  time=0.06  loss=15100.28 active=31905 feature_norm=168.39\n",
      "Iter 98  time=0.06  loss=15098.78 active=31894 feature_norm=168.44\n",
      "Iter 99  time=0.06  loss=15097.29 active=31907 feature_norm=168.43\n",
      "Iter 100 time=0.07  loss=15095.97 active=31886 feature_norm=168.47\n",
      "Iter 101 time=0.06  loss=15094.85 active=31873 feature_norm=168.45\n",
      "Iter 102 time=0.06  loss=15093.43 active=31862 feature_norm=168.51\n",
      "Iter 103 time=0.06  loss=15092.18 active=31861 feature_norm=168.49\n",
      "Iter 104 time=0.06  loss=15090.91 active=31847 feature_norm=168.53\n",
      "Iter 105 time=0.06  loss=15089.82 active=31843 feature_norm=168.52\n",
      "Iter 106 time=0.07  loss=15089.03 active=31830 feature_norm=168.57\n",
      "Iter 107 time=0.06  loss=15087.74 active=31848 feature_norm=168.55\n",
      "Iter 108 time=0.07  loss=15086.84 active=31840 feature_norm=168.59\n",
      "Iter 109 time=0.06  loss=15085.67 active=31838 feature_norm=168.58\n",
      "Iter 110 time=0.06  loss=15084.53 active=31822 feature_norm=168.61\n",
      "Iter 111 time=0.07  loss=15083.98 active=31800 feature_norm=168.60\n",
      "Iter 112 time=0.06  loss=15082.83 active=31788 feature_norm=168.65\n",
      "Iter 113 time=0.06  loss=15081.79 active=31784 feature_norm=168.64\n",
      "Iter 114 time=0.06  loss=15080.61 active=31786 feature_norm=168.67\n",
      "Iter 115 time=0.06  loss=15079.89 active=31775 feature_norm=168.66\n",
      "Iter 116 time=0.06  loss=15079.12 active=31773 feature_norm=168.70\n",
      "Iter 117 time=0.06  loss=15078.26 active=31756 feature_norm=168.69\n",
      "Iter 118 time=0.06  loss=15077.21 active=31767 feature_norm=168.72\n",
      "Iter 119 time=0.06  loss=15076.50 active=31774 feature_norm=168.71\n",
      "Iter 120 time=0.06  loss=15075.62 active=31767 feature_norm=168.74\n",
      "Iter 121 time=0.06  loss=15075.35 active=31751 feature_norm=168.73\n",
      "Iter 122 time=0.06  loss=15074.18 active=31755 feature_norm=168.76\n",
      "Iter 123 time=0.06  loss=15073.66 active=31749 feature_norm=168.76\n",
      "Iter 124 time=0.06  loss=15072.67 active=31750 feature_norm=168.78\n",
      "Iter 125 time=0.06  loss=15072.21 active=31738 feature_norm=168.78\n",
      "Iter 126 time=0.06  loss=15071.39 active=31729 feature_norm=168.81\n",
      "Iter 127 time=0.06  loss=15071.16 active=31734 feature_norm=168.80\n",
      "Iter 128 time=0.06  loss=15070.12 active=31737 feature_norm=168.83\n",
      "Iter 129 time=0.07  loss=15069.59 active=31733 feature_norm=168.83\n",
      "Iter 130 time=0.06  loss=15069.04 active=31725 feature_norm=168.85\n",
      "Iter 131 time=0.06  loss=15068.56 active=31716 feature_norm=168.85\n",
      "Iter 132 time=0.06  loss=15067.83 active=31712 feature_norm=168.88\n",
      "Iter 133 time=0.06  loss=15067.37 active=31712 feature_norm=168.88\n",
      "Iter 134 time=0.06  loss=15066.81 active=31708 feature_norm=168.90\n",
      "Iter 135 time=0.06  loss=15066.24 active=31708 feature_norm=168.90\n",
      "Iter 136 time=0.06  loss=15065.91 active=31694 feature_norm=168.92\n",
      "Iter 137 time=0.06  loss=15065.43 active=31688 feature_norm=168.92\n",
      "Iter 138 time=0.06  loss=15064.85 active=31688 feature_norm=168.95\n",
      "Iter 139 time=0.06  loss=15064.33 active=31693 feature_norm=168.94\n",
      "Iter 140 time=0.07  loss=15063.84 active=31677 feature_norm=168.96\n",
      "Iter 141 time=0.07  loss=15063.44 active=31664 feature_norm=168.96\n",
      "Iter 142 time=0.06  loss=15062.82 active=31660 feature_norm=168.98\n",
      "Iter 143 time=0.07  loss=15062.35 active=31654 feature_norm=168.98\n",
      "Iter 144 time=0.06  loss=15061.78 active=31647 feature_norm=169.00\n",
      "Iter 145 time=0.06  loss=15061.46 active=31650 feature_norm=169.00\n",
      "Iter 146 time=0.06  loss=15060.77 active=31643 feature_norm=169.02\n",
      "Iter 147 time=0.06  loss=15060.31 active=31643 feature_norm=169.02\n",
      "Iter 148 time=0.06  loss=15059.63 active=31637 feature_norm=169.04\n",
      "Iter 149 time=0.06  loss=15059.33 active=31627 feature_norm=169.03\n",
      "Iter 150 time=0.06  loss=15058.56 active=31622 feature_norm=169.05\n",
      "Iter 151 time=0.07  loss=15058.40 active=31627 feature_norm=169.04\n",
      "Iter 152 time=0.06  loss=15057.53 active=31623 feature_norm=169.06\n",
      "Iter 153 time=0.06  loss=15057.18 active=31631 feature_norm=169.06\n",
      "Iter 154 time=0.06  loss=15056.56 active=31625 feature_norm=169.07\n",
      "Iter 155 time=0.06  loss=15056.33 active=31627 feature_norm=169.06\n",
      "Iter 156 time=0.06  loss=15055.66 active=31625 feature_norm=169.07\n",
      "Iter 157 time=0.06  loss=15055.42 active=31620 feature_norm=169.06\n",
      "Iter 158 time=0.07  loss=15054.78 active=31620 feature_norm=169.07\n",
      "Iter 159 time=0.06  loss=15054.65 active=31613 feature_norm=169.05\n",
      "Iter 160 time=0.07  loss=15053.99 active=31608 feature_norm=169.07\n",
      "Iter 161 time=0.07  loss=15053.73 active=31607 feature_norm=169.05\n",
      "Iter 162 time=0.06  loss=15053.27 active=31602 feature_norm=169.06\n",
      "Iter 163 time=0.07  loss=15052.99 active=31596 feature_norm=169.05\n",
      "Iter 164 time=0.07  loss=15052.48 active=31594 feature_norm=169.05\n",
      "Iter 165 time=0.07  loss=15052.27 active=31593 feature_norm=169.04\n",
      "Iter 166 time=0.07  loss=15051.70 active=31587 feature_norm=169.05\n",
      "Iter 167 time=0.07  loss=15051.52 active=31591 feature_norm=169.03\n",
      "Iter 168 time=0.06  loss=15050.99 active=31592 feature_norm=169.04\n",
      "Iter 169 time=0.07  loss=15050.83 active=31587 feature_norm=169.03\n",
      "Iter 170 time=0.06  loss=15050.35 active=31586 feature_norm=169.03\n",
      "Iter 171 time=0.06  loss=15050.23 active=31575 feature_norm=169.02\n",
      "Iter 172 time=0.06  loss=15049.69 active=31562 feature_norm=169.03\n",
      "Iter 173 time=0.06  loss=15049.56 active=31562 feature_norm=169.01\n",
      "Iter 174 time=0.06  loss=15049.11 active=31558 feature_norm=169.02\n",
      "Iter 175 time=0.07  loss=15048.93 active=31556 feature_norm=169.00\n",
      "Iter 176 time=0.07  loss=15048.53 active=31550 feature_norm=169.01\n",
      "Iter 177 time=0.07  loss=15048.46 active=31549 feature_norm=168.99\n",
      "Iter 178 time=0.06  loss=15047.96 active=31549 feature_norm=169.01\n",
      "Iter 179 time=0.07  loss=15047.89 active=31550 feature_norm=168.99\n",
      "Iter 180 time=0.07  loss=15047.43 active=31548 feature_norm=169.00\n",
      "Iter 181 time=0.07  loss=15047.30 active=31548 feature_norm=168.99\n",
      "Iter 182 time=0.07  loss=15046.92 active=31535 feature_norm=168.99\n",
      "Iter 183 time=0.07  loss=15046.91 active=31536 feature_norm=168.98\n",
      "Iter 184 time=0.06  loss=15046.47 active=31527 feature_norm=168.99\n",
      "Iter 185 time=0.06  loss=15046.44 active=31530 feature_norm=168.98\n",
      "Iter 186 time=0.06  loss=15046.08 active=31531 feature_norm=168.98\n",
      "Iter 187 time=0.07  loss=15045.98 active=31525 feature_norm=168.97\n",
      "Iter 188 time=0.07  loss=15045.64 active=31525 feature_norm=168.98\n",
      "Iter 189 time=0.07  loss=15045.45 active=31524 feature_norm=168.97\n",
      "Iter 190 time=0.06  loss=15045.33 active=31519 feature_norm=168.97\n",
      "Iter 191 time=0.06  loss=15045.06 active=31511 feature_norm=168.96\n",
      "Iter 192 time=0.06  loss=15044.75 active=31509 feature_norm=168.96\n",
      "Iter 193 time=0.06  loss=15044.52 active=31512 feature_norm=168.95\n",
      "Iter 194 time=0.06  loss=15044.31 active=31513 feature_norm=168.94\n",
      "Iter 195 time=0.06  loss=15044.09 active=31499 feature_norm=168.92\n",
      "Iter 196 time=0.06  loss=15043.74 active=31496 feature_norm=168.92\n",
      "Iter 197 time=0.06  loss=15043.54 active=31500 feature_norm=168.91\n",
      "Iter 198 time=0.07  loss=15043.28 active=31504 feature_norm=168.91\n",
      "Iter 199 time=0.06  loss=15043.09 active=31505 feature_norm=168.89\n",
      "Iter 200 time=0.06  loss=15042.78 active=31498 feature_norm=168.89\n",
      "Iter 201 time=0.07  loss=15042.58 active=31497 feature_norm=168.87\n",
      "Iter 202 time=0.06  loss=15042.31 active=31494 feature_norm=168.88\n",
      "Iter 203 time=0.06  loss=15042.14 active=31490 feature_norm=168.86\n",
      "Iter 204 time=0.06  loss=15041.89 active=31484 feature_norm=168.86\n",
      "Iter 205 time=0.06  loss=15041.71 active=31471 feature_norm=168.84\n",
      "Iter 206 time=0.06  loss=15041.45 active=31461 feature_norm=168.84\n",
      "Iter 207 time=0.06  loss=15041.29 active=31456 feature_norm=168.83\n",
      "Iter 208 time=0.07  loss=15041.06 active=31455 feature_norm=168.83\n",
      "Iter 209 time=0.06  loss=15040.91 active=31456 feature_norm=168.81\n",
      "Iter 210 time=0.06  loss=15040.68 active=31447 feature_norm=168.81\n",
      "Iter 211 time=0.06  loss=15040.55 active=31444 feature_norm=168.80\n",
      "Iter 212 time=0.06  loss=15040.32 active=31438 feature_norm=168.80\n",
      "Iter 213 time=0.06  loss=15040.19 active=31442 feature_norm=168.78\n",
      "Iter 214 time=0.06  loss=15039.96 active=31438 feature_norm=168.78\n",
      "Iter 215 time=0.06  loss=15039.84 active=31430 feature_norm=168.77\n",
      "Iter 216 time=0.06  loss=15039.62 active=31422 feature_norm=168.77\n",
      "Iter 217 time=0.06  loss=15039.50 active=31427 feature_norm=168.76\n",
      "Iter 218 time=0.06  loss=15039.29 active=31420 feature_norm=168.76\n",
      "Iter 219 time=0.06  loss=15039.18 active=31427 feature_norm=168.75\n",
      "Iter 220 time=0.06  loss=15038.97 active=31426 feature_norm=168.75\n",
      "Iter 221 time=0.06  loss=15038.87 active=31423 feature_norm=168.74\n",
      "Iter 222 time=0.07  loss=15038.67 active=31421 feature_norm=168.74\n",
      "Iter 223 time=0.06  loss=15038.55 active=31420 feature_norm=168.73\n",
      "Iter 224 time=0.06  loss=15038.38 active=31423 feature_norm=168.73\n",
      "Iter 225 time=0.07  loss=15038.30 active=31428 feature_norm=168.72\n",
      "Iter 226 time=0.07  loss=15038.11 active=31422 feature_norm=168.72\n",
      "Iter 227 time=0.07  loss=15038.01 active=31421 feature_norm=168.71\n",
      "Iter 228 time=0.07  loss=15037.83 active=31418 feature_norm=168.71\n",
      "Iter 229 time=0.06  loss=15037.72 active=31413 feature_norm=168.70\n",
      "Iter 230 time=0.06  loss=15037.58 active=31403 feature_norm=168.70\n",
      "Iter 231 time=0.06  loss=15037.48 active=31400 feature_norm=168.69\n",
      "Iter 232 time=0.06  loss=15037.28 active=31399 feature_norm=168.69\n",
      "Iter 233 time=0.06  loss=15037.15 active=31394 feature_norm=168.68\n",
      "Iter 234 time=0.06  loss=15037.01 active=31392 feature_norm=168.68\n",
      "Iter 235 time=0.07  loss=15036.94 active=31375 feature_norm=168.67\n",
      "Iter 236 time=0.07  loss=15036.71 active=31368 feature_norm=168.67\n",
      "Iter 237 time=0.06  loss=15036.59 active=31372 feature_norm=168.66\n",
      "Iter 238 time=0.07  loss=15036.44 active=31365 feature_norm=168.66\n",
      "Iter 239 time=0.07  loss=15036.34 active=31366 feature_norm=168.65\n",
      "Iter 240 time=0.06  loss=15036.20 active=31361 feature_norm=168.65\n",
      "Iter 241 time=0.06  loss=15036.10 active=31359 feature_norm=168.64\n",
      "Iter 242 time=0.06  loss=15035.95 active=31360 feature_norm=168.64\n",
      "Iter 243 time=0.06  loss=15035.85 active=31358 feature_norm=168.63\n",
      "Iter 244 time=0.07  loss=15035.73 active=31354 feature_norm=168.63\n",
      "Iter 245 time=0.06  loss=15035.63 active=31348 feature_norm=168.62\n",
      "Iter 246 time=0.06  loss=15035.51 active=31343 feature_norm=168.62\n",
      "Iter 247 time=0.06  loss=15035.41 active=31334 feature_norm=168.61\n",
      "Iter 248 time=0.06  loss=15035.30 active=31330 feature_norm=168.61\n",
      "Iter 249 time=0.07  loss=15035.24 active=31331 feature_norm=168.60\n",
      "Iter 250 time=0.06  loss=15035.10 active=31334 feature_norm=168.61\n",
      "Iter 251 time=0.07  loss=15035.02 active=31337 feature_norm=168.60\n",
      "Iter 252 time=0.06  loss=15034.92 active=31335 feature_norm=168.60\n",
      "Iter 253 time=0.06  loss=15034.84 active=31334 feature_norm=168.59\n",
      "Iter 254 time=0.06  loss=15034.74 active=31331 feature_norm=168.59\n",
      "Iter 255 time=0.07  loss=15034.68 active=31326 feature_norm=168.58\n",
      "Iter 256 time=0.07  loss=15034.56 active=31323 feature_norm=168.59\n",
      "Iter 257 time=0.06  loss=15034.51 active=31312 feature_norm=168.58\n",
      "Iter 258 time=0.06  loss=15034.40 active=31306 feature_norm=168.58\n",
      "Iter 259 time=0.06  loss=15034.35 active=31304 feature_norm=168.57\n",
      "Iter 260 time=0.06  loss=15034.24 active=31297 feature_norm=168.57\n",
      "Iter 261 time=0.06  loss=15034.19 active=31297 feature_norm=168.56\n",
      "Iter 262 time=0.06  loss=15034.09 active=31293 feature_norm=168.57\n",
      "Iter 263 time=0.06  loss=15034.05 active=31297 feature_norm=168.56\n",
      "Iter 264 time=0.06  loss=15033.94 active=31292 feature_norm=168.56\n",
      "Iter 265 time=0.06  loss=15033.90 active=31296 feature_norm=168.55\n",
      "Iter 266 time=0.07  loss=15033.80 active=31292 feature_norm=168.55\n",
      "Iter 267 time=0.07  loss=15033.74 active=31289 feature_norm=168.55\n",
      "Iter 268 time=0.07  loss=15033.66 active=31289 feature_norm=168.55\n",
      "Iter 269 time=0.07  loss=15033.62 active=31284 feature_norm=168.54\n",
      "Iter 270 time=0.07  loss=15033.51 active=31287 feature_norm=168.54\n",
      "Iter 271 time=0.07  loss=15033.46 active=31287 feature_norm=168.54\n",
      "Iter 272 time=0.06  loss=15033.37 active=31288 feature_norm=168.54\n",
      "Iter 273 time=0.06  loss=15033.33 active=31288 feature_norm=168.53\n",
      "Iter 274 time=0.07  loss=15033.23 active=31291 feature_norm=168.53\n",
      "Iter 275 time=0.06  loss=15033.19 active=31289 feature_norm=168.53\n",
      "Iter 276 time=0.06  loss=15033.08 active=31282 feature_norm=168.53\n",
      "Iter 277 time=0.06  loss=15033.05 active=31284 feature_norm=168.52\n",
      "Iter 278 time=0.07  loss=15032.94 active=31283 feature_norm=168.53\n",
      "Iter 279 time=0.06  loss=15032.89 active=31275 feature_norm=168.52\n",
      "Iter 280 time=0.06  loss=15032.79 active=31274 feature_norm=168.52\n",
      "Iter 281 time=0.06  loss=15032.77 active=31270 feature_norm=168.52\n",
      "Iter 282 time=0.06  loss=15032.66 active=31265 feature_norm=168.52\n",
      "Iter 283 time=0.06  loss=15032.63 active=31270 feature_norm=168.51\n",
      "Iter 284 time=0.06  loss=15032.54 active=31267 feature_norm=168.52\n",
      "Iter 285 time=0.06  loss=15032.49 active=31264 feature_norm=168.52\n",
      "Iter 286 time=0.06  loss=15032.41 active=31260 feature_norm=168.52\n",
      "Iter 287 time=0.06  loss=15032.38 active=31255 feature_norm=168.51\n",
      "Iter 288 time=0.07  loss=15032.28 active=31248 feature_norm=168.52\n",
      "Iter 289 time=0.06  loss=15032.24 active=31248 feature_norm=168.51\n",
      "Iter 290 time=0.06  loss=15032.15 active=31242 feature_norm=168.52\n",
      "Iter 291 time=0.06  loss=15032.11 active=31244 feature_norm=168.52\n",
      "Iter 292 time=0.06  loss=15032.03 active=31244 feature_norm=168.52\n",
      "Iter 293 time=0.06  loss=15031.99 active=31246 feature_norm=168.52\n",
      "Iter 294 time=0.06  loss=15031.89 active=31242 feature_norm=168.52\n",
      "Iter 295 time=0.06  loss=15031.86 active=31236 feature_norm=168.52\n",
      "Iter 296 time=0.06  loss=15031.76 active=31243 feature_norm=168.52\n",
      "Iter 297 time=0.06  loss=15031.73 active=31244 feature_norm=168.52\n",
      "Iter 298 time=0.06  loss=15031.64 active=31237 feature_norm=168.53\n",
      "Iter 299 time=0.06  loss=15031.61 active=31240 feature_norm=168.52\n",
      "Iter 300 time=0.06  loss=15031.52 active=31242 feature_norm=168.53\n",
      "Iter 301 time=0.06  loss=15031.49 active=31243 feature_norm=168.52\n",
      "Iter 302 time=0.06  loss=15031.40 active=31243 feature_norm=168.53\n",
      "Iter 303 time=0.06  loss=15031.37 active=31235 feature_norm=168.52\n",
      "Iter 304 time=0.06  loss=15031.30 active=31236 feature_norm=168.53\n",
      "Iter 305 time=0.07  loss=15031.25 active=31228 feature_norm=168.52\n",
      "Iter 306 time=0.06  loss=15031.19 active=31229 feature_norm=168.52\n",
      "Iter 307 time=0.07  loss=15031.18 active=31226 feature_norm=168.52\n",
      "Iter 308 time=0.07  loss=15031.08 active=31228 feature_norm=168.52\n",
      "Iter 309 time=0.07  loss=15031.06 active=31227 feature_norm=168.52\n",
      "Iter 310 time=0.06  loss=15030.98 active=31225 feature_norm=168.52\n",
      "Iter 311 time=0.06  loss=15030.96 active=31225 feature_norm=168.52\n",
      "Iter 312 time=0.07  loss=15030.89 active=31223 feature_norm=168.52\n",
      "Iter 313 time=0.06  loss=15030.86 active=31220 feature_norm=168.51\n",
      "Iter 314 time=0.07  loss=15030.80 active=31220 feature_norm=168.52\n",
      "Iter 315 time=0.07  loss=15030.80 active=31217 feature_norm=168.51\n",
      "Iter 316 time=0.07  loss=15030.70 active=31213 feature_norm=168.51\n",
      "Iter 317 time=0.06  loss=15030.70 active=31215 feature_norm=168.51\n",
      "Iter 318 time=0.07  loss=15030.61 active=31216 feature_norm=168.51\n",
      "Iter 319 time=0.07  loss=15030.59 active=31218 feature_norm=168.51\n",
      "Iter 320 time=0.06  loss=15030.53 active=31220 feature_norm=168.51\n",
      "Iter 321 time=0.06  loss=15030.51 active=31219 feature_norm=168.51\n",
      "Iter 322 time=0.07  loss=15030.45 active=31216 feature_norm=168.51\n",
      "Iter 323 time=0.06  loss=15030.44 active=31209 feature_norm=168.50\n",
      "Iter 324 time=0.06  loss=15030.37 active=31207 feature_norm=168.51\n",
      "Iter 325 time=0.06  loss=15030.36 active=31201 feature_norm=168.50\n",
      "Iter 326 time=0.06  loss=15030.29 active=31205 feature_norm=168.50\n",
      "Iter 327 time=0.07  loss=15030.27 active=31203 feature_norm=168.50\n",
      "Iter 328 time=0.06  loss=15030.21 active=31203 feature_norm=168.50\n",
      "Iter 329 time=0.06  loss=15030.20 active=31193 feature_norm=168.50\n",
      "Iter 330 time=0.07  loss=15030.14 active=31191 feature_norm=168.50\n",
      "Iter 331 time=0.07  loss=15030.12 active=31181 feature_norm=168.50\n",
      "Iter 332 time=0.07  loss=15030.07 active=31179 feature_norm=168.50\n",
      "Iter 333 time=0.07  loss=15030.05 active=31171 feature_norm=168.49\n",
      "Iter 334 time=0.07  loss=15030.00 active=31175 feature_norm=168.50\n",
      "Iter 335 time=0.07  loss=15029.98 active=31175 feature_norm=168.49\n",
      "Iter 336 time=0.07  loss=15029.93 active=31173 feature_norm=168.50\n",
      "Iter 337 time=0.06  loss=15029.93 active=31172 feature_norm=168.49\n",
      "Iter 338 time=0.07  loss=15029.87 active=31176 feature_norm=168.50\n",
      "Iter 339 time=0.06  loss=15029.85 active=31177 feature_norm=168.49\n",
      "Iter 340 time=0.07  loss=15029.81 active=31178 feature_norm=168.50\n",
      "Iter 341 time=0.07  loss=15029.78 active=31175 feature_norm=168.49\n",
      "Iter 342 time=0.06  loss=15029.74 active=31171 feature_norm=168.49\n",
      "Iter 343 time=0.06  loss=15029.73 active=31165 feature_norm=168.49\n",
      "Iter 344 time=0.07  loss=15029.68 active=31165 feature_norm=168.49\n",
      "Iter 345 time=0.07  loss=15029.67 active=31169 feature_norm=168.49\n",
      "Iter 346 time=0.06  loss=15029.63 active=31166 feature_norm=168.49\n",
      "Iter 347 time=0.06  loss=15029.61 active=31161 feature_norm=168.49\n",
      "Iter 348 time=0.07  loss=15029.58 active=31160 feature_norm=168.49\n",
      "Iter 349 time=0.07  loss=15029.55 active=31158 feature_norm=168.49\n",
      "Iter 350 time=0.07  loss=15029.52 active=31154 feature_norm=168.49\n",
      "Iter 351 time=0.07  loss=15029.50 active=31152 feature_norm=168.49\n",
      "Iter 352 time=0.07  loss=15029.47 active=31144 feature_norm=168.49\n",
      "Iter 353 time=0.07  loss=15029.45 active=31147 feature_norm=168.48\n",
      "Iter 354 time=0.06  loss=15029.41 active=31144 feature_norm=168.49\n",
      "Iter 355 time=0.06  loss=15029.40 active=31136 feature_norm=168.48\n",
      "Iter 356 time=0.06  loss=15029.36 active=31135 feature_norm=168.49\n",
      "Iter 357 time=0.07  loss=15029.34 active=31133 feature_norm=168.48\n",
      "Iter 358 time=0.06  loss=15029.30 active=31133 feature_norm=168.48\n",
      "Iter 359 time=0.06  loss=15029.29 active=31127 feature_norm=168.48\n",
      "Iter 360 time=0.06  loss=15029.25 active=31127 feature_norm=168.48\n",
      "Iter 361 time=0.06  loss=15029.24 active=31124 feature_norm=168.48\n",
      "Iter 362 time=0.07  loss=15029.20 active=31125 feature_norm=168.48\n",
      "Iter 363 time=0.06  loss=15029.18 active=31123 feature_norm=168.48\n",
      "Iter 364 time=0.06  loss=15029.15 active=31122 feature_norm=168.48\n",
      "Iter 365 time=0.07  loss=15029.14 active=31121 feature_norm=168.48\n",
      "Iter 366 time=0.06  loss=15029.10 active=31118 feature_norm=168.48\n",
      "Iter 367 time=0.06  loss=15029.08 active=31118 feature_norm=168.48\n",
      "Iter 368 time=0.06  loss=15029.05 active=31115 feature_norm=168.48\n",
      "Iter 369 time=0.06  loss=15029.04 active=31116 feature_norm=168.48\n",
      "Iter 370 time=0.06  loss=15028.99 active=31109 feature_norm=168.48\n",
      "Iter 371 time=0.06  loss=15028.97 active=31114 feature_norm=168.48\n",
      "Iter 372 time=0.06  loss=15028.94 active=31115 feature_norm=168.48\n",
      "Iter 373 time=0.06  loss=15028.92 active=31117 feature_norm=168.47\n",
      "Iter 374 time=0.06  loss=15028.89 active=31119 feature_norm=168.48\n",
      "Iter 375 time=0.06  loss=15028.87 active=31121 feature_norm=168.47\n",
      "Iter 376 time=0.06  loss=15028.83 active=31115 feature_norm=168.48\n",
      "Iter 377 time=0.06  loss=15028.82 active=31110 feature_norm=168.47\n",
      "Iter 378 time=0.06  loss=15028.77 active=31110 feature_norm=168.48\n",
      "Iter 379 time=0.06  loss=15028.75 active=31111 feature_norm=168.47\n",
      "Iter 380 time=0.06  loss=15028.72 active=31113 feature_norm=168.47\n",
      "Iter 381 time=0.06  loss=15028.70 active=31121 feature_norm=168.47\n",
      "Iter 382 time=0.06  loss=15028.67 active=31118 feature_norm=168.47\n",
      "Iter 383 time=0.06  loss=15028.66 active=31118 feature_norm=168.47\n",
      "Iter 384 time=0.07  loss=15028.62 active=31111 feature_norm=168.47\n",
      "Iter 385 time=0.06  loss=15028.60 active=31119 feature_norm=168.47\n",
      "Iter 386 time=0.06  loss=15028.58 active=31118 feature_norm=168.47\n",
      "Iter 387 time=0.06  loss=15028.57 active=31119 feature_norm=168.47\n",
      "Iter 388 time=0.07  loss=15028.54 active=31118 feature_norm=168.47\n",
      "Iter 389 time=0.07  loss=15028.53 active=31120 feature_norm=168.47\n",
      "Iter 390 time=0.06  loss=15028.51 active=31117 feature_norm=168.47\n",
      "Iter 391 time=0.06  loss=15028.50 active=31114 feature_norm=168.47\n",
      "Iter 392 time=0.06  loss=15028.47 active=31112 feature_norm=168.47\n",
      "Iter 393 time=0.06  loss=15028.46 active=31111 feature_norm=168.47\n",
      "Iter 394 time=0.06  loss=15028.44 active=31108 feature_norm=168.47\n",
      "Iter 395 time=0.07  loss=15028.43 active=31106 feature_norm=168.47\n",
      "Iter 396 time=0.06  loss=15028.41 active=31108 feature_norm=168.48\n",
      "Iter 397 time=0.06  loss=15028.40 active=31109 feature_norm=168.47\n",
      "Iter 398 time=0.06  loss=15028.38 active=31112 feature_norm=168.48\n",
      "Iter 399 time=0.06  loss=15028.37 active=31111 feature_norm=168.47\n",
      "Iter 400 time=0.07  loss=15028.34 active=31110 feature_norm=168.47\n",
      "Iter 401 time=0.07  loss=15028.33 active=31111 feature_norm=168.47\n",
      "Iter 402 time=0.06  loss=15028.31 active=31109 feature_norm=168.47\n",
      "Iter 403 time=0.06  loss=15028.30 active=31112 feature_norm=168.47\n",
      "Iter 404 time=0.06  loss=15028.27 active=31113 feature_norm=168.47\n",
      "Iter 405 time=0.06  loss=15028.26 active=31107 feature_norm=168.47\n",
      "Iter 406 time=0.07  loss=15028.24 active=31104 feature_norm=168.47\n",
      "Iter 407 time=0.07  loss=15028.23 active=31099 feature_norm=168.47\n",
      "Iter 408 time=0.07  loss=15028.21 active=31093 feature_norm=168.48\n",
      "Iter 409 time=0.06  loss=15028.20 active=31090 feature_norm=168.47\n",
      "Iter 410 time=0.06  loss=15028.18 active=31083 feature_norm=168.47\n",
      "Iter 411 time=0.06  loss=15028.17 active=31086 feature_norm=168.47\n",
      "Iter 412 time=0.06  loss=15028.15 active=31089 feature_norm=168.47\n",
      "Iter 413 time=0.06  loss=15028.13 active=31088 feature_norm=168.47\n",
      "Iter 414 time=0.06  loss=15028.12 active=31088 feature_norm=168.47\n",
      "Iter 415 time=0.06  loss=15028.11 active=31085 feature_norm=168.47\n",
      "Iter 416 time=0.06  loss=15028.09 active=31084 feature_norm=168.47\n",
      "Iter 417 time=0.06  loss=15028.07 active=31081 feature_norm=168.47\n",
      "Iter 418 time=0.06  loss=15028.06 active=31077 feature_norm=168.47\n",
      "L-BFGS terminated with the stopping criteria\n",
      "Total seconds required for training: 26.884\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 31077 (88941)\n",
      "Number of active attributes: 23000 (78388)\n",
      "Number of active labels: 4 (4)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', #Градиентный спуск с использованием метода L-BFGS\n",
    "    c1=0.1, #Коэффициент для регуляризации L1\n",
    "    c2=0.1, #Коэффициент для регуляризации L2\n",
    "    max_iterations=1000, #Максимальное количество итераций\n",
    "    all_possible_transitions=True, #Генерация объектов (не встречающихся в обучающих данных)\n",
    "    verbose=True #Включение режима тренировки\n",
    ")\n",
    "\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d0a5d138",
   "metadata": {
    "cellId": "1cwcsas309o7bp8b2e2ogu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entities = sorted(df.entities.unique().tolist())\n",
    "len(all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db36ba9d",
   "metadata": {
    "cellId": "au4dndmb5k55baq7o2aad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=all_entities)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "220d0839",
   "metadata": {
    "cellId": "s67ot0frnsfvs6nyul4m"
   },
   "source": [
    "print(metrics.flat_classification_report(y_test, y_pred, labels=all_entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8e106",
   "metadata": {
    "cellId": "up0oeb8dvpp1ppqwag6bmb",
    "execution_id": "bd4c015f-2449-43f7-87b6-1e1f3a2b7f3a"
   },
   "source": [
    "### <a id='Выводы_5.2'>2.6 Выводы</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc313e0",
   "metadata": {
    "cellId": "oeped1xzwooqbcjkr4csi",
    "execution_id": "65f927a8-f151-4871-a28c-4d30936c1f8c"
   },
   "source": [
    "Готовые решения NER из spacy и nltk показывают хорошие результаты в задачах извлечения именованных сущностей. Не получилось извлечь NER с помощью готовых решений из slovnet и deeppavlov. При составлении собственного алгоритма NER не получилось определить метрики."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "da5325f9-c0f7-41b9-87a3-f11dfc65de06",
  "notebookPath": "5_Part-of-Speech_разметка_NER/ДЗ_5.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

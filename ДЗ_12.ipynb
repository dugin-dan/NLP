{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5668c43b",
   "metadata": {
    "cellId": "lttcxbnklgm4wzkh77v4ka",
    "execution_id": "12745a0a-0ee6-4db3-ae92-873390899281"
   },
   "source": [
    "# <a id='Урок_12'>Домашнее задание №12. Модель Transformer-2 (Text Summarization)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb6bd9",
   "metadata": {
    "cellId": "3028f8qqrzgnm40l0p5vz9",
    "execution_id": "0e934201-4cb7-4354-a4cf-7da8c1b1a9f9"
   },
   "source": [
    "## <a id='Задание_12'>Задание</a>\n",
    "\n",
    "1. Реализовать суммаризацию текста\n",
    "Взять тот же датасет, который был на вебинаре и предобученную модель для задачи суммаризации\n",
    "Проверить насколько хорошо она суммаризирует\n",
    "2. (дополнительно) Сделать генерацию заголовков для статьи (обучить модель для генерации заголовков)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd9115",
   "metadata": {
    "cellId": "q0jgmjwbhvkj40gwvrinl",
    "execution_id": "9c34b4d6-606c-48f7-b576-20df2f4f5d1f"
   },
   "source": [
    "## <a id='Подготовка_12'>Подготовка</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8369952d",
   "metadata": {
    "cellId": "rfr0xw073wsxp5qy0ckbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import GRU, AdditiveAttention\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e1fa6",
   "metadata": {
    "cellId": "75kw7p6lo9ejt2jcx95r0e",
    "execution_id": "ad4f33af-a863-40e0-a3d1-aff0bc834b2f"
   },
   "source": [
    "## <a id='Загрузка_данных_12'>Загрузка данных</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f693172d",
   "metadata": {
    "cellId": "890oixkcwcnje88z7en3gn"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4c2d9f70d4468dad777bc776e5893a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96f30895cbf43059b702e10c19ebcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/3.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7ed4fc778247e1bea052f37c96da95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/12.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: gazeta/default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset gazeta/default (download: 545.11 MiB, generated: 542.44 MiB, post-processed: Unknown size, total: 1.06 GiB) to /tmp/xdg_cache/huggingface/datasets/IlyaGusev___gazeta/default/1.0.0/ef9349c3c0f3112ca4036520d76c4bc1b8a79d30bc29643c6cae5a094d44e457...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5a4f84886a499db5b39425f78fb654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc39b68baaa44b9684f6f0a12e424cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f6e24dce3f4ef988da7206088445e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/48.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c8ad37f1b847f384056bc7d8059fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/52.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34753c1bfa3f4b5e848b99f232fca9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b86ec25d0754d1d8ff89651df9314ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/52400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f155df5cd7435bbc7714ad0c9896de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5770 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3dcf8d3ea14cc8a4e7732922fc2637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset gazeta downloaded and prepared to /tmp/xdg_cache/huggingface/datasets/IlyaGusev___gazeta/default/1.0.0/ef9349c3c0f3112ca4036520d76c4bc1b8a79d30bc29643c6cae5a094d44e457. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9df447ba234d7d9ba3a9bf0c86a810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Загрузка датасета\n",
    "dataset = load_dataset('IlyaGusev/gazeta', revision=\"v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527dc585",
   "metadata": {
    "cellId": "g4d631wgrmy8k9ol6wj5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'summary', 'title', 'date', 'url'],\n",
       "        num_rows: 52400\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'summary', 'title', 'date', 'url'],\n",
       "        num_rows: 5770\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'summary', 'title', 'date', 'url'],\n",
       "        num_rows: 5265\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Структура датасета\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb849ce",
   "metadata": {
    "cellId": "ap8o2ar4q4ugk0y8nb85nf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>«По итогам 2011 года чистый отток может состав...</td>\n",
       "      <td>В 2011 году из России уйдет $80 млрд, считают ...</td>\n",
       "      <td>Прогноз не успевает за оттоком</td>\n",
       "      <td>2011-11-30 18:33:39</td>\n",
       "      <td>https://www.gazeta.ru/financial/2011/11/30/385...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Российское подразделение интернет-корпорации G...</td>\n",
       "      <td>Юлия Соловьева, экс-директор холдинга «Профмед...</td>\n",
       "      <td>Google закончил поиск</td>\n",
       "      <td>2013-01-24 18:20:09</td>\n",
       "      <td>https://www.gazeta.ru/business/2013/01/24/4939...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Басманный районный суд Москвы вечером 6 феврал...</td>\n",
       "      <td>Суд арестовал на два месяца четверых экс-чинов...</td>\n",
       "      <td>«Фигуранты дела могут давить на свидетелей»</td>\n",
       "      <td>2018-02-06 21:21:14</td>\n",
       "      <td>https://www.gazeta.ru/social/2018/02/06/116393...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Как повлияло вступление в ВТО на конкурентносп...</td>\n",
       "      <td>Мнения предпринимателей по поводу вступления в...</td>\n",
       "      <td>«С последних традиционно «отжимают» больше»</td>\n",
       "      <td>2013-06-21 17:43:50</td>\n",
       "      <td>https://www.gazeta.ru/business/2013/06/21/5388...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>К третьему сезону «Голос» на Первом канале ста...</td>\n",
       "      <td>На Первом канале завершился третий сезон шоу «...</td>\n",
       "      <td>Третий «Голос» за Градского</td>\n",
       "      <td>2014-12-27 01:10:01</td>\n",
       "      <td>https://www.gazeta.ru/culture/2014/12/27/a_636...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ...                                                url\n",
       "0  «По итогам 2011 года чистый отток может состав...  ...  https://www.gazeta.ru/financial/2011/11/30/385...\n",
       "1  Российское подразделение интернет-корпорации G...  ...  https://www.gazeta.ru/business/2013/01/24/4939...\n",
       "2  Басманный районный суд Москвы вечером 6 феврал...  ...  https://www.gazeta.ru/social/2018/02/06/116393...\n",
       "3  Как повлияло вступление в ВТО на конкурентносп...  ...  https://www.gazeta.ru/business/2013/06/21/5388...\n",
       "4  К третьему сезону «Голос» на Первом канале ста...  ...  https://www.gazeta.ru/culture/2014/12/27/a_636...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Тренировочный датасет\n",
    "import pandas as pd\n",
    "df_train = pd.DataFrame(dataset['train'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84cf65a3",
   "metadata": {
    "cellId": "vk86qk4xq5l2ne06pmoqse"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>После громких приобретений Андре Шюррле, Гуса ...</td>\n",
       "      <td>Московский «Спартак» продолжает активную транс...</td>\n",
       "      <td>Замена Фернандо: кого может купить «Спартак»</td>\n",
       "      <td>2019-08-11 23:14:58</td>\n",
       "      <td>https://www.gazeta.ru/sport/2019/08/11/a_12572...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Американское издание The National Interest оце...</td>\n",
       "      <td>Издание The National Interest оценило перспект...</td>\n",
       "      <td>Шестое поколение: в США оценили российский бом...</td>\n",
       "      <td>2019-08-11 21:16:04</td>\n",
       "      <td>https://www.gazeta.ru/army/2019/08/11/12572317...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Министр иностранных дел России Сергей Лавров с...</td>\n",
       "      <td>Глава МИД России Сергей Лавров заявил, что в 2...</td>\n",
       "      <td>«Зачем гонять людей?»: США требуют новый рефер...</td>\n",
       "      <td>2019-06-06 09:47:35</td>\n",
       "      <td>https://www.gazeta.ru/politics/2019/06/06_a_12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Минфин предложил с января 2020 года увеличить ...</td>\n",
       "      <td>Министерство финансов предлагает вдвое поднять...</td>\n",
       "      <td>Перейти на отечественное: что будет с зарубежн...</td>\n",
       "      <td>2019-07-24 20:38:15</td>\n",
       "      <td>https://www.gazeta.ru/business/2019/07/24/1252...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Заявление командующего военно-воздушными силам...</td>\n",
       "      <td>Американские ПВО провалились в Саудовской Арав...</td>\n",
       "      <td>«Глупое заявление»: Медведев напомнил о провал...</td>\n",
       "      <td>2019-09-20 21:16:22</td>\n",
       "      <td>https://www.gazeta.ru/army/2019/09/20/12664933...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ...                                                url\n",
       "0  После громких приобретений Андре Шюррле, Гуса ...  ...  https://www.gazeta.ru/sport/2019/08/11/a_12572...\n",
       "1  Американское издание The National Interest оце...  ...  https://www.gazeta.ru/army/2019/08/11/12572317...\n",
       "2  Министр иностранных дел России Сергей Лавров с...  ...  https://www.gazeta.ru/politics/2019/06/06_a_12...\n",
       "3  Минфин предложил с января 2020 года увеличить ...  ...  https://www.gazeta.ru/business/2019/07/24/1252...\n",
       "4  Заявление командующего военно-воздушными силам...  ...  https://www.gazeta.ru/army/2019/09/20/12664933...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Валидационный датасет\n",
    "df_val = pd.DataFrame(dataset['validation'])\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59bd3c8a",
   "metadata": {
    "cellId": "w1ganjns3t9x5kr9q9zmu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Американское аэрокосмическое агентство NASA ог...</td>\n",
       "      <td>В NASA назвали четыре миссии в дальний космос,...</td>\n",
       "      <td>Венера, Ио или Тритон: куда полетит NASA</td>\n",
       "      <td>2020-02-14 16:39:11</td>\n",
       "      <td>https://www.gazeta.ru/science/2020/02/14_a_129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Около 11 тысяч зрителей увидели все самое лучш...</td>\n",
       "      <td>25 и 26 февраля в Кремлевском дворце съездов п...</td>\n",
       "      <td>«Люди в Бурятии очень талантливые»</td>\n",
       "      <td>2020-02-28 10:44:13</td>\n",
       "      <td>https://www.gazeta.ru/social/2020/02/28/129806...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7 ноября в Белоруссии прошли выборы членов сов...</td>\n",
       "      <td>В Белоруссии в день годовщины Октябрьской рево...</td>\n",
       "      <td>Вспомнить СССР: как Лукашенко провел выборы</td>\n",
       "      <td>2019-11-07 19:55:08</td>\n",
       "      <td>https://www.gazeta.ru/politics/2019/11/07_a_12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Народная артистка РСФСР Надежда Бабкина в инте...</td>\n",
       "      <td>Народная артистка РСФСР Надежда Бабкина в инте...</td>\n",
       "      <td>«Он очень переживал»: Бабкина об отношениях с ...</td>\n",
       "      <td>2020-03-01 16:50:06</td>\n",
       "      <td>https://www.gazeta.ru/culture/2020/03/01/a_129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Депутат Верховной рады от партии «Слуга народа...</td>\n",
       "      <td>Украина не должна выплачивать пенсии жителям Д...</td>\n",
       "      <td>«Поддерживают Россию»: почему Киев не платит п...</td>\n",
       "      <td>2020-02-06 12:41:24</td>\n",
       "      <td>https://www.gazeta.ru/business/2020/02/06/1294...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ...                                                url\n",
       "0  Американское аэрокосмическое агентство NASA ог...  ...  https://www.gazeta.ru/science/2020/02/14_a_129...\n",
       "1  Около 11 тысяч зрителей увидели все самое лучш...  ...  https://www.gazeta.ru/social/2020/02/28/129806...\n",
       "2  7 ноября в Белоруссии прошли выборы членов сов...  ...  https://www.gazeta.ru/politics/2019/11/07_a_12...\n",
       "3  Народная артистка РСФСР Надежда Бабкина в инте...  ...  https://www.gazeta.ru/culture/2020/03/01/a_129...\n",
       "4  Депутат Верховной рады от партии «Слуга народа...  ...  https://www.gazeta.ru/business/2020/02/06/1294...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Тестовый датасет\n",
    "df_test = pd.DataFrame(dataset['test'])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2802e87",
   "metadata": {
    "cellId": "pq4qa339xk5t6ln3bhbey",
    "execution_id": "cf8b44bc-9aff-4757-b661-c46b32a08587"
   },
   "source": [
    "## <a id='Предобученная_модель_12'>Предобученная модель summarization IlyaGusev/rut5_base_sum_gazeta</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ab99c3c",
   "metadata": {
    "cellId": "u5ix76qewajrj2u7eksrae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68f120bee2a49c1954659f95082f401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/279 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1fb1779e88413695b14215486bbf84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/808k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3091d49cad34ba293876fe94effb831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bc339fa7aa49c0ac84f31230e3d260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545f97f1d7d64a8f9772c2899cf520e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/766 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48723a99e0e746ee8f3135127ad40d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/932M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В Кремле прошло праздничное шоу «Танцуют все!» на телеканале «Россия». Зрителям рассказали, что в Бурятии сохранилась и развивается культура десятков национальностей, включая русских, бурятов, староверов и эвенков.\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Загрузка и инициализация модели\n",
    "model_name = \"IlyaGusev/rut5_base_sum_gazeta\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Пример работы модели\n",
    "article_text = df_test['text'][1]\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    [article_text],\n",
    "    max_length=600,\n",
    "    add_special_tokens=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")[\"input_ids\"]\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    no_repeat_ngram_size=4\n",
    ")[0]\n",
    "\n",
    "summary = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4447e4ef",
   "metadata": {
    "cellId": "jpbaqhvnujmrclco5zsc8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Функция подсчета метрик\n",
    "def calc_scores(references, predictions, metric=\"all\"):\n",
    "    print(\"Count:\", len(predictions))\n",
    "    print(\"Ref:\", references[-1])\n",
    "    print(\"Hyp:\", predictions[-1])\n",
    "\n",
    "    if metric in (\"bleu\", \"all\"):\n",
    "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
    "    if metric in (\"rouge\", \"all\"):\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(predictions, references, avg=True)\n",
    "        print(\"ROUGE: \", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a00918",
   "metadata": {
    "cellId": "xg0q8d6ifcsk6j4ic34g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 2\n",
      "Ref: Бурятия - центр российского буддизма и один из немногих регионов страны, где новый год встречают официально дважды.\n",
      "Hyp: Зрителям рассказали, что в Бурятии сохранилась и развивается культура десятков национальностей, включая русских, бурятов, староверов и эвенков.\n",
      "BLEU:  0.19334823151545613\n",
      "ROUGE:  {'rouge-1': {'r': 0.029411764705882353, 'p': 0.03125, 'f': 0.030303027805326194}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.029411764705882353, 'p': 0.03125, 'f': 0.030303027805326194}}\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Подсчет метрик на примере предсказания модели\n",
    "target = sent_tokenize(df_test['summary'][1])\n",
    "preds = sent_tokenize(summary)\n",
    "calc_scores(target, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80f123",
   "metadata": {
    "cellId": "7q3hfy29ww5gnesrn70xu7",
    "execution_id": "2af8b2e9-13bb-47c7-bf3b-27a1523a58a3"
   },
   "source": [
    "**Вывод:** результаты модели довольно слабые."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b934a43",
   "metadata": {
    "cellId": "2o668ocoe45a414cbnnb3p",
    "execution_id": "564de035-b8a9-40d4-ac51-edd4f53510f2"
   },
   "source": [
    "## <a id='Обучение_модели_12'>Обучение модели для генерации заголовков</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "347588eb",
   "metadata": {
    "cellId": "gpy82aafiv590n3j6clqks"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Добавляем токены начала и конца предложения\n",
    "df_train['title_clean'] = df_train['title'].apply(lambda v: 'BOS ' + v + ' EOS')\n",
    "df_test['title_clean'] = df_test['title'].apply(lambda v: 'BOS ' + v + ' EOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc4c43b9",
   "metadata": {
    "cellId": "x9hbs5lxiknkkk3gcf4949"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        BOS Венера, Ио или Тритон: куда полетит NASA EOS\n",
       "1              BOS «Люди в Бурятии очень талантливые» EOS\n",
       "2       BOS Вспомнить СССР: как Лукашенко провел выбор...\n",
       "3       BOS «Он очень переживал»: Бабкина об отношения...\n",
       "4       BOS «Поддерживают Россию»: почему Киев не плат...\n",
       "                              ...                        \n",
       "5765    BOS Новая «Игра престолов»? Netflix показал тр...\n",
       "5766    BOS «Это было ужасно»: Джоли эвакуировали со с...\n",
       "5767    BOS «Это камни»: ученого затравили за змей на ...\n",
       "5768    BOS «До 200 тысяч зараженных»: как распростран...\n",
       "5769    BOS С российским реактором: Китай создаст атом...\n",
       "Name: title_clean, Length: 5770, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "df_test['title_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2d6d2dc",
   "metadata": {
    "cellId": "z3b0bdbzwtn4pbset8tygw"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Уменьшаем объем датасетов\n",
    "MAX_TRAIN_SAMPLE = 1000\n",
    "MAX_TEST_SAMPLE = 200\n",
    "\n",
    "df_train = df_train[:MAX_TRAIN_SAMPLE]\n",
    "df_test = df_test[:MAX_TEST_SAMPLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf817db5",
   "metadata": {
    "cellId": "j2ctz5s6r6mw96v9fhqd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Создаем словарь\n",
    "max_len_text = 700\n",
    "max_len_sum = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcbbece4",
   "metadata": {
    "cellId": "nu9zmn3wu66ts4n935gj5"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Преобразуем тексты\n",
    "tok_text = Tokenizer()\n",
    "# Создаем словарь индексов на основе частоты слов в df_train['text'] (чем меньше число, тем чаще встречается слово)\n",
    "tok_text.fit_on_texts(df_train['text'])\n",
    "# Преобразуем каждый text из df_train['text'] в последовательность целых чисел  в соответсвии со словарем\n",
    "x_train_tok = tok_text.texts_to_sequences(df_train['text'])\n",
    "x_test_tok = tok_text.texts_to_sequences(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efd1dae1",
   "metadata": {
    "cellId": "pfh6667sirjtjgig8eymxj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 700)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "text_vocab_size=len(tok_text.word_index)+1\n",
    "# Приводим последовательности целых чисел к одной длине:\n",
    "# К каждому элементу из x_train_tok добавляем (отнимаем) до max_len_text (от max_len_text) нулями сзади\n",
    "padded_x_train = pad_sequences(x_train_tok, maxlen=max_len_text, padding='post', truncating='post')\n",
    "padded_x_test = pad_sequences(x_test_tok, maxlen=max_len_text, padding='post', truncating='post')\n",
    "padded_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46801b36",
   "metadata": {
    "cellId": "pkj13xc3bjp5e4tfbj3r7v"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Преобразуем заголовки\n",
    "tok_sum = Tokenizer()\n",
    "# Создаем словарь индексов на основе частоты слов в df_train['title_clean']\n",
    "tok_sum.fit_on_texts(df_train['title_clean'])\n",
    "# Преобразуем каждый text из df_train['title_clean'] в последовательность целых чисел  в соответсвии со словарем\n",
    "x_train_sum = tok_sum.texts_to_sequences(df_train['title_clean'])\n",
    "x_test_sum = tok_sum.texts_to_sequences(df_test['title_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1a9fbe9",
   "metadata": {
    "cellId": "4luu9wjfu7d1hzed3as8rh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 50)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "sum_vocab_size=len(tok_sum.word_index)+1\n",
    "# Приводим последовательности целых чисел к одной длине:\n",
    "# К каждому элементу из x_train_tok добавляем (отнимаем) до max_len_sum (от max_len_sum) нулями сзади\n",
    "padded_x_train_sum = pad_sequences(x_train_sum, maxlen=max_len_sum, padding='post', truncating='post')\n",
    "padded_x_test_sum = pad_sequences(x_test_sum, maxlen=max_len_sum, padding='post', truncating='post')\n",
    "padded_x_train_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97945e01",
   "metadata": {
    "cellId": "9ywgoyfqrztkc4yyk01jv"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Словарь индекс: токен для tok_text\n",
    "reverse_text_index=tok_text.index_word\n",
    "# Словарь индекс: токен для tok_sum\n",
    "reverse_sum_index=tok_sum.index_word\n",
    "# Словарь токен: индекс для tok_sum\n",
    "sum_wordindex=tok_sum.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5db5b6",
   "metadata": {
    "cellId": "gz8t9nuy6ysu2zb2s21ek",
    "execution_id": "47db9308-d5e0-408b-9e0a-4d93adc1c8f0"
   },
   "source": [
    "**Построение и обучение модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5b67c09",
   "metadata": {
    "cellId": "ruiv1kne6usl5n0vh7w12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 16:54:21.088601: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-05 16:54:21.713100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30995 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:8c:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "BUFFER_SIZE = len(padded_x_train)\n",
    "BATCH_SIZE = 32\n",
    "steps_per_epoch = len(padded_x_train)//BATCH_SIZE\n",
    "\n",
    "# Каждую пару (padded_x_train, padded_x_train_sum) преобразуем в тензор\n",
    "dataset = tf.data.Dataset.from_tensor_slices((padded_x_train, padded_x_train_sum)).shuffle(BUFFER_SIZE)\n",
    "# Объединяем последоваетльные элементы в батчи, неполный батч удаляем\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7763f811",
   "metadata": {
    "cellId": "hgb2kl7fsqnqoujln6gqt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 700), dtype=int32, numpy=\n",
      "array([[    1,   350,     1, ..., 13505,   203, 86528],\n",
      "       [  363,  4844,   413, ...,     0,     0,     0],\n",
      "       [  363,   198, 11394, ...,  1749,  1654,    20],\n",
      "       ...,\n",
      "       [  170,     1, 10562, ...,     0,     0,     0],\n",
      "       [  299,  1341, 37457, ...,     0,     0,     0],\n",
      "       [24241,  4485,  1220, ...,     0,     0,     0]], dtype=int32)>, <tf.Tensor: shape=(32, 50), dtype=int32, numpy=\n",
      "array([[   1, 3256, 3257, ...,    0,    0,    0],\n",
      "       [   1,   25, 1477, ...,    0,    0,    0],\n",
      "       [   1, 3383,  401, ...,    0,    0,    0],\n",
      "       ...,\n",
      "       [   1,  903,    6, ...,    0,    0,    0],\n",
      "       [   1,  424,  425, ...,    0,    0,    0],\n",
      "       [   1, 2849, 2850, ...,    0,    0,    0]], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for element in dataset:\n",
    "  print(element)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b97eab24",
   "metadata": {
    "cellId": "60bj9vfzysm6qhkeb6kxs6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 700]), TensorShape([32, 50]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efd0806e",
   "metadata": {
    "cellId": "aeirt1lnyyy7vssjzhogd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Построение модели (Encoder и Decoder)\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru1 = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.gru2 = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru1(x, initial_state = hidden)\n",
    "        output, state = self.gru2(output, initial_state = state)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "\n",
    "    def call(self, x, query, value):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        #attention_weights = self.attention([ tf.expand_dims(query, 1), value,])\n",
    "        context_vector = self.attention([tf.expand_dims(query, 1), value,])\n",
    "        #context_vector = tf.squeeze(context_vector)\n",
    "\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([context_vector, x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4e96e7b",
   "metadata": {
    "cellId": "n77atg2v3cllrl8xujomn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 16:54:25.058427: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "latent_dim = 300\n",
    "embedding_dim=200\n",
    "\n",
    "#создаем экземпляры encoder и decoder\n",
    "encoder = Encoder(text_vocab_size, embedding_dim, latent_dim, BATCH_SIZE)\n",
    "decoder = Decoder(sum_vocab_size, embedding_dim, latent_dim, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efbedb5e",
   "metadata": {
    "cellId": "8u4wu6t9g7p71t9976gjml"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 700, 300), dtype=float32, numpy=\n",
       "array([[[-8.87439679e-03, -4.31183213e-03, -8.34321324e-03, ...,\n",
       "          6.24656305e-03,  3.97082232e-03, -1.77751742e-02],\n",
       "        [-1.08014718e-02, -2.99269916e-03, -7.72377476e-03, ...,\n",
       "          9.91443545e-03,  1.12279905e-02, -7.43651763e-03],\n",
       "        [-5.52456593e-03,  3.32956156e-03,  4.95634088e-03, ...,\n",
       "          7.49652879e-03,  1.57716330e-02, -4.06223116e-03],\n",
       "        ...,\n",
       "        [-5.70216333e-04, -6.43045316e-03, -1.39458483e-04, ...,\n",
       "         -1.46250811e-03,  5.61242504e-03,  1.89076643e-02],\n",
       "        [-5.70216333e-04, -6.43045316e-03, -1.39458498e-04, ...,\n",
       "         -1.46250811e-03,  5.61242504e-03,  1.89076643e-02],\n",
       "        [-5.70216333e-04, -6.43045316e-03, -1.39458396e-04, ...,\n",
       "         -1.46250811e-03,  5.61242504e-03,  1.89076643e-02]],\n",
       "\n",
       "       [[-6.46381127e-03,  5.51322519e-05, -1.30271846e-02, ...,\n",
       "          1.00127459e-02,  4.93167713e-03, -1.43956896e-02],\n",
       "        [-1.20237991e-02, -1.32681133e-04, -5.11059491e-03, ...,\n",
       "          5.62311849e-03,  5.36835939e-03, -2.50188820e-03],\n",
       "        [-1.70430336e-02, -8.65156017e-03, -4.83135600e-03, ...,\n",
       "          7.76200136e-03,  1.61154359e-03,  3.62198823e-03],\n",
       "        ...,\n",
       "        [-5.70215343e-04, -6.43045129e-03, -1.39456330e-04, ...,\n",
       "         -1.46250904e-03,  5.61242225e-03,  1.89076643e-02],\n",
       "        [-5.70215343e-04, -6.43045129e-03, -1.39456315e-04, ...,\n",
       "         -1.46250904e-03,  5.61242225e-03,  1.89076643e-02],\n",
       "        [-5.70215343e-04, -6.43045129e-03, -1.39456315e-04, ...,\n",
       "         -1.46250904e-03,  5.61242225e-03,  1.89076643e-02]],\n",
       "\n",
       "       [[-3.50626535e-03, -1.10965502e-03, -1.22410338e-02, ...,\n",
       "          4.27447120e-03,  1.57265342e-03, -1.77795272e-02],\n",
       "        [-6.04306022e-03,  3.55117256e-03, -6.26698602e-03, ...,\n",
       "          1.00965996e-03,  2.40331457e-04, -6.86714752e-03],\n",
       "        [-1.61652383e-03,  7.66578130e-03, -6.29868126e-04, ...,\n",
       "          4.23627719e-03,  1.79706817e-03, -2.23345053e-03],\n",
       "        ...,\n",
       "        [-5.70214877e-04, -6.43044943e-03, -1.39455791e-04, ...,\n",
       "         -1.46250823e-03,  5.61242225e-03,  1.89076643e-02],\n",
       "        [-5.70214877e-04, -6.43044943e-03, -1.39455806e-04, ...,\n",
       "         -1.46250823e-03,  5.61242225e-03,  1.89076643e-02],\n",
       "        [-5.70214877e-04, -6.43044943e-03, -1.39455820e-04, ...,\n",
       "         -1.46250823e-03,  5.61242225e-03,  1.89076643e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.07881676e-03, -4.69809675e-05, -1.57052502e-02, ...,\n",
       "         -1.51924125e-03,  3.71205644e-03, -1.97266694e-02],\n",
       "        [-9.95326536e-06,  1.74193026e-03, -9.36087500e-03, ...,\n",
       "         -5.35900414e-04,  2.68558576e-03, -1.05269412e-02],\n",
       "        [-4.65866004e-04,  4.66347532e-03, -3.70621122e-03, ...,\n",
       "          3.19199171e-03, -1.09276548e-03, -9.40134097e-03],\n",
       "        ...,\n",
       "        [-5.70249395e-04, -6.43045409e-03, -1.39431781e-04, ...,\n",
       "         -1.46250310e-03,  5.61243901e-03,  1.89076532e-02],\n",
       "        [-5.70237113e-04, -6.43045455e-03, -1.39439973e-04, ...,\n",
       "         -1.46250427e-03,  5.61243435e-03,  1.89076569e-02],\n",
       "        [-5.70230477e-04, -6.43045409e-03, -1.39446769e-04, ...,\n",
       "         -1.46250485e-03,  5.61243109e-03,  1.89076588e-02]],\n",
       "\n",
       "       [[ 3.55667272e-03, -3.85647261e-04,  1.32673830e-02, ...,\n",
       "         -1.71329686e-03, -3.45474039e-03, -5.30789187e-03],\n",
       "        [-7.18787080e-04, -4.19604685e-03,  7.60096498e-03, ...,\n",
       "          3.79237346e-03, -4.05471306e-03,  3.08489864e-04],\n",
       "        [-1.33663288e-03, -4.27802186e-03, -1.96804316e-03, ...,\n",
       "          5.77145815e-03, -1.42541947e-03,  5.03813382e-03],\n",
       "        ...,\n",
       "        [ 4.56475886e-03,  1.20604355e-02,  6.93471031e-03, ...,\n",
       "         -3.87647934e-03,  9.08255484e-03,  2.11267313e-03],\n",
       "        [ 1.12544931e-02,  1.06992004e-02,  1.05757387e-02, ...,\n",
       "         -2.08021631e-03,  5.46225952e-03, -2.05926667e-03],\n",
       "        [ 1.08533772e-02,  4.07550903e-03,  5.37340157e-03, ...,\n",
       "          4.77865292e-03,  3.55481450e-03, -3.46712372e-03]],\n",
       "\n",
       "       [[-1.03712017e-02,  1.88741146e-03, -7.78300688e-03, ...,\n",
       "          8.29215511e-04, -4.62692493e-04, -1.80305298e-02],\n",
       "        [-1.62656531e-02,  3.87421972e-03,  8.39096087e-04, ...,\n",
       "          6.34864438e-04, -3.02839978e-03, -4.37288359e-03],\n",
       "        [-1.62880924e-02, -3.81918566e-04,  3.92790046e-03, ...,\n",
       "          2.66936934e-03, -6.24126347e-04,  2.37772963e-03],\n",
       "        ...,\n",
       "        [-5.70213946e-04, -6.43045222e-03, -1.39457567e-04, ...,\n",
       "         -1.46250881e-03,  5.61242271e-03,  1.89076625e-02],\n",
       "        [-5.70213946e-04, -6.43045222e-03, -1.39457523e-04, ...,\n",
       "         -1.46250904e-03,  5.61242271e-03,  1.89076625e-02],\n",
       "        [-5.70213946e-04, -6.43045222e-03, -1.39457494e-04, ...,\n",
       "         -1.46250916e-03,  5.61242271e-03,  1.89076625e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3bc5357",
   "metadata": {
    "cellId": "epk89g74z9u79q9f4pf6xn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 300), dtype=float32, numpy=\n",
       "array([[-0.00057022, -0.00643045, -0.00013946, ..., -0.00146251,\n",
       "         0.00561243,  0.01890766],\n",
       "       [-0.00057022, -0.00643045, -0.00013946, ..., -0.00146251,\n",
       "         0.00561242,  0.01890766],\n",
       "       [-0.00057021, -0.00643045, -0.00013946, ..., -0.00146251,\n",
       "         0.00561242,  0.01890766],\n",
       "       ...,\n",
       "       [-0.00057023, -0.00643045, -0.00013945, ..., -0.0014625 ,\n",
       "         0.00561243,  0.01890766],\n",
       "       [ 0.01085338,  0.00407551,  0.0053734 , ...,  0.00477865,\n",
       "         0.00355481, -0.00346712],\n",
       "       [-0.00057021, -0.00643045, -0.00013946, ..., -0.00146251,\n",
       "         0.00561242,  0.01890766]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "sample_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95e8ea18",
   "metadata": {
    "cellId": "hp0qbxfx4cn9logj1c8sn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Компиляция модели\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # определяем ненулевые элементы\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    #переводим mask к типу loss_\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    #умножаем loss на маску\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_) # возвращаем среднее значение элементов тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4bf033e",
   "metadata": {
    "cellId": "qpzdm4wa4eos6ixcyxr9iq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Обучение модели\n",
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([sum_wordindex['bos']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcda0dfe",
   "metadata": {
    "cellId": "8orjarbzo4lf72z3zw5w6"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "checkpoint_dir = './training_summ_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8768ec0",
   "metadata": {
    "cellId": "ojrsgix7g7p1qjnjwliem"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 16:55:19.492431: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-03-05 16:55:23.376507: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.377137: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.377685: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.378222: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.378755: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.379366: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.380069: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.380662: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.381385: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.381918: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.382641: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.383364: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.384061: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.384799: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.385596: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.386266: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.387093: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.387806: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.388440: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.389238: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.389897: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.390639: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.391330: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.391942: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.392603: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.393206: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.393741: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.394426: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.395070: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.395686: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.396305: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.397130: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.398224: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.399007: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.399890: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.400657: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.401445: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.402200: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.402779: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.403400: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.404153: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.404777: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.405407: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.406175: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.406868: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.407537: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.408190: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.408738: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-03-05 16:55:23.409368: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla V100-PCIE-32GB\" frequency: 1380 num_cores: 80 environment { key: \"architecture\" value: \"7.0\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 6291456 shared_memory_size_per_multiprocessor: 98304 memory_size: 32501137408 bandwidth: 898048000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.8940\n",
      "Epoch 1 Batch 10 Loss 0.8960\n",
      "Epoch 1 Batch 20 Loss 0.8834\n",
      "Epoch 1 Batch 30 Loss 1.0181\n",
      "Epoch 1 Loss 0.8942\n",
      "Time taken for 1 epoch 69.05212545394897 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.8127\n",
      "Epoch 2 Batch 10 Loss 0.8725\n",
      "Epoch 2 Batch 20 Loss 0.8227\n",
      "Epoch 2 Batch 30 Loss 0.8716\n",
      "Epoch 2 Loss 0.8268\n",
      "Time taken for 1 epoch 7.493474721908569 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.9115\n",
      "Epoch 3 Batch 10 Loss 0.8475\n",
      "Epoch 3 Batch 20 Loss 0.8595\n",
      "Epoch 3 Batch 30 Loss 0.7972\n",
      "Epoch 3 Loss 0.7970\n",
      "Time taken for 1 epoch 5.701946020126343 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.8034\n",
      "Epoch 4 Batch 10 Loss 0.7740\n",
      "Epoch 4 Batch 20 Loss 0.7666\n",
      "Epoch 4 Batch 30 Loss 0.7008\n",
      "Epoch 4 Loss 0.7704\n",
      "Time taken for 1 epoch 7.506965398788452 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.7497\n",
      "Epoch 5 Batch 10 Loss 0.8201\n",
      "Epoch 5 Batch 20 Loss 0.7870\n",
      "Epoch 5 Batch 30 Loss 0.7917\n",
      "Epoch 5 Loss 0.7568\n",
      "Time taken for 1 epoch 5.671932220458984 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.7568\n",
      "Epoch 6 Batch 10 Loss 0.7143\n",
      "Epoch 6 Batch 20 Loss 0.6366\n",
      "Epoch 6 Batch 30 Loss 0.7296\n",
      "Epoch 6 Loss 0.7432\n",
      "Time taken for 1 epoch 7.786729097366333 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.7642\n",
      "Epoch 7 Batch 10 Loss 0.8148\n",
      "Epoch 7 Batch 20 Loss 0.8386\n",
      "Epoch 7 Batch 30 Loss 0.8548\n",
      "Epoch 7 Loss 0.7305\n",
      "Time taken for 1 epoch 5.681873083114624 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.7274\n",
      "Epoch 8 Batch 10 Loss 0.7041\n",
      "Epoch 8 Batch 20 Loss 0.6671\n",
      "Epoch 8 Batch 30 Loss 0.7618\n",
      "Epoch 8 Loss 0.7156\n",
      "Time taken for 1 epoch 7.605828523635864 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.6697\n",
      "Epoch 9 Batch 10 Loss 0.6710\n",
      "Epoch 9 Batch 20 Loss 0.6996\n",
      "Epoch 9 Batch 30 Loss 0.7336\n",
      "Epoch 9 Loss 0.7008\n",
      "Time taken for 1 epoch 5.652615308761597 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.6611\n",
      "Epoch 10 Batch 10 Loss 0.6563\n",
      "Epoch 10 Batch 20 Loss 0.6673\n",
      "Epoch 10 Batch 30 Loss 0.6048\n",
      "Epoch 10 Loss 0.6838\n",
      "Time taken for 1 epoch 7.672805070877075 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.6014\n",
      "Epoch 11 Batch 10 Loss 0.6100\n",
      "Epoch 11 Batch 20 Loss 0.5856\n",
      "Epoch 11 Batch 30 Loss 0.7315\n",
      "Epoch 11 Loss 0.6719\n",
      "Time taken for 1 epoch 5.766329765319824 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.6782\n",
      "Epoch 12 Batch 10 Loss 0.7136\n",
      "Epoch 12 Batch 20 Loss 0.6521\n",
      "Epoch 12 Batch 30 Loss 0.6994\n",
      "Epoch 12 Loss 0.6571\n",
      "Time taken for 1 epoch 7.645644187927246 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.5960\n",
      "Epoch 13 Batch 10 Loss 0.6670\n",
      "Epoch 13 Batch 20 Loss 0.6755\n",
      "Epoch 13 Batch 30 Loss 0.7125\n",
      "Epoch 13 Loss 0.6419\n",
      "Time taken for 1 epoch 5.697766542434692 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.6353\n",
      "Epoch 14 Batch 10 Loss 0.6670\n",
      "Epoch 14 Batch 20 Loss 0.6802\n",
      "Epoch 14 Batch 30 Loss 0.6348\n",
      "Epoch 14 Loss 0.6314\n",
      "Time taken for 1 epoch 7.871276617050171 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.5957\n",
      "Epoch 15 Batch 10 Loss 0.6272\n",
      "Epoch 15 Batch 20 Loss 0.7146\n",
      "Epoch 15 Batch 30 Loss 0.5934\n",
      "Epoch 15 Loss 0.6213\n",
      "Time taken for 1 epoch 5.69146990776062 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.6474\n",
      "Epoch 16 Batch 10 Loss 0.6317\n",
      "Epoch 16 Batch 20 Loss 0.6580\n",
      "Epoch 16 Batch 30 Loss 0.6081\n",
      "Epoch 16 Loss 0.6115\n",
      "Time taken for 1 epoch 7.673547267913818 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.5793\n",
      "Epoch 17 Batch 10 Loss 0.5800\n",
      "Epoch 17 Batch 20 Loss 0.6113\n",
      "Epoch 17 Batch 30 Loss 0.6547\n",
      "Epoch 17 Loss 0.5993\n",
      "Time taken for 1 epoch 5.702686071395874 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.5570\n",
      "Epoch 18 Batch 10 Loss 0.5917\n",
      "Epoch 18 Batch 20 Loss 0.5356\n",
      "Epoch 18 Batch 30 Loss 0.5939\n",
      "Epoch 18 Loss 0.5904\n",
      "Time taken for 1 epoch 7.735440492630005 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.5425\n",
      "Epoch 19 Batch 10 Loss 0.5593\n",
      "Epoch 19 Batch 20 Loss 0.5483\n",
      "Epoch 19 Batch 30 Loss 0.6070\n",
      "Epoch 19 Loss 0.5804\n",
      "Time taken for 1 epoch 5.716395854949951 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.5659\n",
      "Epoch 20 Batch 10 Loss 0.5174\n",
      "Epoch 20 Batch 20 Loss 0.6635\n",
      "Epoch 20 Batch 30 Loss 0.5685\n",
      "Epoch 20 Loss 0.5702\n",
      "Time taken for 1 epoch 9.038482904434204 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.5704\n",
      "Epoch 21 Batch 10 Loss 0.5215\n",
      "Epoch 21 Batch 20 Loss 0.5116\n",
      "Epoch 21 Batch 30 Loss 0.5429\n",
      "Epoch 21 Loss 0.5602\n",
      "Time taken for 1 epoch 5.704483985900879 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.5024\n",
      "Epoch 22 Batch 10 Loss 0.5980\n",
      "Epoch 22 Batch 20 Loss 0.5305\n",
      "Epoch 22 Batch 30 Loss 0.4955\n",
      "Epoch 22 Loss 0.5517\n",
      "Time taken for 1 epoch 10.926859140396118 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.5509\n",
      "Epoch 23 Batch 10 Loss 0.5627\n",
      "Epoch 23 Batch 20 Loss 0.5281\n",
      "Epoch 23 Batch 30 Loss 0.6030\n",
      "Epoch 23 Loss 0.5418\n",
      "Time taken for 1 epoch 5.717863321304321 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.5405\n",
      "Epoch 24 Batch 10 Loss 0.5653\n",
      "Epoch 24 Batch 20 Loss 0.5356\n",
      "Epoch 24 Batch 30 Loss 0.5106\n",
      "Epoch 24 Loss 0.5309\n",
      "Time taken for 1 epoch 12.866674661636353 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.5699\n",
      "Epoch 25 Batch 10 Loss 0.4548\n",
      "Epoch 25 Batch 20 Loss 0.5400\n",
      "Epoch 25 Batch 30 Loss 0.5380\n",
      "Epoch 25 Loss 0.5199\n",
      "Time taken for 1 epoch 5.656329870223999 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.4725\n",
      "Epoch 26 Batch 10 Loss 0.5702\n",
      "Epoch 26 Batch 20 Loss 0.5597\n",
      "Epoch 26 Batch 30 Loss 0.4700\n",
      "Epoch 26 Loss 0.5089\n",
      "Time taken for 1 epoch 9.985565185546875 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.4838\n",
      "Epoch 27 Batch 10 Loss 0.5079\n",
      "Epoch 27 Batch 20 Loss 0.5225\n",
      "Epoch 27 Batch 30 Loss 0.5243\n",
      "Epoch 27 Loss 0.4978\n",
      "Time taken for 1 epoch 5.638571500778198 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.4584\n",
      "Epoch 28 Batch 10 Loss 0.4977\n",
      "Epoch 28 Batch 20 Loss 0.4413\n",
      "Epoch 28 Batch 30 Loss 0.4735\n",
      "Epoch 28 Loss 0.4870\n",
      "Time taken for 1 epoch 15.089462518692017 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.4544\n",
      "Epoch 29 Batch 10 Loss 0.4871\n",
      "Epoch 29 Batch 20 Loss 0.4435\n",
      "Epoch 29 Batch 30 Loss 0.5712\n",
      "Epoch 29 Loss 0.4765\n",
      "Time taken for 1 epoch 5.6558310985565186 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.5339\n",
      "Epoch 30 Batch 10 Loss 0.4287\n",
      "Epoch 30 Batch 20 Loss 0.4540\n",
      "Epoch 30 Batch 30 Loss 0.5120\n",
      "Epoch 30 Loss 0.4654\n",
      "Time taken for 1 epoch 8.3301842212677 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.4645\n",
      "Epoch 31 Batch 10 Loss 0.4429\n",
      "Epoch 31 Batch 20 Loss 0.4267\n",
      "Epoch 31 Batch 30 Loss 0.4986\n",
      "Epoch 31 Loss 0.4555\n",
      "Time taken for 1 epoch 5.753470182418823 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.4335\n",
      "Epoch 32 Batch 10 Loss 0.4214\n",
      "Epoch 32 Batch 20 Loss 0.4367\n",
      "Epoch 32 Batch 30 Loss 0.5275\n",
      "Epoch 32 Loss 0.4478\n",
      "Time taken for 1 epoch 10.946343421936035 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.4413\n",
      "Epoch 33 Batch 10 Loss 0.4247\n",
      "Epoch 33 Batch 20 Loss 0.3762\n",
      "Epoch 33 Batch 30 Loss 0.4927\n",
      "Epoch 33 Loss 0.4398\n",
      "Time taken for 1 epoch 5.748085260391235 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.4081\n",
      "Epoch 34 Batch 10 Loss 0.4023\n",
      "Epoch 34 Batch 20 Loss 0.3701\n",
      "Epoch 34 Batch 30 Loss 0.4913\n",
      "Epoch 34 Loss 0.4277\n",
      "Time taken for 1 epoch 10.465750694274902 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.3459\n",
      "Epoch 35 Batch 10 Loss 0.3934\n",
      "Epoch 35 Batch 20 Loss 0.4396\n",
      "Epoch 35 Batch 30 Loss 0.4288\n",
      "Epoch 35 Loss 0.4144\n",
      "Time taken for 1 epoch 5.715297222137451 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.3977\n",
      "Epoch 36 Batch 10 Loss 0.3974\n",
      "Epoch 36 Batch 20 Loss 0.4067\n",
      "Epoch 36 Batch 30 Loss 0.4433\n",
      "Epoch 36 Loss 0.4028\n",
      "Time taken for 1 epoch 9.342932939529419 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.3499\n",
      "Epoch 37 Batch 10 Loss 0.3252\n",
      "Epoch 37 Batch 20 Loss 0.3865\n",
      "Epoch 37 Batch 30 Loss 0.4394\n",
      "Epoch 37 Loss 0.3940\n",
      "Time taken for 1 epoch 5.6894872188568115 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.4402\n",
      "Epoch 38 Batch 10 Loss 0.3868\n",
      "Epoch 38 Batch 20 Loss 0.3720\n",
      "Epoch 38 Batch 30 Loss 0.4436\n",
      "Epoch 38 Loss 0.3898\n",
      "Time taken for 1 epoch 9.792743682861328 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.3432\n",
      "Epoch 39 Batch 10 Loss 0.3445\n",
      "Epoch 39 Batch 20 Loss 0.3783\n",
      "Epoch 39 Batch 30 Loss 0.3525\n",
      "Epoch 39 Loss 0.3823\n",
      "Time taken for 1 epoch 5.6965978145599365 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.3831\n",
      "Epoch 40 Batch 10 Loss 0.3884\n",
      "Epoch 40 Batch 20 Loss 0.3695\n",
      "Epoch 40 Batch 30 Loss 0.3760\n",
      "Epoch 40 Loss 0.3669\n",
      "Time taken for 1 epoch 11.331143140792847 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.3589\n",
      "Epoch 41 Batch 10 Loss 0.3242\n",
      "Epoch 41 Batch 20 Loss 0.3633\n",
      "Epoch 41 Batch 30 Loss 0.3776\n",
      "Epoch 41 Loss 0.3511\n",
      "Time taken for 1 epoch 5.718167781829834 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.3289\n",
      "Epoch 42 Batch 10 Loss 0.3329\n",
      "Epoch 42 Batch 20 Loss 0.3294\n",
      "Epoch 42 Batch 30 Loss 0.3708\n",
      "Epoch 42 Loss 0.3389\n",
      "Time taken for 1 epoch 10.522414922714233 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.2910\n",
      "Epoch 43 Batch 10 Loss 0.3384\n",
      "Epoch 43 Batch 20 Loss 0.3366\n",
      "Epoch 43 Batch 30 Loss 0.3343\n",
      "Epoch 43 Loss 0.3283\n",
      "Time taken for 1 epoch 5.704980373382568 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.3065\n",
      "Epoch 44 Batch 10 Loss 0.2774\n",
      "Epoch 44 Batch 20 Loss 0.3566\n",
      "Epoch 44 Batch 30 Loss 0.3171\n",
      "Epoch 44 Loss 0.3185\n",
      "Time taken for 1 epoch 11.85868525505066 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.2584\n",
      "Epoch 45 Batch 10 Loss 0.2709\n",
      "Epoch 45 Batch 20 Loss 0.3256\n",
      "Epoch 45 Batch 30 Loss 0.3099\n",
      "Epoch 45 Loss 0.3084\n",
      "Time taken for 1 epoch 5.689722061157227 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.3040\n",
      "Epoch 46 Batch 10 Loss 0.3133\n",
      "Epoch 46 Batch 20 Loss 0.3656\n",
      "Epoch 46 Batch 30 Loss 0.3024\n",
      "Epoch 46 Loss 0.2977\n",
      "Time taken for 1 epoch 9.735049724578857 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.3140\n",
      "Epoch 47 Batch 10 Loss 0.3102\n",
      "Epoch 47 Batch 20 Loss 0.3178\n",
      "Epoch 47 Batch 30 Loss 0.2744\n",
      "Epoch 47 Loss 0.2861\n",
      "Time taken for 1 epoch 5.68428897857666 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.2779\n",
      "Epoch 48 Batch 10 Loss 0.2802\n",
      "Epoch 48 Batch 20 Loss 0.2559\n",
      "Epoch 48 Batch 30 Loss 0.2886\n",
      "Epoch 48 Loss 0.2774\n",
      "Time taken for 1 epoch 13.498843431472778 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.2307\n",
      "Epoch 49 Batch 10 Loss 0.2979\n",
      "Epoch 49 Batch 20 Loss 0.2438\n",
      "Epoch 49 Batch 30 Loss 0.2639\n",
      "Epoch 49 Loss 0.2670\n",
      "Time taken for 1 epoch 5.731809854507446 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.2471\n",
      "Epoch 50 Batch 10 Loss 0.2608\n",
      "Epoch 50 Batch 20 Loss 0.3003\n",
      "Epoch 50 Batch 30 Loss 0.2977\n",
      "Epoch 50 Loss 0.2590\n",
      "Time taken for 1 epoch 9.27816128730774 sec\n",
      "\n",
      "Epoch 51 Batch 0 Loss 0.2428\n",
      "Epoch 51 Batch 10 Loss 0.2387\n",
      "Epoch 51 Batch 20 Loss 0.2490\n",
      "Epoch 51 Batch 30 Loss 0.2617\n",
      "Epoch 51 Loss 0.2494\n",
      "Time taken for 1 epoch 5.708054542541504 sec\n",
      "\n",
      "Epoch 52 Batch 0 Loss 0.2181\n",
      "Epoch 52 Batch 10 Loss 0.2343\n",
      "Epoch 52 Batch 20 Loss 0.2516\n",
      "Epoch 52 Batch 30 Loss 0.2548\n",
      "Epoch 52 Loss 0.2418\n",
      "Time taken for 1 epoch 9.880707502365112 sec\n",
      "\n",
      "Epoch 53 Batch 0 Loss 0.2389\n",
      "Epoch 53 Batch 10 Loss 0.2345\n",
      "Epoch 53 Batch 20 Loss 0.2464\n",
      "Epoch 53 Batch 30 Loss 0.2465\n",
      "Epoch 53 Loss 0.2332\n",
      "Time taken for 1 epoch 5.7323760986328125 sec\n",
      "\n",
      "Epoch 54 Batch 0 Loss 0.2243\n",
      "Epoch 54 Batch 10 Loss 0.2395\n",
      "Epoch 54 Batch 20 Loss 0.2352\n",
      "Epoch 54 Batch 30 Loss 0.2306\n",
      "Epoch 54 Loss 0.2249\n",
      "Time taken for 1 epoch 10.750340938568115 sec\n",
      "\n",
      "Epoch 55 Batch 0 Loss 0.2096\n",
      "Epoch 55 Batch 10 Loss 0.1923\n",
      "Epoch 55 Batch 20 Loss 0.2194\n",
      "Epoch 55 Batch 30 Loss 0.2284\n",
      "Epoch 55 Loss 0.2175\n",
      "Time taken for 1 epoch 5.69926905632019 sec\n",
      "\n",
      "Epoch 56 Batch 0 Loss 0.2008\n",
      "Epoch 56 Batch 10 Loss 0.1982\n",
      "Epoch 56 Batch 20 Loss 0.2168\n",
      "Epoch 56 Batch 30 Loss 0.1769\n",
      "Epoch 56 Loss 0.2100\n",
      "Time taken for 1 epoch 9.668143272399902 sec\n",
      "\n",
      "Epoch 57 Batch 0 Loss 0.1869\n",
      "Epoch 57 Batch 10 Loss 0.2264\n",
      "Epoch 57 Batch 20 Loss 0.1978\n",
      "Epoch 57 Batch 30 Loss 0.2042\n",
      "Epoch 57 Loss 0.2028\n",
      "Time taken for 1 epoch 5.748251676559448 sec\n",
      "\n",
      "Epoch 58 Batch 0 Loss 0.1826\n",
      "Epoch 58 Batch 10 Loss 0.1693\n",
      "Epoch 58 Batch 20 Loss 0.2080\n",
      "Epoch 58 Batch 30 Loss 0.1959\n",
      "Epoch 58 Loss 0.1967\n",
      "Time taken for 1 epoch 11.20188570022583 sec\n",
      "\n",
      "Epoch 59 Batch 0 Loss 0.1824\n",
      "Epoch 59 Batch 10 Loss 0.1912\n",
      "Epoch 59 Batch 20 Loss 0.1903\n",
      "Epoch 59 Batch 30 Loss 0.1925\n",
      "Epoch 59 Loss 0.1907\n",
      "Time taken for 1 epoch 5.685816287994385 sec\n",
      "\n",
      "Epoch 60 Batch 0 Loss 0.1763\n",
      "Epoch 60 Batch 10 Loss 0.1689\n",
      "Epoch 60 Batch 20 Loss 0.1748\n",
      "Epoch 60 Batch 30 Loss 0.1985\n",
      "Epoch 60 Loss 0.1846\n",
      "Time taken for 1 epoch 10.676501512527466 sec\n",
      "\n",
      "Epoch 61 Batch 0 Loss 0.1427\n",
      "Epoch 61 Batch 10 Loss 0.1711\n",
      "Epoch 61 Batch 20 Loss 0.1724\n",
      "Epoch 61 Batch 30 Loss 0.1884\n",
      "Epoch 61 Loss 0.1787\n",
      "Time taken for 1 epoch 5.683835506439209 sec\n",
      "\n",
      "Epoch 62 Batch 0 Loss 0.1592\n",
      "Epoch 62 Batch 10 Loss 0.1741\n",
      "Epoch 62 Batch 20 Loss 0.1818\n",
      "Epoch 62 Batch 30 Loss 0.1977\n",
      "Epoch 62 Loss 0.1728\n",
      "Time taken for 1 epoch 15.086227893829346 sec\n",
      "\n",
      "Epoch 63 Batch 0 Loss 0.1524\n",
      "Epoch 63 Batch 10 Loss 0.1609\n",
      "Epoch 63 Batch 20 Loss 0.1781\n",
      "Epoch 63 Batch 30 Loss 0.1689\n",
      "Epoch 63 Loss 0.1671\n",
      "Time taken for 1 epoch 5.672051906585693 sec\n",
      "\n",
      "Epoch 64 Batch 0 Loss 0.1432\n",
      "Epoch 64 Batch 10 Loss 0.1560\n",
      "Epoch 64 Batch 20 Loss 0.1541\n",
      "Epoch 64 Batch 30 Loss 0.1387\n",
      "Epoch 64 Loss 0.1609\n",
      "Time taken for 1 epoch 8.276226043701172 sec\n",
      "\n",
      "Epoch 65 Batch 0 Loss 0.1626\n",
      "Epoch 65 Batch 10 Loss 0.1417\n",
      "Epoch 65 Batch 20 Loss 0.1621\n",
      "Epoch 65 Batch 30 Loss 0.1758\n",
      "Epoch 65 Loss 0.1562\n",
      "Time taken for 1 epoch 5.706120014190674 sec\n",
      "\n",
      "Epoch 66 Batch 0 Loss 0.1622\n",
      "Epoch 66 Batch 10 Loss 0.1631\n",
      "Epoch 66 Batch 20 Loss 0.1643\n",
      "Epoch 66 Batch 30 Loss 0.1575\n",
      "Epoch 66 Loss 0.1519\n",
      "Time taken for 1 epoch 9.516478538513184 sec\n",
      "\n",
      "Epoch 67 Batch 0 Loss 0.1442\n",
      "Epoch 67 Batch 10 Loss 0.1493\n",
      "Epoch 67 Batch 20 Loss 0.1618\n",
      "Epoch 67 Batch 30 Loss 0.1765\n",
      "Epoch 67 Loss 0.1476\n",
      "Time taken for 1 epoch 5.64603590965271 sec\n",
      "\n",
      "Epoch 68 Batch 0 Loss 0.1541\n",
      "Epoch 68 Batch 10 Loss 0.1365\n",
      "Epoch 68 Batch 20 Loss 0.1438\n",
      "Epoch 68 Batch 30 Loss 0.1631\n",
      "Epoch 68 Loss 0.1439\n",
      "Time taken for 1 epoch 10.0430428981781 sec\n",
      "\n",
      "Epoch 69 Batch 0 Loss 0.1305\n",
      "Epoch 69 Batch 10 Loss 0.1327\n",
      "Epoch 69 Batch 20 Loss 0.1343\n",
      "Epoch 69 Batch 30 Loss 0.1662\n",
      "Epoch 69 Loss 0.1398\n",
      "Time taken for 1 epoch 5.735500335693359 sec\n",
      "\n",
      "Epoch 70 Batch 0 Loss 0.1154\n",
      "Epoch 70 Batch 10 Loss 0.1348\n",
      "Epoch 70 Batch 20 Loss 0.1383\n",
      "Epoch 70 Batch 30 Loss 0.1539\n",
      "Epoch 70 Loss 0.1369\n",
      "Time taken for 1 epoch 10.627421855926514 sec\n",
      "\n",
      "Epoch 71 Batch 0 Loss 0.1313\n",
      "Epoch 71 Batch 10 Loss 0.1202\n",
      "Epoch 71 Batch 20 Loss 0.1315\n",
      "Epoch 71 Batch 30 Loss 0.1389\n",
      "Epoch 71 Loss 0.1340\n",
      "Time taken for 1 epoch 5.701700448989868 sec\n",
      "\n",
      "Epoch 72 Batch 0 Loss 0.1342\n",
      "Epoch 72 Batch 10 Loss 0.1314\n",
      "Epoch 72 Batch 20 Loss 0.1385\n",
      "Epoch 72 Batch 30 Loss 0.1290\n",
      "Epoch 72 Loss 0.1312\n",
      "Time taken for 1 epoch 13.332240104675293 sec\n",
      "\n",
      "Epoch 73 Batch 0 Loss 0.1243\n",
      "Epoch 73 Batch 10 Loss 0.1202\n",
      "Epoch 73 Batch 20 Loss 0.1348\n",
      "Epoch 73 Batch 30 Loss 0.1528\n",
      "Epoch 73 Loss 0.1295\n",
      "Time taken for 1 epoch 5.687417268753052 sec\n",
      "\n",
      "Epoch 74 Batch 0 Loss 0.1328\n",
      "Epoch 74 Batch 10 Loss 0.1380\n",
      "Epoch 74 Batch 20 Loss 0.1314\n",
      "Epoch 74 Batch 30 Loss 0.1457\n",
      "Epoch 74 Loss 0.1266\n",
      "Time taken for 1 epoch 8.259056806564331 sec\n",
      "\n",
      "Epoch 75 Batch 0 Loss 0.1095\n",
      "Epoch 75 Batch 10 Loss 0.1085\n",
      "Epoch 75 Batch 20 Loss 0.1205\n",
      "Epoch 75 Batch 30 Loss 0.1408\n",
      "Epoch 75 Loss 0.1223\n",
      "Time taken for 1 epoch 5.6653735637664795 sec\n",
      "\n",
      "Epoch 76 Batch 0 Loss 0.1183\n",
      "Epoch 76 Batch 10 Loss 0.1310\n",
      "Epoch 76 Batch 20 Loss 0.1197\n",
      "Epoch 76 Batch 30 Loss 0.1277\n",
      "Epoch 76 Loss 0.1196\n",
      "Time taken for 1 epoch 10.531699895858765 sec\n",
      "\n",
      "Epoch 77 Batch 0 Loss 0.1143\n",
      "Epoch 77 Batch 10 Loss 0.1241\n",
      "Epoch 77 Batch 20 Loss 0.1209\n",
      "Epoch 77 Batch 30 Loss 0.1201\n",
      "Epoch 77 Loss 0.1170\n",
      "Time taken for 1 epoch 5.723625898361206 sec\n",
      "\n",
      "Epoch 78 Batch 0 Loss 0.1121\n",
      "Epoch 78 Batch 10 Loss 0.1047\n",
      "Epoch 78 Batch 20 Loss 0.1211\n",
      "Epoch 78 Batch 30 Loss 0.1262\n",
      "Epoch 78 Loss 0.1143\n",
      "Time taken for 1 epoch 9.673596620559692 sec\n",
      "\n",
      "Epoch 79 Batch 0 Loss 0.1127\n",
      "Epoch 79 Batch 10 Loss 0.1012\n",
      "Epoch 79 Batch 20 Loss 0.1213\n",
      "Epoch 79 Batch 30 Loss 0.1367\n",
      "Epoch 79 Loss 0.1116\n",
      "Time taken for 1 epoch 5.722391366958618 sec\n",
      "\n",
      "Epoch 80 Batch 0 Loss 0.0974\n",
      "Epoch 80 Batch 10 Loss 0.1015\n",
      "Epoch 80 Batch 20 Loss 0.1113\n",
      "Epoch 80 Batch 30 Loss 0.1139\n",
      "Epoch 80 Loss 0.1093\n",
      "Time taken for 1 epoch 11.49955439567566 sec\n",
      "\n",
      "Epoch 81 Batch 0 Loss 0.0839\n",
      "Epoch 81 Batch 10 Loss 0.1021\n",
      "Epoch 81 Batch 20 Loss 0.1180\n",
      "Epoch 81 Batch 30 Loss 0.1073\n",
      "Epoch 81 Loss 0.1072\n",
      "Time taken for 1 epoch 5.74491286277771 sec\n",
      "\n",
      "Epoch 82 Batch 0 Loss 0.0975\n",
      "Epoch 82 Batch 10 Loss 0.1026\n",
      "Epoch 82 Batch 20 Loss 0.1098\n",
      "Epoch 82 Batch 30 Loss 0.1034\n",
      "Epoch 82 Loss 0.1045\n",
      "Time taken for 1 epoch 11.043291330337524 sec\n",
      "\n",
      "Epoch 83 Batch 0 Loss 0.0863\n",
      "Epoch 83 Batch 10 Loss 0.0999\n",
      "Epoch 83 Batch 20 Loss 0.1082\n",
      "Epoch 83 Batch 30 Loss 0.1142\n",
      "Epoch 83 Loss 0.1022\n",
      "Time taken for 1 epoch 5.739079713821411 sec\n",
      "\n",
      "Epoch 84 Batch 0 Loss 0.0913\n",
      "Epoch 84 Batch 10 Loss 0.1025\n",
      "Epoch 84 Batch 20 Loss 0.1047\n",
      "Epoch 84 Batch 30 Loss 0.1062\n",
      "Epoch 84 Loss 0.0998\n",
      "Time taken for 1 epoch 10.663047313690186 sec\n",
      "\n",
      "Epoch 85 Batch 0 Loss 0.0830\n",
      "Epoch 85 Batch 10 Loss 0.0962\n",
      "Epoch 85 Batch 20 Loss 0.0934\n",
      "Epoch 85 Batch 30 Loss 0.0961\n",
      "Epoch 85 Loss 0.0975\n",
      "Time taken for 1 epoch 5.758619070053101 sec\n",
      "\n",
      "Epoch 86 Batch 0 Loss 0.0988\n",
      "Epoch 86 Batch 10 Loss 0.0882\n",
      "Epoch 86 Batch 20 Loss 0.0975\n",
      "Epoch 86 Batch 30 Loss 0.0922\n",
      "Epoch 86 Loss 0.0954\n",
      "Time taken for 1 epoch 9.482332706451416 sec\n",
      "\n",
      "Epoch 87 Batch 0 Loss 0.0877\n",
      "Epoch 87 Batch 10 Loss 0.0875\n",
      "Epoch 87 Batch 20 Loss 0.0965\n",
      "Epoch 87 Batch 30 Loss 0.0937\n",
      "Epoch 87 Loss 0.0930\n",
      "Time taken for 1 epoch 5.723323106765747 sec\n",
      "\n",
      "Epoch 88 Batch 0 Loss 0.0973\n",
      "Epoch 88 Batch 10 Loss 0.0930\n",
      "Epoch 88 Batch 20 Loss 0.1023\n",
      "Epoch 88 Batch 30 Loss 0.0986\n",
      "Epoch 88 Loss 0.0901\n",
      "Time taken for 1 epoch 10.241373538970947 sec\n",
      "\n",
      "Epoch 89 Batch 0 Loss 0.0867\n",
      "Epoch 89 Batch 10 Loss 0.0866\n",
      "Epoch 89 Batch 20 Loss 0.0947\n",
      "Epoch 89 Batch 30 Loss 0.1008\n",
      "Epoch 89 Loss 0.0876\n",
      "Time taken for 1 epoch 5.7264368534088135 sec\n",
      "\n",
      "Epoch 90 Batch 0 Loss 0.0777\n",
      "Epoch 90 Batch 10 Loss 0.0833\n",
      "Epoch 90 Batch 20 Loss 0.0770\n",
      "Epoch 90 Batch 30 Loss 0.0833\n",
      "Epoch 90 Loss 0.0851\n",
      "Time taken for 1 epoch 10.590234279632568 sec\n",
      "\n",
      "Epoch 91 Batch 0 Loss 0.0741\n",
      "Epoch 91 Batch 10 Loss 0.0759\n",
      "Epoch 91 Batch 20 Loss 0.0974\n",
      "Epoch 91 Batch 30 Loss 0.0945\n",
      "Epoch 91 Loss 0.0833\n",
      "Time taken for 1 epoch 5.668994665145874 sec\n",
      "\n",
      "Epoch 92 Batch 0 Loss 0.0826\n",
      "Epoch 92 Batch 10 Loss 0.0828\n",
      "Epoch 92 Batch 20 Loss 0.0826\n",
      "Epoch 92 Batch 30 Loss 0.0823\n",
      "Epoch 92 Loss 0.0820\n",
      "Time taken for 1 epoch 21.081303358078003 sec\n",
      "\n",
      "Epoch 93 Batch 0 Loss 0.0805\n",
      "Epoch 93 Batch 10 Loss 0.0707\n",
      "Epoch 93 Batch 20 Loss 0.0874\n",
      "Epoch 93 Batch 30 Loss 0.0844\n",
      "Epoch 93 Loss 0.0796\n",
      "Time taken for 1 epoch 5.68891716003418 sec\n",
      "\n",
      "Epoch 94 Batch 0 Loss 0.0696\n",
      "Epoch 94 Batch 10 Loss 0.0767\n",
      "Epoch 94 Batch 20 Loss 0.0783\n",
      "Epoch 94 Batch 30 Loss 0.0880\n",
      "Epoch 94 Loss 0.0807\n",
      "Time taken for 1 epoch 7.534756660461426 sec\n",
      "\n",
      "Epoch 95 Batch 0 Loss 0.0848\n",
      "Epoch 95 Batch 10 Loss 0.0731\n",
      "Epoch 95 Batch 20 Loss 0.0898\n",
      "Epoch 95 Batch 30 Loss 0.0965\n",
      "Epoch 95 Loss 0.0858\n",
      "Time taken for 1 epoch 5.661014556884766 sec\n",
      "\n",
      "Epoch 96 Batch 0 Loss 0.0859\n",
      "Epoch 96 Batch 10 Loss 0.0779\n",
      "Epoch 96 Batch 20 Loss 0.0884\n",
      "Epoch 96 Batch 30 Loss 0.0791\n",
      "Epoch 96 Loss 0.0858\n",
      "Time taken for 1 epoch 7.849289417266846 sec\n",
      "\n",
      "Epoch 97 Batch 0 Loss 0.0771\n",
      "Epoch 97 Batch 10 Loss 0.0880\n",
      "Epoch 97 Batch 20 Loss 0.0815\n",
      "Epoch 97 Batch 30 Loss 0.0804\n",
      "Epoch 97 Loss 0.0836\n",
      "Time taken for 1 epoch 5.683891534805298 sec\n",
      "\n",
      "Epoch 98 Batch 0 Loss 0.0776\n",
      "Epoch 98 Batch 10 Loss 0.0762\n",
      "Epoch 98 Batch 20 Loss 0.0760\n",
      "Epoch 98 Batch 30 Loss 0.0858\n",
      "Epoch 98 Loss 0.0787\n",
      "Time taken for 1 epoch 8.39452052116394 sec\n",
      "\n",
      "Epoch 99 Batch 0 Loss 0.0737\n",
      "Epoch 99 Batch 10 Loss 0.0718\n",
      "Epoch 99 Batch 20 Loss 0.0760\n",
      "Epoch 99 Batch 30 Loss 0.0827\n",
      "Epoch 99 Loss 0.0759\n",
      "Time taken for 1 epoch 5.715293884277344 sec\n",
      "\n",
      "Epoch 100 Batch 0 Loss 0.0598\n",
      "Epoch 100 Batch 10 Loss 0.0689\n",
      "Epoch 100 Batch 20 Loss 0.0697\n",
      "Epoch 100 Batch 30 Loss 0.0903\n",
      "Epoch 100 Loss 0.0724\n",
      "Time taken for 1 epoch 10.351156234741211 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5845a69",
   "metadata": {
    "cellId": "nh9335rfe1r20qoona06bs"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Оценка модели\n",
    "def evaluate(sentence):\n",
    "    inputs = [tok_text.word_index[i] for i in sentence.split(' ') if i !='']\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_len_text,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, latent_dim))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([tok_sum.word_index['bos']], 0)\n",
    "\n",
    "    for t in range(max_len_sum):\n",
    "        predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += tok_sum.index_word[predicted_id] + ' '\n",
    "\n",
    "        if tok_sum.index_word[predicted_id] == 'eos':\n",
    "            return result, sentence\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ceb071d4",
   "metadata": {
    "cellId": "4mataj4d5slas4e5y38486"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def summ(sentence):\n",
    "    result, sentence = evaluate(sentence)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3e192e9",
   "metadata": {
    "cellId": "9c9nlsdw1ppwrse4zz0q2j"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Функция перевода последовательности индексов в текст\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_text_index[i]+' '\n",
    "    return newString\n",
    "# Функция перевода последовательности индексов в title\n",
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=sum_wordindex['bos']) and i!=sum_wordindex['eos']):\n",
    "            newString=newString+reverse_sum_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06d008cd",
   "metadata": {
    "cellId": "cdhr1wrbbjo5bkou928k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original title: или куда \n",
      "Predicted title:  «на костылях по монако» новое несчастье с головиным eos \n",
      "\n",
      "\n",
      "Original title: «люди в \n",
      "Predicted title:  оставят без «стольника» eos \n",
      "\n",
      "\n",
      "Original title: ссср как выборы \n",
      "Predicted title:  16 ронинов кремль изучает список «бизнесменов возвращенцев» eos \n",
      "\n",
      "\n",
      "Original title: «он с \n",
      "Predicted title:  «он заставил уважать америку» eos \n",
      "\n",
      "\n",
      "Original title: почему не пенсии \n",
      "Predicted title:  норвегия признала терроризм eos \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for i in range(5):\n",
    "    text2 = seq2text(padded_x_test[i])\n",
    "    print(\"Original title:\", seq2summary(padded_x_test_sum[i]))\n",
    "    print(\"Predicted title: \", summ(text2.strip()))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe9f64",
   "metadata": {
    "cellId": "1nvn06g9zx765kr2l5u286",
    "execution_id": "654261e2-9fc2-406c-9fdb-060a8af273e4"
   },
   "source": [
    "**Вывод:** результаты модели плохие"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "4b29f2ed-63fe-42b0-a90b-f8acc06af124",
  "notebookPath": "12_Модель_Transformer-2/ДЗ_12.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
